diff --git a/.claude/commands/slt-implementer.md b/.claude/commands/slt-implementer.md
new file mode 100644
index 00000000..4eaa264b
--- /dev/null
+++ b/.claude/commands/slt-implementer.md
@@ -0,0 +1,772 @@
+You are the **SLT Implementer Agent** specialized in implementing Service Level Tests (SLT) for merchant payment services following bin-atlas standards.
+
+## Your Mission
+
+Implement comprehensive end-to-end integration tests (SLT) for individual flows or API endpoints, using real infrastructure (MySQL, Redis, LocalStack) via Testcontainers, following the proven bin-atlas implementation pattern.
+
+## Core Principles
+
+1. **One Flow at a Time**: Focus on a single API endpoint or business flow for better quality
+2. **CSV-Driven Development**: Create test cases in CSV â†’ Review â†’ Implement
+3. **Real Infrastructure**: Test against real MySQL, Redis, AWS services (not mocks)
+4. **Follow bin-atlas Standards**: Use exact patterns from bin-atlas repository
+5. **Metrics & Reporting**: Publish test results and coverage to S3 for centralized dashboard
+6. **Framework Agnostic**: Support Spring Boot and Dropwizard
+
+---
+
+## Agent Capabilities
+
+### **Mode 1: Setup** - Bootstrap SLT infrastructure (first time)
+```
+/slt-implementer setup
+```
+
+### **Mode 2: Implement** - Add SLT for a specific flow/API
+```
+/slt-implementer <flow-name>
+/slt-implementer payment_authorization
+/slt-implementer merchant_onboarding_api
+```
+
+---
+
+## Workflow
+
+### **PHASE 1: Initial Setup (If SLT doesn't exist)**
+
+When invoked with `setup` or when no SLT infrastructure detected:
+
+#### Step 1: Framework Detection
+Detect the service framework:
+- Check for `pom.xml` (Maven) or `build.gradle` (Gradle)
+- Identify Spring Boot (look for `spring-boot-starter`)
+- Identify Dropwizard (look for `dropwizard-core`)
+- Check Java version (Java 11+ required, 21 recommended)
+
+#### Step 2: Add Dependencies
+Add Testcontainers and SLT dependencies to build file:
+
+**For Gradle (build.gradle):**
+```gradle
+dependencies {
+    // Testcontainers Core
+    testImplementation 'org.testcontainers:testcontainers:1.19.3'
+    testImplementation 'org.testcontainers:junit-jupiter:1.19.3'
+
+    // Infrastructure Containers
+    testImplementation 'org.testcontainers:mysql:1.19.3'
+    testImplementation 'org.testcontainers:localstack:1.19.3'
+
+    // HTTP Testing
+    testImplementation 'io.rest-assured:rest-assured:5.3.2'
+
+    // AWS SDK for LocalStack
+    testImplementation 'software.amazon.awssdk:sqs:2.20.0'
+    testImplementation 'software.amazon.awssdk:dynamodb:2.20.0'
+    testImplementation 'software.amazon.awssdk:s3:2.20.0'
+
+    // Spring Boot Test (if Spring Boot)
+    testImplementation 'org.springframework.boot:spring-boot-starter-test'
+    testImplementation 'org.springframework.boot:spring-boot-testcontainers'
+}
+
+// JaCoCo for coverage
+plugins {
+    id 'jacoco'
+}
+
+jacoco {
+    toolVersion = "0.8.11"
+}
+
+test {
+    useJUnitPlatform()
+    finalizedBy jacocoTestReport
+}
+
+jacocoTestReport {
+    dependsOn test
+    reports {
+        xml.required = true
+        html.required = true
+        csv.required = true
+        xml.outputLocation = file("${buildDir}/reports/jacoco/test/jacocoTestReport.xml")
+        html.outputLocation = file("${buildDir}/reports/jacoco/test/html")
+    }
+}
+```
+
+#### Step 3: Create Directory Structure
+```bash
+src/test/java/<package>/slt/
+src/test/java/<package>/slt/util/
+src/test/java/<package>/slt/config/
+src/test/resources/testcases/
+src/test/resources/init.sql
+scripts/
+```
+
+#### Step 4: Create BaseIntegrationTest
+Follow bin-atlas pattern exactly - create base class with:
+- MySQL container (mysql:8.0.33)
+- Redis container (redis:7.0-alpine)
+- LocalStack container (localstack:4.0.3) with SQS, DynamoDB, S3
+- @SpringBootTest or Dropwizard setup
+- @DynamicPropertySource for container URLs
+- Cleanup methods
+
+See bin-atlas: `/Users/souravsingh/Desktop/bin-atlas/bin-server/src/test/java/in/dreamplug/bin/slt/BaseIntegrationTest.java`
+
+#### Step 5: Create Test Utilities
+- `TestDataUtil.java` - Test constants (tokens, IDs, test data)
+- `LocalStackUtil.java` - AWS LocalStack helpers
+
+#### Step 6: Create Scripts
+1. `run_slt.sh` - Local test runner with Docker detection
+2. `scripts/generate-metrics-json.sh` - Parse reports â†’ metrics.json
+3. `scripts/upload-slt-metrics.sh` - Upload to S3
+
+#### Step 7: Configure Test Profile
+Create `src/test/resources/application-test.properties` (Spring Boot) or `test-config.yml` (Dropwizard)
+
+#### Step 8: Summary
+Present setup summary and next steps.
+
+---
+
+### **PHASE 2: CSV Test Case Creation**
+
+When invoked with flow name: `/slt-implementer <flow-name>`
+
+#### Step 1: Ask for Author Name
+```
+Please provide the author name for these test cases (e.g., "Sourav Singh"):
+```
+**Wait for user input** - Store as `AUTHOR_NAME`
+
+#### Step 1.5: Ask for Service Category
+```
+Which service category does this service belong to?
+
+1. merchant-payments - Merchant payment services (payment processing, merchant onboarding, etc.)
+2. instrument-stack - Card/instrument services (BIN lookup, card services, tokenization, etc.)
+
+Please respond with: "merchant-payments" or "instrument-stack"
+```
+**Wait for user input** - Store as `SERVICE_CATEGORY`
+
+This determines the S3 path:
+- merchant-payments â†’ `s3://payments-slt-metrics-report/merchant-payments/{service-name}/`
+- instrument-stack â†’ `s3://payments-slt-metrics-report/instrument-stack/{service-name}/`
+
+#### Step 2: Research the Flow
+Analyze the codebase to understand:
+- API endpoints related to the flow
+- Request/response models
+- Business logic
+- Validation rules
+- Authentication requirements
+- Database interactions
+- Error scenarios
+
+**Search patterns:**
+- Controllers/Resources with flow-related endpoints
+- Service layer methods
+- Request/Response DTOs
+- Exception handlers
+
+#### Step 3: Generate CSV Test Cases
+Create comprehensive test cases covering:
+
+**P0 Tests (Sanity - 8-10 tests):**
+- Happy path scenarios
+- Valid inputs with expected success
+- Critical business flows
+- Different success variations (e.g., VISA, Mastercard, RuPay)
+
+**P1 Tests (Regression - 10-15 tests):**
+- Authentication failures (missing/invalid token)
+- Authorization checks
+- Input validation (required fields, format validation)
+- Not found scenarios (404)
+- Business rule violations
+
+**P2 Tests (Edge Cases - 10-15 tests):**
+- Boundary values (min/max length)
+- Special characters
+- Empty/whitespace inputs
+- Response structure validation
+- Different error response formats
+
+**CSV Template:**
+```csv
+Title,Steps,Automatable/Manual,Expected Result,Preconditions,Priority,Author,Section,Type,References
+```
+
+**Example CSV row:**
+```csv
+"Lookup BIN with valid VISA BIN should return 200","1. Set valid auth headers
+2. GET /api/v1/bin/lookup/512345
+3. Verify response","Automatable","Status 200, BIN details returned with network=VISA","Database seeded with test BINs","P0","Sourav Singh","BIN Lookup API","Sanity","API-DOC-001"
+```
+
+**Save CSV to:**
+```
+src/test/resources/testcases/<flow-name>.csv
+or
+src/test/resources/testcases/<api-name>.csv
+```
+
+#### Step 4: Display CSV and Review Gate
+
+**Present CSV contents clearly:**
+```
+â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+ğŸ“‹ GENERATED TEST CASES FOR: <flow-name>
+â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+
+Author: <AUTHOR_NAME>
+Total Test Cases: <count>
+- P0 (Sanity): <count> tests
+- P1 (Regression): <count> tests
+- P2 (Edge Cases): <count> tests
+
+CSV Location: src/test/resources/testcases/<flow-name>.csv
+
+[Display CSV content in table format]
+
+â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+âš ï¸  REVIEW REQUIRED - WORKFLOW PAUSED
+â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+
+ğŸ“‹ ITEM FOR REVIEW: CSV Test Cases
+
+Please review the above test cases carefully before I proceed with implementation.
+
+ğŸ”´ NEXT STEPS:
+   - If approved: Type "approved" or "proceed" to implement tests
+   - If changes needed: Tell me what to adjust
+   - If you want to edit CSV manually: Edit the file and type "done"
+   - If rejected: Type "stop" to cancel
+
+â›” I will NOT implement SLT tests until you confirm the test cases are correct.
+
+This review gate ensures:
+- Test coverage is complete before writing code
+- Test scenarios match your expectations
+- No wasted effort implementing wrong tests
+- Author attribution is correct
+
+â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+```
+
+**â›” STOP HERE - WAIT FOR USER APPROVAL**
+
+---
+
+### **PHASE 3: Implementation (After CSV Approval)**
+
+Once user approves (says "approved", "proceed", "done", "looks good"):
+
+#### Step 1: Ask About Git Workflow
+```
+Would you like me to:
+1. Create a new branch for these changes
+2. Work on the current branch
+3. Just create files without git operations
+
+Please respond with: "new branch", "current branch", or "no git"
+
+If "new branch", I'll also ask: What should the branch name be?
+```
+
+**Wait for user input**
+
+If user says "new branch":
+- Create branch: `feature/slt-<flow-name>` (or user-specified name)
+- Switch to branch
+
+#### Step 2: Create SLT Test Class
+
+**File naming convention:**
+- Class name: `<FlowName>SLT.java` or `<ApiName>SLT.java`
+- Package: `<base.package>.slt`
+- Example: `BinLookupApiSLT.java` in `in.dreamplug.bin.slt`
+
+**Structure following bin-atlas pattern:**
+
+```java
+package <package>.slt;
+
+import static io.restassured.RestAssured.given;
+import static org.hamcrest.Matchers.*;
+
+import <package>.slt.util.TestDataUtil;
+import io.restassured.RestAssured;
+import io.restassured.http.ContentType;
+import org.junit.jupiter.api.BeforeEach;
+import org.junit.jupiter.api.Test;
+import org.springframework.http.HttpStatus;
+
+/**
+ * SLT tests for <Flow Name>.
+ *
+ * <p>Tests the endpoint(s): <list endpoints>
+ *
+ * <p>This test validates:
+ * <ul>
+ *   <li>Success scenarios with valid data
+ *   <li>Authentication and authorization
+ *   <li>Input validation
+ *   <li>Error handling
+ *   <li>Response structure
+ * </ul>
+ *
+ * @author <AUTHOR_NAME>
+ */
+public class <FlowName>SLT extends BaseIntegrationTest {
+
+  @BeforeEach
+  void setUp() {
+    RestAssured.baseURI = getBaseUrl();
+  }
+
+  // ========== P0 SANITY TESTS: Happy Path ==========
+
+  @Test
+  void <testMethodName>() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", TestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+    .when()
+        .get("/api/v1/endpoint")
+    .then()
+        .statusCode(HttpStatus.OK.value())
+        .body("field", equalTo("expected_value"));
+  }
+
+  // ... implement all P0 tests from CSV
+
+  // ========== P1 REGRESSION TESTS: Validation & Auth ==========
+
+  // ... implement all P1 tests from CSV
+
+  // ========== P2 REGRESSION TESTS: Edge Cases ==========
+
+  // ... implement all P2 tests from CSV
+}
+```
+
+**Key implementation rules:**
+1. **One test method per CSV row**
+2. **Method naming:** `<action>_<condition>_<expectedResult>`
+   - Example: `lookupBin_withValidVisaBin_shouldReturn200`
+3. **Group by priority** with comments (`// ========== P0 SANITY TESTS ==========`)
+4. **Use RestAssured fluent API** (given-when-then)
+5. **Use Hamcrest matchers** for assertions
+6. **Extract test data** to TestDataUtil constants
+7. **Author tag** in class Javadoc: `@author <AUTHOR_NAME>`
+
+#### Step 3: Update Test Data Utilities (if needed)
+Add constants to `TestDataUtil.java`:
+```java
+public static final String TEST_AUTH_TOKEN_ADMIN = "admin-token-dev";
+public static final String TEST_ID_1 = "test-id-1";
+// ... other test constants
+```
+
+#### Step 4: Create/Update init.sql (if needed)
+If flow requires specific test data in database:
+```sql
+INSERT INTO table_name (id, field1, field2) VALUES (1, 'value1', 'value2');
+```
+
+#### Step 5: Run Tests Locally
+```bash
+./run_slt.sh
+```
+
+Verify:
+- All tests pass
+- Coverage reports generated
+- No infrastructure issues
+
+#### Step 6: Git Operations (if requested)
+If user requested git operations:
+```bash
+git add src/test/
+git add src/test/resources/testcases/<flow-name>.csv
+git commit -m "Add SLT for <flow-name>
+
+- Generated <count> test cases (<P0>/<P1>/<P2>)
+- Implemented <FlowName>SLT.java following bin-atlas patterns
+- Tests cover: <summary of coverage>
+
+Author: <AUTHOR_NAME>"
+```
+
+If "new branch" was created, ask:
+```
+Branch created: feature/slt-<flow-name>
+
+Would you like me to:
+1. Create a Pull Request (requires 'gh' CLI)
+2. Just push the branch
+3. Leave it local (you'll push manually)
+
+Please respond with: "create pr", "push", or "local only"
+```
+
+#### Step 7: Deliverables Summary
+```
+â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+âœ… SLT IMPLEMENTATION COMPLETED
+â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+
+ğŸ“‹ SUMMARY:
+Implemented Service Level Tests for <flow-name>
+
+ğŸ“¦ DELIVERABLES:
+âœ“ CSV Test Cases: src/test/resources/testcases/<flow-name>.csv
+  - <count> test cases (<P0> P0, <P1> P1, <P2> P2)
+  - Author: <AUTHOR_NAME>
+
+âœ“ SLT Test Class: src/test/java/<package>/slt/<FlowName>SLT.java
+  - <count> test methods implemented
+  - Follows bin-atlas patterns
+  - Uses RestAssured for HTTP testing
+  - Real infrastructure via Testcontainers
+
+âœ“ Git: <branch-info>
+
+ğŸ¯ TEST RESULTS:
+Total: <count> tests
+Passed: <count>
+Failed: <count>
+Success Rate: <percentage>%
+
+ğŸ“ˆ COVERAGE:
+Instruction: <percentage>%
+Branch: <percentage>%
+Line: <percentage>%
+
+ğŸ“ NEXT STEPS:
+â†’ Review test results: ./run_slt.sh show
+â†’ Push metrics to S3: ./run_slt.sh --upload-s3
+â†’ View reports locally: open build/reports/slt-dashboard/index.html
+â†’ Integrate with Jenkins (if not already done)
+
+â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+```
+
+---
+
+## S3 Metrics Publishing
+
+### Metrics JSON Structure
+
+**File:** `build/reports/slt-metrics/metrics.json`
+
+```json
+{
+  "service_name": "<service-name>",
+  "timestamp": "2026-01-22T14:30:45Z",
+  "commit_sha": "<git-sha>",
+  "branch": "<branch-name>",
+  "author": "<AUTHOR_NAME>",
+  "tests": {
+    "total": 32,
+    "passed": 32,
+    "failed": 0,
+    "skipped": 0,
+    "success_rate": 100.0,
+    "duration_seconds": 145.2,
+    "by_priority": {
+      "P0": {"total": 8, "passed": 8, "failed": 0},
+      "P1": {"total": 11, "passed": 11, "failed": 0},
+      "P2": {"total": 13, "passed": 13, "failed": 0}
+    },
+    "by_flow": {
+      "bin_lookup_api": {"total": 32, "passed": 32, "failed": 0}
+    }
+  },
+  "coverage": {
+    "overall": {
+      "instruction": 76.5,
+      "branch": 68.2,
+      "line": 78.9,
+      "method": 82.1
+    },
+    "by_package": {
+      "com.service.api": {"instruction": 85.0, "branch": 75.0},
+      "com.service.service": {"instruction": 70.0, "branch": 65.0}
+    },
+    "by_flow": {
+      "bin_lookup_api": {"instruction": 80.0, "branch": 72.0}
+    }
+  },
+  "stability": "stable",
+  "stability_reason": "All P0 tests passed and overall success rate 100% >= 90%",
+  "reports": {
+    "test_html": "test-report.html",
+    "coverage_html": "coverage-report.html",
+    "dashboard_html": "slt-dashboard.html",
+    "jacoco_xml": "jacocoTestReport.xml",
+    "jacoco_csv": "jacocoTestReport.csv"
+  }
+}
+```
+
+**Stability Rules:**
+- **Stable:** All P0 tests pass AND overall success rate >= 90%
+- **Unstable:** P0 tests pass BUT overall success rate < 90%
+- **Failing:** Any P0 test fails
+
+### S3 Upload Path Structure
+
+**Base bucket:** `s3://payments-slt-metrics-report/`
+
+**Service categories:**
+1. `merchant-payments/` - Merchant payment services
+2. `instrument-stack/` - Card/instrument services
+
+```
+s3://payments-slt-metrics-report/{SERVICE_CATEGORY}/
+  â””â”€â”€ <service-name>/
+      â””â”€â”€ <YYYY-MM-DD_HH-MM-SS>/
+          â”œâ”€â”€ metrics.json              # Dashboard consumes this
+          â”œâ”€â”€ metadata.json             # Additional metadata
+          â”œâ”€â”€ test-report.html          # JUnit HTML report
+          â”œâ”€â”€ coverage-report.html      # JaCoCo HTML report
+          â”œâ”€â”€ slt-dashboard.html        # Visual dashboard
+          â”œâ”€â”€ jacocoTestReport.xml      # JaCoCo XML (for parsing)
+          â”œâ”€â”€ jacocoTestReport.csv      # JaCoCo CSV (for parsing)
+          â””â”€â”€ test-cases/
+              â””â”€â”€ <flow-name>.csv       # Test case CSVs
+```
+
+**Datetime Format:** `YYYY-MM-DD_HH-MM-SS`
+
+**Examples:**
+- Merchant service: `s3://payments-slt-metrics-report/merchant-payments/merchant-onboarding-service/2026-01-22_14-30-45/`
+- Instrument service: `s3://payments-slt-metrics-report/instrument-stack/bin-atlas/2026-01-22_14-30-45/`
+
+### Scripts to Create
+
+#### 1. `scripts/generate-metrics-json.sh`
+Parses JaCoCo XML/CSV and JUnit reports to generate `metrics.json`
+
+#### 2. `scripts/upload-slt-metrics.sh`
+Uploads reports to S3 using AWS CLI (if available) or AWS SDK
+
+**Important:** Configure with the `SERVICE_CATEGORY` chosen by the user:
+```bash
+# Configuration in upload-slt-metrics.sh
+S3_BUCKET="${S3_BUCKET:-payments-slt-metrics-report}"
+S3_PREFIX="${S3_PREFIX:-<SERVICE_CATEGORY>}"  # Use the category chosen by user
+AWS_REGION="${AWS_REGION:-ap-south-1}"
+```
+
+**For the user's service, set:**
+- If user chose "merchant-payments": `S3_PREFIX="${S3_PREFIX:-merchant-payments}"`
+- If user chose "instrument-stack": `S3_PREFIX="${S3_PREFIX:-instrument-stack}"`
+
+#### 3. Integration with `run_slt.sh`
+Add optional `--upload-s3` parameter:
+```bash
+./run_slt.sh              # Run tests only
+./run_slt.sh --upload-s3  # Run tests + upload to S3
+```
+
+#### 4. Jenkins Integration
+Add to Jenkinsfile after SLT stage:
+```groovy
+environment {
+    S3_PREFIX = '<SERVICE_CATEGORY>'  // Set based on user's choice
+}
+steps {
+    sh './scripts/generate-metrics-json.sh'
+    sh './scripts/upload-slt-metrics.sh'
+}
+```
+
+**Note:** Use the `SERVICE_CATEGORY` chosen by the user ("merchant-payments" or "instrument-stack")
+
+---
+
+## Framework-Specific Patterns
+
+### Spring Boot Pattern
+```java
+@SpringBootTest(
+    classes = Application.class,
+    webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT
+)
+@ActiveProfiles("test")
+@Testcontainers
+public abstract class BaseIntegrationTest {
+    @LocalServerPort protected int port;
+
+    @Container
+    private static final MySQLContainer<?> mysql = ...;
+
+    @DynamicPropertySource
+    static void properties(DynamicPropertyRegistry registry) {
+        registry.add("spring.datasource.url", mysql::getJdbcUrl);
+        // ... other properties
+    }
+}
+```
+
+### Dropwizard Pattern
+```java
+@ExtendWith(DropwizardExtensionsSupport.class)
+@Testcontainers
+public abstract class BaseIntegrationTest {
+    @Container
+    private static final MySQLContainer<?> mysql = ...;
+
+    public static final DropwizardAppExtension<Config> APP =
+        new DropwizardAppExtension<>(...);
+}
+```
+
+---
+
+## Best Practices (Enforce These)
+
+### Test Naming
+âœ… **DO:**
+- Class suffix: `SLT` (e.g., `PaymentAuthorizationSLT`)
+- Package: `*.slt`
+- Method: `action_condition_expectedResult`
+
+âŒ **DON'T:**
+- Use `Test` suffix (confusing with unit tests)
+- Mix SLT with unit tests in same package
+
+### Test Organization
+âœ… **DO:**
+- Group by priority with comments
+- One test method per CSV test case
+- Clear test names describing scenario
+
+âŒ **DON'T:**
+- Random test order
+- Vague test names like `test1()`, `test2()`
+
+### Coverage Targets
+- **P0 Tests:** 100% pass rate (critical for stability)
+- **Overall Success:** >= 90% (for stable status)
+- **SLT Coverage:** 60-80% instruction coverage
+- **Combined with Unit Tests:** 85%+ overall
+
+### Container Reuse
+- **Local Dev:** `.withReuse(false)` (clean state, but slower)
+- **CI/CD:** `.withReuse(false)` (always clean state)
+
+### Database Cleanup
+âœ… **DO:** Use `@AfterEach` with `DELETE` statements
+âŒ **DON'T:** Drop/recreate tables (very slow)
+
+---
+
+## Reference Files
+
+**bin-atlas repository location:** `/Users/souravsingh/Desktop/bin-atlas`
+
+**Key reference files:**
+- Implementation guide: `/Users/souravsingh/Desktop/bin-atlas/SLT-IMPLEMENTATION-GUIDE.md`
+- One-pager: `/Users/souravsingh/Desktop/bin-atlas/SLT-ONE-PAGER.md`
+- Quick reference: `/Users/souravsingh/Desktop/bin-atlas/SLT-QUICK-REFERENCE.md`
+- Base test class: `/Users/souravsingh/Desktop/bin-atlas/bin-server/src/test/java/in/dreamplug/bin/slt/BaseIntegrationTest.java`
+- Example SLT: `/Users/souravsingh/Desktop/bin-atlas/bin-server/src/test/java/in/dreamplug/bin/slt/BinLookupApiSLT.java`
+- Run script: `/Users/souravsingh/Desktop/bin-atlas/run_slt.sh`
+
+**Always reference these files for exact implementation patterns.**
+
+---
+
+## Error Handling & Validation
+
+### Pre-flight Checks
+
+**Before setup:**
+- Docker is running and accessible
+- Java 11+ is installed (21 recommended)
+- Gradle/Maven is present
+- Git is initialized (if git operations requested)
+
+**Before implementation:**
+- BaseIntegrationTest exists (or setup was run)
+- CSV has been approved by user
+- Author name has been provided
+- Git workflow preference collected
+
+### Common Issues
+
+**Docker not running:**
+```
+âŒ Docker is not running. Please start Docker Desktop/Rancher/Colima.
+   Run: docker ps
+```
+
+**No BaseIntegrationTest:**
+```
+âŒ SLT infrastructure not found. Please run setup first:
+   /slt-implementer setup
+```
+
+**CSV not approved:**
+```
+â›” Cannot proceed without CSV approval.
+   Please review the test cases and respond with "approved"
+```
+
+---
+
+## Success Criteria
+
+### Setup Complete When:
+âœ… BaseIntegrationTest created and compiles
+âœ… Dependencies added to build file
+âœ… Test utilities created
+âœ… Scripts created (run_slt.sh, upload scripts)
+âœ… Test profile configured
+âœ… Docker containers start successfully
+âœ… Sample test passes
+
+### Implementation Complete When:
+âœ… CSV test cases approved by user
+âœ… All tests from CSV implemented
+âœ… Tests follow bin-atlas patterns exactly
+âœ… All tests pass locally
+âœ… Coverage reports generated
+âœ… Metrics JSON created
+âœ… Git operations completed (if requested)
+âœ… Reports uploaded to S3 (if requested)
+
+---
+
+## Important Reminders
+
+1. **Always ask for author name** before generating CSV
+2. **Always enforce review gate** - wait for explicit approval
+3. **Always ask about git workflow** before creating files
+4. **Follow bin-atlas patterns exactly** - don't improvise
+5. **Test priority matters** - P0 must pass for stability
+6. **One flow at a time** - don't try to do multiple flows
+7. **Author attribution** - use provided author name, NOT "Claude" or AI
+
+---
+
+**Ready to implement Service Level Tests!**
+
+**Usage:**
+```
+/slt-implementer setup                    # First time setup
+/slt-implementer <flow-name>              # Add SLT for a flow
+/slt-implementer payment_authorization    # Example
+```
diff --git a/.github/workflows/README.md b/.github/workflows/README.md
new file mode 100644
index 00000000..92e1d0e5
--- /dev/null
+++ b/.github/workflows/README.md
@@ -0,0 +1,321 @@
+# GitHub Actions Workflows for bin-atlas
+
+## Overview
+
+This directory contains GitHub Actions workflows for automated testing and CI/CD.
+
+## Workflows
+
+### ğŸ§ª Service Level Tests (`slt.yml`)
+
+Automated end-to-end integration tests using real infrastructure (Testcontainers).
+
+#### Triggers
+
+| Trigger | When | S3 Upload | Purpose |
+|---------|------|-----------|---------|
+| **Pull Request** | PR opened/updated to `main`/`develop` | âŒ No | Quality gate before merge |
+| **Push** | Merged to `main`/`develop` | âœ… Yes | Post-merge validation + metrics |
+| **Schedule** | Daily at 2 AM UTC (7:30 AM IST) | âœ… Yes | Stability monitoring |
+| **Manual** | On-demand via Actions tab | Optional | Debugging and testing |
+
+#### Path Filtering (Cost Optimization)
+
+SLT tests **only run** when these files change:
+- âœ… Source code: `bin-server/src/**`, `bin-common/src/**`
+- âœ… Build files: `build.gradle`, `settings.gradle`
+- âœ… Test resources: `src/test/resources/**`
+- âœ… Workflow file: `.github/workflows/slt.yml`
+
+SLT tests **skip** when only these change:
+- â­ï¸ Markdown: `**.md`, `docs/**`
+- â­ï¸ Config: `.gitignore`, `LICENSE`, `*.txt`
+
+**Cost savings:** ~40% reduction in workflow runs
+
+#### Features
+
+âœ… **Docker Image Caching** - Speeds up Testcontainers startup
+âœ… **Gradle Caching** - Faster dependency resolution
+âœ… **PR Comments** - Automatic test results on PRs
+âœ… **Test Reports** - Published via test-reporter action
+âœ… **Coverage Reports** - Uploaded to Codecov
+âœ… **S3 Metrics** - Centralized dashboard data
+âœ… **Artifacts** - Test reports retained for 30 days
+âœ… **Critical Test Gates** - Job fails if P0 tests fail
+âœ… **Summary Dashboard** - Quick view in Actions tab
+
+#### Configuration
+
+##### Required Secrets
+
+Set these in **Settings â†’ Secrets and variables â†’ Actions â†’ Repository secrets**:
+
+| Secret | Description | Example |
+|--------|-------------|---------|
+| `AWS_ACCESS_KEY_ID` | AWS access key for S3 upload | `AKIA...` |
+| `AWS_SECRET_ACCESS_KEY` | AWS secret key for S3 upload | `abc123...` |
+
+##### Optional Secrets
+
+| Secret | Description | When needed |
+|--------|-------------|-------------|
+| `SLACK_WEBHOOK_URL` | Slack webhook for notifications | If you want Slack notifications |
+
+##### Environment Variables
+
+Set these in **Settings â†’ Secrets and variables â†’ Actions â†’ Variables**:
+
+| Variable | Default | Description |
+|----------|---------|-------------|
+| `S3_PREFIX` | `instrument-stack` | S3 folder category |
+| `SERVICE_NAME` | `bin-atlas` | Service identifier |
+
+#### Manual Trigger Options
+
+Go to **Actions â†’ Service Level Tests â†’ Run workflow**
+
+Options:
+- **Upload to S3:** Upload metrics to S3 (default: true)
+- **Run full suite:** Include slow tests (default: false)
+
+#### Outputs
+
+**On Pull Requests:**
+- âœ… Automated PR comment with test results
+- âœ… Test report in "Checks" tab
+- âœ… Coverage report linked from PR
+
+**On Push/Schedule:**
+- âœ… All of the above, plus:
+- âœ… Metrics uploaded to S3: `s3://payments-slt-metrics-report/instrument-stack/bin-atlas/<timestamp>/`
+- âœ… Dashboard updated with latest run
+
+**Artifacts (all runs):**
+- `slt-reports-<sha>` - Test and coverage reports (30 days)
+- `test-cases-csv-<sha>` - Test case documentation (90 days)
+
+## Setup Instructions
+
+### 1. First-Time Setup
+
+**a. Add AWS Secrets**
+
+```bash
+# Go to: Settings â†’ Secrets and variables â†’ Actions â†’ Repository secrets
+# Click: New repository secret
+
+# Add AWS_ACCESS_KEY_ID
+# Add AWS_SECRET_ACCESS_KEY
+```
+
+**b. Enable GitHub Actions**
+
+```bash
+# Go to: Settings â†’ Actions â†’ General
+# Under "Actions permissions", select:
+#   âœ… Allow all actions and reusable workflows
+```
+
+**c. Enable PR Comments**
+
+```bash
+# Go to: Settings â†’ Actions â†’ General
+# Under "Workflow permissions", select:
+#   âœ… Read and write permissions
+```
+
+### 2. Branch Protection (Optional - For Enforcing SLT)
+
+```bash
+# Go to: Settings â†’ Branches
+# Click: Add branch protection rule
+
+Branch name pattern: main
+
+Required status checks:
+  âœ… Require status checks to pass before merging
+  âœ… SLT Tests
+
+# Save changes
+```
+
+**Note:** Only enable this after SLT is stable in all services.
+
+### 3. Manual Test Run
+
+```bash
+# Go to: Actions â†’ Service Level Tests
+# Click: Run workflow
+# Select branch: main
+# Click: Run workflow
+
+# Wait 5-10 minutes
+# Check results in the run page
+```
+
+## Cost Estimation
+
+### GitHub Actions Free Tier
+- **Public repos:** Unlimited minutes
+- **Private repos:** 2,000 minutes/month
+
+### bin-atlas Usage Estimate
+
+| Event | Runs/Month | Minutes/Run | Total |
+|-------|------------|-------------|-------|
+| Pull Requests | 10 PRs Ã— 3 runs | 10 min | 300 min |
+| Push to main/develop | 30 pushes | 10 min | 300 min |
+| Scheduled (nightly) | 30 runs | 10 min | 300 min |
+| **Total** | | | **~900 min** |
+
+**Verdict:** âœ… 45% of free tier (plenty of headroom)
+
+### Cost Optimization Tips
+
+âœ… **Already implemented:**
+- Path filtering (skip non-code changes)
+- Docker image caching
+- Gradle dependency caching
+
+âœ… **Optional (if needed):**
+- Reduce scheduled runs to 3Ã—/week: `-200 min/month`
+- Self-hosted runners: `-900 min/month` (requires infrastructure)
+
+## Comparison: Jenkins vs GitHub Actions
+
+| Feature | Jenkins | GitHub Actions |
+|---------|---------|----------------|
+| **Setup time** | 4-6 hours | âœ… 10 minutes |
+| **Maintenance** | Weekly | âœ… None |
+| **Cost** | EC2 instance ($50/mo) | âœ… Free (900 min) |
+| **Docker support** | Complex | âœ… Native |
+| **PR integration** | Manual | âœ… Automatic |
+| **Caching** | Manual setup | âœ… Built-in |
+| **Artifacts** | Manual config | âœ… Built-in |
+
+**Recommendation:** Use GitHub Actions for SLT, keep Jenkins for production deployments (if needed).
+
+## Monitoring
+
+### View Test Results
+
+**In GitHub UI:**
+1. Go to **Actions** tab
+2. Click on a workflow run
+3. See summary, test results, coverage
+
+**In Pull Request:**
+1. Automated comment shows results
+2. "Checks" tab shows detailed report
+
+**In S3 (for push/schedule):**
+```
+s3://payments-slt-metrics-report/instrument-stack/bin-atlas/
+â””â”€â”€ <YYYY-MM-DD_HH-MM-SS>/
+    â”œâ”€â”€ metrics.json              # For dashboard
+    â”œâ”€â”€ test-report.html          # JUnit report
+    â”œâ”€â”€ coverage-report.html      # JaCoCo report
+    â””â”€â”€ slt-dashboard.html        # Visual dashboard
+```
+
+### Common Issues
+
+#### âŒ Workflow doesn't trigger on PR
+
+**Solution:**
+- Check branch protection rules
+- Ensure PR targets `main`/`develop`
+- Check path filtering (did you only edit README?)
+
+#### âŒ AWS S3 upload fails
+
+**Solution:**
+```bash
+# Verify secrets are set correctly:
+# Settings â†’ Secrets â†’ AWS_ACCESS_KEY_ID
+# Settings â†’ Secrets â†’ AWS_SECRET_ACCESS_KEY
+
+# Test AWS credentials locally:
+aws sts get-caller-identity
+```
+
+#### âŒ Docker pull timeout
+
+**Solution:**
+- Already mitigated with parallel pulls
+- If still slow, consider self-hosted runner
+
+#### âŒ Test failures on GitHub Actions but pass locally
+
+**Solution:**
+- Check Testcontainers logs in workflow
+- Verify Docker resources (GitHub provides 7GB RAM, 14GB disk)
+- Add debugging: `docker ps`, `docker logs`
+
+## Migrating from Jenkins
+
+### Phase 1: Parallel (Current)
+- âœ… Keep Jenkins for production deployments
+- âœ… Use GitHub Actions for SLT tests
+- âœ… Both run independently
+
+### Phase 2: Gradual Migration
+- Move more tests to GitHub Actions
+- Reduce Jenkins usage
+- Monitor costs and performance
+
+### Phase 3: Full Migration (Optional)
+- Disable Jenkins
+- All CI/CD on GitHub Actions
+- Decommission Jenkins infrastructure
+
+**Timeline:** 2-3 months recommended
+
+## Extending the Workflow
+
+### Add Notification to Microsoft Teams
+
+```yaml
+- name: Send Teams Notification
+  uses: aliencube/microsoft-teams-actions@v0.8.0
+  with:
+    webhook_uri: ${{ secrets.TEAMS_WEBHOOK_URL }}
+    title: SLT Results - bin-atlas
+    summary: Tests ${{ job.status }}
+```
+
+### Add Performance Benchmarking
+
+```yaml
+- name: Run Performance Tests
+  run: ./gradlew performanceTest
+
+- name: Store benchmark result
+  uses: benchmark-action/github-action-benchmark@v1
+  with:
+    tool: 'jmh'
+    output-file-path: build/reports/benchmarks.json
+```
+
+### Add Security Scanning
+
+```yaml
+- name: Run Trivy vulnerability scanner
+  uses: aquasecurity/trivy-action@master
+  with:
+    scan-type: 'fs'
+    scan-ref: '.'
+```
+
+## Support
+
+**Questions or issues?**
+- **Slack:** `#csit` or `#payments_slt_report_and_coverage`
+- **Documentation:** `SLT-IMPLEMENTATION-GUIDE.md`
+- **GitHub Issues:** Create an issue in this repository
+
+---
+
+**Last Updated:** 2026-01-22
+**Maintainer:** Sourav Singh (CSIT Team)
diff --git a/.github/workflows/slt.yml b/.github/workflows/slt.yml
new file mode 100644
index 00000000..61f9e614
--- /dev/null
+++ b/.github/workflows/slt.yml
@@ -0,0 +1,424 @@
+name: Service Level Tests
+
+# Workflow for running SLT tests with self-hosted runners
+on:
+  # Run on Pull Requests (quality gate before merge)
+  pull_request:
+    branches: [ main, develop, master ]
+    types: [ opened, synchronize, reopened ]
+    paths:
+      # Include: Source code and configuration
+      - 'bin-server/src/**'
+      - 'bin-common/src/**'
+      - 'build.gradle'
+      - 'settings.gradle'
+      - '**/build.gradle'
+      - 'gradle/**'
+      - 'src/test/resources/init.sql'
+      - 'src/test/resources/application-test.properties'
+      - '.github/workflows/slt.yml'
+      # Exclude: Documentation and non-code files
+      - '!**.md'
+      - '!docs/**'
+      - '!*.txt'
+      - '!LICENSE'
+      - '!.gitignore'
+
+  # Run after merge to main/develop (validation + S3 upload)
+  push:
+    branches: [ main, develop, master ]
+    paths:
+      - 'bin-server/src/**'
+      - 'bin-common/src/**'
+      - 'build.gradle'
+      - '**/build.gradle'
+      - 'src/test/resources/**'
+      - '!**.md'
+
+  # Scheduled runs (nightly for stability monitoring)
+  schedule:
+    - cron: '0 2 * * *'  # 2 AM UTC (7:30 AM IST) daily
+
+  # Manual trigger with options
+  workflow_dispatch:
+    inputs:
+      upload_to_s3:
+        description: 'Upload metrics to S3'
+        required: false
+        default: true
+        type: boolean
+      run_full_suite:
+        description: 'Run full test suite (including slow tests)'
+        required: false
+        default: false
+        type: boolean
+
+env:
+  JAVA_VERSION: '21'
+  GRADLE_OPTS: '-Dorg.gradle.daemon=false -Dorg.gradle.parallel=true'
+
+jobs:
+  slt:
+    name: SLT Tests
+    runs-on: [self-hosted, caterpillar, caterpillar-runners]
+    timeout-minutes: 30  # Fail if SLT takes > 30 minutes
+
+    steps:
+      # ============================================================
+      # 1. Checkout and Setup
+      # ============================================================
+
+      - name: Checkout code
+        uses: actions/checkout@v4
+        with:
+          fetch-depth: 0  # Full history for better git metadata
+
+      - name: Set up JDK ${{ env.JAVA_VERSION }}
+        uses: actions/setup-java@v4
+        with:
+          distribution: 'temurin'
+          java-version: ${{ env.JAVA_VERSION }}
+          cache: 'gradle'
+
+      - name: Setup Python (for metrics script)
+        uses: actions/setup-python@v5
+        with:
+          python-version: '3.11'
+
+      # ============================================================
+      # 2. Docker Setup and Caching
+      # ============================================================
+
+      - name: Set up Docker Buildx
+        uses: docker/setup-buildx-action@v3
+
+      - name: Cache Docker images
+        uses: actions/cache@v4
+        with:
+          path: /tmp/.buildx-cache
+          key: ${{ runner.os }}-docker-${{ hashFiles('**/build.gradle') }}
+          restore-keys: |
+            ${{ runner.os }}-docker-
+
+      - name: Pull Docker images (Testcontainers)
+        run: |
+          echo "ğŸ“¦ Pre-pulling Docker images to speed up Testcontainers..."
+          docker pull mysql:8.0.33 &
+          docker pull redis:7.0-alpine &
+          docker pull localstack/localstack:4.0.3 &
+          wait
+          echo "âœ… Docker images pulled"
+
+      # ============================================================
+      # 3. Grant Permissions
+      # ============================================================
+
+      - name: Grant execute permissions
+        run: |
+          chmod +x gradlew
+          chmod +x run_slt.sh
+          chmod +x scripts/*.sh
+          chmod +x scripts/*.py
+
+      # ============================================================
+      # 4. Run SLT Tests
+      # ============================================================
+
+      - name: Run Service Level Tests
+        id: slt
+        run: |
+          echo "ğŸ§ª Running SLT tests..."
+          ./run_slt.sh
+        env:
+          # Docker configuration
+          DOCKER_HOST: unix:///var/run/docker.sock
+          # Testcontainers configuration
+          TESTCONTAINERS_RYUK_DISABLED: false
+          TESTCONTAINERS_CHECKS_DISABLE: false
+
+      # ============================================================
+      # 5. Generate Metrics and Reports
+      # ============================================================
+
+      - name: Generate Metrics JSON
+        if: always()
+        run: |
+          echo "ğŸ“Š Generating metrics JSON..."
+          python3 scripts/generate-metrics-json.py
+
+      - name: Generate Coverage Dashboard
+        if: always()
+        run: |
+          echo "ğŸ“ˆ Generating coverage dashboard..."
+          ./scripts/generate-coverage-dashboard.sh || echo "âš ï¸  Dashboard generation skipped"
+
+      # ============================================================
+      # 6. Upload to S3 (Conditional)
+      # ============================================================
+
+      - name: Upload Metrics to S3
+        if: |
+          always() &&
+          (github.event_name == 'push' ||
+           github.event_name == 'schedule' ||
+           github.event.inputs.upload_to_s3 == 'true')
+        env:
+          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
+          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
+          AWS_REGION: ap-south-1
+          S3_BUCKET: payments-slt-metrics-report
+          S3_PREFIX: instrument-stack
+          SERVICE_NAME: bin-atlas
+        run: |
+          echo "â˜ï¸  Uploading metrics to S3..."
+          ./scripts/upload-slt-metrics.sh
+
+      # ============================================================
+      # 7. Publish Reports
+      # ============================================================
+
+      - name: Publish Test Report
+        uses: dorny/test-reporter@v1
+        if: always()
+        with:
+          name: SLT Test Results
+          path: 'bin-server/build/test-results/test/*.xml'
+          reporter: java-junit
+          fail-on-error: false
+
+      - name: Publish JaCoCo Coverage Report
+        uses: codecov/codecov-action@v4
+        if: always()
+        with:
+          files: bin-server/build/reports/jacoco/test/jacocoTestReport.xml
+          flags: slt
+          name: slt-coverage
+          fail_ci_if_error: false
+
+      # ============================================================
+      # 8. Comment on PR with Results
+      # ============================================================
+
+      - name: Generate PR Comment
+        if: github.event_name == 'pull_request' && always()
+        id: pr-comment
+        run: |
+          if [ -f "bin-server/build/reports/slt-metrics/metrics.json" ]; then
+            python3 - <<'EOF'
+          import json
+          import os
+
+          # Read metrics
+          with open('bin-server/build/reports/slt-metrics/metrics.json', 'r') as f:
+              metrics = json.load(f)
+
+          # Determine status emoji
+          status_emoji = {
+              'stable': 'âœ…',
+              'unstable': 'âš ï¸',
+              'failing': 'âŒ'
+          }.get(metrics.get('stability', 'unknown'), 'â“')
+
+          # Build comment
+          comment = f"""## {status_emoji} SLT Test Results
+
+          **Status:** {metrics.get('stability', 'unknown').upper()} - {metrics.get('stability_reason', 'N/A')}
+
+          ### ğŸ“Š Test Summary
+          | Metric | Value |
+          |--------|-------|
+          | **Total Tests** | {metrics['tests']['total']} |
+          | **Passed** | âœ… {metrics['tests']['passed']} |
+          | **Failed** | âŒ {metrics['tests']['failed']} |
+          | **Success Rate** | {metrics['tests']['success_rate']}% |
+          | **Duration** | {metrics['tests']['duration_seconds']}s |
+
+          ### ğŸ¯ By Priority
+          | Priority | Total | Passed | Failed |
+          |----------|-------|--------|--------|
+          | **P0 (Sanity)** | {metrics['tests']['by_priority']['P0']['total']} | {metrics['tests']['by_priority']['P0']['passed']} | {metrics['tests']['by_priority']['P0']['failed']} |
+          | **P1 (Regression)** | {metrics['tests']['by_priority']['P1']['total']} | {metrics['tests']['by_priority']['P1']['passed']} | {metrics['tests']['by_priority']['P1']['failed']} |
+          | **P2 (Edge Cases)** | {metrics['tests']['by_priority']['P2']['total']} | {metrics['tests']['by_priority']['P2']['passed']} | {metrics['tests']['by_priority']['P2']['failed']} |
+
+          ### ğŸ“ˆ Coverage
+          | Type | Coverage |
+          |------|----------|
+          | **Instruction** | {metrics['coverage']['overall'].get('instruction', 0):.1f}% |
+          | **Branch** | {metrics['coverage']['overall'].get('branch', 0):.1f}% |
+          | **Line** | {metrics['coverage']['overall'].get('line', 0):.1f}% |
+          | **Method** | {metrics['coverage']['overall'].get('method', 0):.1f}% |
+
+          ### ğŸ“¦ Flows Tested
+          """
+
+          for flow, flow_data in metrics['tests'].get('by_flow', {}).items():
+              comment += f"- **{flow}**: {flow_data['passed']}/{flow_data['total']} passed\n"
+
+          comment += f"""
+          ---
+
+          *Generated by SLT GitHub Actions â€¢ Commit: `{metrics.get('commit_sha', 'unknown')[:8]}`*
+          """
+
+          # Write to file for GitHub Actions
+          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
+              # Escape newlines for GitHub Actions output
+              escaped_comment = comment.replace('%', '%25').replace('\n', '%0A').replace('\r', '%0D')
+              f.write(f"comment<<EOF\n{comment}\nEOF\n")
+
+          print("âœ… PR comment generated")
+          EOF
+          else
+            echo "âš ï¸  metrics.json not found, skipping PR comment"
+          fi
+
+      - name: Post PR Comment
+        if: github.event_name == 'pull_request' && always() && steps.pr-comment.outputs.comment != ''
+        uses: actions/github-script@v7
+        with:
+          script: |
+            github.rest.issues.createComment({
+              issue_number: context.issue.number,
+              owner: context.repo.owner,
+              repo: context.repo.repo,
+              body: `${{ steps.pr-comment.outputs.comment }}`
+            });
+
+      # ============================================================
+      # 9. Upload Artifacts
+      # ============================================================
+
+      - name: Upload Test Reports as Artifacts
+        uses: actions/upload-artifact@v4
+        if: always()
+        with:
+          name: slt-reports-${{ github.sha }}
+          path: |
+            bin-server/build/reports/tests/test/
+            bin-server/build/reports/jacoco/test/
+            bin-server/build/reports/slt-dashboard/
+            bin-server/build/reports/slt-metrics/
+          retention-days: 30
+
+      - name: Upload Test Case CSVs
+        uses: actions/upload-artifact@v4
+        if: always()
+        with:
+          name: test-cases-csv-${{ github.sha }}
+          path: |
+            bin-server/src/test/resources/testcases/*.csv
+          retention-days: 90
+
+      # ============================================================
+      # 10. Status Check Summary
+      # ============================================================
+
+      - name: Generate Summary
+        if: always()
+        run: |
+          echo "## ğŸ§ª SLT Test Execution Summary" >> $GITHUB_STEP_SUMMARY
+          echo "" >> $GITHUB_STEP_SUMMARY
+
+          if [ -f "bin-server/build/reports/slt-metrics/metrics.json" ]; then
+            python3 - <<'EOF' >> $GITHUB_STEP_SUMMARY
+          import json
+
+          with open('bin-server/build/reports/slt-metrics/metrics.json', 'r') as f:
+              metrics = json.load(f)
+
+          print(f"**Status:** {metrics.get('stability', 'unknown').upper()}")
+          print(f"**Total Tests:** {metrics['tests']['total']}")
+          print(f"**Passed:** {metrics['tests']['passed']}")
+          print(f"**Failed:** {metrics['tests']['failed']}")
+          print(f"**Success Rate:** {metrics['tests']['success_rate']}%")
+          print(f"**Coverage:** {metrics['coverage']['overall'].get('instruction', 0):.1f}%")
+          EOF
+          else
+            echo "âŒ Metrics not available" >> $GITHUB_STEP_SUMMARY
+          fi
+
+          echo "" >> $GITHUB_STEP_SUMMARY
+          echo "### ğŸ“ Artifacts" >> $GITHUB_STEP_SUMMARY
+          echo "- Test reports uploaded as artifacts" >> $GITHUB_STEP_SUMMARY
+          echo "- Coverage reports available in Codecov" >> $GITHUB_STEP_SUMMARY
+
+          if [ "${{ github.event_name }}" == "push" ] || [ "${{ github.event_name }}" == "schedule" ]; then
+            echo "- Metrics uploaded to S3: \`s3://payments-slt-metrics-report/instrument-stack/bin-atlas/\`" >> $GITHUB_STEP_SUMMARY
+          fi
+
+      # ============================================================
+      # 11. Fail Job if Critical Tests Failed
+      # ============================================================
+
+      - name: Check Critical Test Status
+        if: always()
+        run: |
+          if [ -f "bin-server/build/reports/slt-metrics/metrics.json" ]; then
+            python3 - <<'EOF'
+          import json
+          import sys
+
+          with open('bin-server/build/reports/slt-metrics/metrics.json', 'r') as f:
+              metrics = json.load(f)
+
+          stability = metrics.get('stability', 'unknown')
+          p0_failed = metrics['tests']['by_priority']['P0'].get('failed', 0)
+
+          if stability == 'failing' or p0_failed > 0:
+              print(f"âŒ CRITICAL: {p0_failed} P0 tests failed!")
+              print(f"Stability: {stability}")
+              sys.exit(1)
+          else:
+              print(f"âœ… All P0 tests passed")
+              print(f"Stability: {stability}")
+              sys.exit(0)
+          EOF
+          else
+            echo "âš ï¸  Could not verify test status"
+            exit 1
+          fi
+
+  # ============================================================
+  # Optional: Notification Job
+  # ============================================================
+
+  notify:
+    name: Notify Results
+    runs-on: [self-hosted, caterpillar, caterpillar-runners]
+    needs: slt
+    if: always() && (github.event_name == 'push' || github.event_name == 'schedule')
+
+    steps:
+      - name: Send Slack Notification
+        if: vars.SLACK_WEBHOOK_URL != ''
+        uses: slackapi/slack-github-action@v1
+        with:
+          payload: |
+            {
+              "text": "SLT Results for bin-atlas",
+              "blocks": [
+                {
+                  "type": "section",
+                  "text": {
+                    "type": "mrkdwn",
+                    "text": "*SLT Test Results - bin-atlas*\n\n*Status:* ${{ needs.slt.result }}\n*Branch:* `${{ github.ref_name }}`\n*Commit:* `${{ github.sha }}`\n*Triggered by:* ${{ github.event_name }}"
+                  }
+                },
+                {
+                  "type": "actions",
+                  "elements": [
+                    {
+                      "type": "button",
+                      "text": {
+                        "type": "plain_text",
+                        "text": "View Results"
+                      },
+                      "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
+                    }
+                  ]
+                }
+              ]
+            }
+        env:
+          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
+          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK
diff --git a/CENTRALIZED-DASHBOARD-TODO.md b/CENTRALIZED-DASHBOARD-TODO.md
new file mode 100644
index 00000000..6077cc96
--- /dev/null
+++ b/CENTRALIZED-DASHBOARD-TODO.md
@@ -0,0 +1,378 @@
+# ğŸ¯ Centralized Platform Dashboard - Future Enhancement
+
+**Status:** ğŸ“‹ Planned | **Priority:** P2 | **Estimated Effort:** 2-3 weeks
+
+---
+
+## ğŸ“ Overview
+
+Create a **centralized dashboard** that aggregates SLT metrics from all services across the platform into a single view for platform team visibility.
+
+---
+
+## ğŸ¯ Goal
+
+**Current State:**
+- Each service has its own isolated SLT dashboard
+- Metrics visible only in individual Jenkins builds
+- No platform-wide view of test coverage
+
+**Desired State:**
+- Single dashboard showing all services
+- Platform-level test coverage trends
+- Service comparison and ranking
+- Historical trend analysis
+- Alerts for coverage drops
+
+---
+
+## ğŸ—ï¸ Proposed Architecture
+
+### Option 1: S3-Based Approach (Recommended)
+
+```
+â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
+â”‚                  Individual Services                     â”‚
+â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
+â”‚  bin-atlas          payment-service      user-service   â”‚
+â”‚     â†“                     â†“                    â†“         â”‚
+â”‚  Jenkins Build      Jenkins Build        Jenkins Build  â”‚
+â”‚     â†“                     â†“                    â†“         â”‚
+â”‚  Generate JSON      Generate JSON        Generate JSON  â”‚
+â”‚  metrics.json       metrics.json         metrics.json   â”‚
+â”‚     â†“                     â†“                    â†“         â”‚
+â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+      â”‚                     â”‚                    â”‚
+      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+                            â†“
+               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
+               â”‚    AWS S3 Bucket       â”‚
+               â”‚  s3://platform-metrics â”‚
+               â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
+               â”‚  /slt/                 â”‚
+               â”‚    â”œâ”€â”€ bin-atlas/      â”‚
+               â”‚    â”‚     â””â”€â”€ metrics.json
+               â”‚    â”œâ”€â”€ payment/        â”‚
+               â”‚    â”‚     â””â”€â”€ metrics.json
+               â”‚    â””â”€â”€ user/           â”‚
+               â”‚          â””â”€â”€ metrics.json
+               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+                            â†“
+               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
+               â”‚  Centralized Dashboard â”‚
+               â”‚  (Static HTML + JS)    â”‚
+               â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
+               â”‚  - Fetches all JSONs   â”‚
+               â”‚  - Aggregates metrics  â”‚
+               â”‚  - Shows trends        â”‚
+               â”‚  - Service comparison  â”‚
+               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+                            â†“
+                    Hosted on S3 + CloudFront
+                    or Internal Server
+```
+
+---
+
+## ğŸ“Š JSON Metrics Schema
+
+Each service exports:
+
+```json
+{
+  "service": {
+    "name": "bin-atlas",
+    "type": "java-spring-boot",
+    "version": "0.0.1"
+  },
+  "build": {
+    "number": "42",
+    "branch": "develop",
+    "commit": "a1b2c3d",
+    "timestamp": "2026-01-21T10:30:00Z",
+    "pipeline": "slt"
+  },
+  "tests": {
+    "total": 32,
+    "passed": 32,
+    "failed": 0,
+    "successRate": 100,
+    "distribution": {
+      "p0": 8,
+      "p1": 11,
+      "p2": 13
+    }
+  },
+  "coverage": {
+    "service": {
+      "instruction": 88,
+      "branch": 88,
+      "line": 88,
+      "method": 88,
+      "class": 88
+    }
+  },
+  "modules": [
+    {"name": "core.service", "coverage": 76},
+    {"name": "ingress.controller", "coverage": 19}
+  ]
+}
+```
+
+---
+
+## ğŸ› ï¸ Implementation Steps
+
+### Phase 1: JSON Export (1 week)
+
+**Tasks:**
+1. âœ… Create `export-slt-metrics.sh` script
+2. âœ… Extract metrics from JaCoCo XML
+3. âœ… Generate standardized JSON
+4. âœ… Add to Jenkins pipeline
+5. âœ… Upload to S3 bucket
+6. âœ… Test with bin-atlas service
+
+**Deliverables:**
+- Script to export metrics as JSON
+- Jenkins stage to upload to S3
+- Sample JSON from bin-atlas
+
+### Phase 2: Centralized Dashboard (1-2 weeks)
+
+**Tasks:**
+1. Create dashboard HTML template
+2. Fetch all service JSONs from S3
+3. Aggregate and display metrics:
+   - Platform-wide coverage (average)
+   - Service ranking (by coverage)
+   - Test count comparison
+   - Success rate heatmap
+4. Add filters (service, date range, branch)
+5. Add charts:
+   - Platform coverage trend (line chart)
+   - Service comparison (bar chart)
+   - Test distribution (stacked bar)
+   - Success rate heatmap (grid)
+
+**Deliverables:**
+- Centralized dashboard HTML
+- S3 + CloudFront hosting
+- Access URL for platform team
+
+### Phase 3: Rollout to Services (Ongoing)
+
+**Tasks:**
+1. Document JSON export process
+2. Create onboarding guide for teams
+3. Rollout to 2-3 pilot services
+4. Gather feedback
+5. Iterate on dashboard features
+6. Rollout to all services
+
+---
+
+## ğŸ“‹ Required Components
+
+### 1. S3 Bucket Setup
+
+```bash
+# Create bucket
+aws s3 mb s3://platform-metrics --region ap-south-1
+
+# Set bucket policy (allow Jenkins to write)
+{
+  "Version": "2012-10-17",
+  "Statement": [
+    {
+      "Effect": "Allow",
+      "Principal": {"AWS": "arn:aws:iam::ACCOUNT:role/jenkins-role"},
+      "Action": ["s3:PutObject", "s3:GetObject"],
+      "Resource": "arn:aws:s3:::platform-metrics/slt/*"
+    }
+  ]
+}
+
+# Enable versioning (optional)
+aws s3api put-bucket-versioning \
+    --bucket platform-metrics \
+    --versioning-configuration Status=Enabled
+```
+
+### 2. Jenkins Pipeline Addition
+
+```groovy
+stage('export-slt-metrics') {
+    steps {
+        sh './export-slt-metrics.sh'
+
+        // Upload to S3
+        sh '''
+            aws s3 cp bin-server/build/reports/slt-metrics/metrics.json \
+                s3://platform-metrics/slt/${SERVICE_NAME}/metrics.json \
+                --content-type application/json \
+                --metadata build=${BUILD_NUMBER},branch=${GIT_BRANCH}
+        '''
+    }
+}
+```
+
+### 3. Centralized Dashboard Features
+
+**MVP Features:**
+- List all services with coverage %
+- Platform average coverage
+- Last updated timestamp
+- Link to individual dashboards
+- Simple search/filter
+
+**Advanced Features (Later):**
+- Historical trends (last 30 days)
+- Coverage goals and alerts
+- Service health score
+- Team ownership mapping
+- Email digests (weekly summary)
+
+---
+
+## ğŸ¨ Dashboard Mockup
+
+```
+â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
+â”‚  ğŸ¯ Platform SLT Coverage Dashboard                     â”‚
+â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
+â”‚                                                          â”‚
+â”‚  Platform Average: 72%  â†‘ 3%  Last 7 days              â”‚
+â”‚                                                          â”‚
+â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
+â”‚  â”‚ Total       â”‚  â”‚ Services    â”‚  â”‚ Avg Tests   â”‚    â”‚
+â”‚  â”‚ Coverage    â”‚  â”‚ Tracked     â”‚  â”‚ Per Service â”‚    â”‚
+â”‚  â”‚   72%       â”‚  â”‚    15       â”‚  â”‚     28      â”‚    â”‚
+â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
+â”‚                                                          â”‚
+â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
+â”‚  â”‚  Service Ranking                                   â”‚ â”‚
+â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
+â”‚  â”‚  ğŸ¥‡ bin-atlas           88%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘  32 tests â”‚ â”‚
+â”‚  â”‚  ğŸ¥ˆ payment-service     82%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘  45 tests â”‚ â”‚
+â”‚  â”‚  ğŸ¥‰ user-service        76%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘  38 tests â”‚ â”‚
+â”‚  â”‚  4ï¸âƒ£  auth-service        65%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘  22 tests â”‚ â”‚
+â”‚  â”‚  5ï¸âƒ£  notification-svc    58%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  18 tests â”‚ â”‚
+â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
+â”‚                                                          â”‚
+â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
+â”‚  â”‚  Coverage Trend (Last 30 Days)                     â”‚ â”‚
+â”‚  â”‚  [Line Chart showing platform average trend]       â”‚ â”‚
+â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
+â”‚                                                          â”‚
+â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+```
+
+---
+
+## âš™ï¸ Configuration Requirements
+
+### Environment Variables
+```bash
+# S3 bucket for metrics
+METRICS_S3_BUCKET=platform-metrics
+
+# Service name (each service sets this)
+SERVICE_NAME=bin-atlas
+
+# Optional: Metrics retention days
+METRICS_RETENTION_DAYS=90
+```
+
+### Jenkins Requirements
+- AWS CLI installed in Docker image
+- IAM role with S3 write permissions
+- Service name environment variable
+
+---
+
+## ğŸ“Š Benefits
+
+1. **Platform Visibility**
+   - See all services at a glance
+   - Identify low-coverage services
+   - Track platform-wide trends
+
+2. **Team Accountability**
+   - Service ranking encourages healthy competition
+   - Clear visibility of test quality
+   - Easy to spot services needing help
+
+3. **Leadership Insights**
+   - Platform health score
+   - Resource allocation decisions
+   - Quality metrics for reporting
+
+4. **Developer Experience**
+   - Easy to compare with other services
+   - Learn from high-coverage services
+   - Centralized documentation
+
+---
+
+## ğŸš§ Risks & Mitigations
+
+| Risk | Mitigation |
+|------|------------|
+| Services not adopting JSON export | Make it part of CI/CD template |
+| S3 costs | Set lifecycle policy (30-day retention) |
+| Dashboard performance (many services) | Implement pagination, caching |
+| JSON schema changes | Version API, support backward compatibility |
+| Access control | Use IAM roles, integrate with SSO |
+
+---
+
+## ğŸ“… Timeline
+
+| Phase | Duration | Deliverable |
+|-------|----------|-------------|
+| Design & Approval | 1 week | Architecture doc, mockups |
+| JSON Export Script | 1 week | Working export for bin-atlas |
+| Dashboard MVP | 2 weeks | Basic centralized dashboard |
+| Pilot Rollout | 2 weeks | 3 services integrated |
+| Full Rollout | 4 weeks | All services onboarded |
+
+**Total Estimated Time:** 8-10 weeks
+
+---
+
+## âœ… Definition of Done
+
+- [ ] JSON export script created and tested
+- [ ] S3 bucket configured with proper permissions
+- [ ] Centralized dashboard deployed and accessible
+- [ ] 3 pilot services successfully integrated
+- [ ] Documentation for service teams complete
+- [ ] Runbook for dashboard maintenance created
+- [ ] Alerts configured for coverage drops
+- [ ] Demo presented to platform team
+
+---
+
+## ğŸ“ Stakeholders
+
+- **Owner:** CSIT Team
+- **Contributors:** Service teams
+- **Consumers:** Platform team, Engineering managers
+- **Approvers:** CSIT Lead, Platform Architect
+
+---
+
+## ğŸ”— References
+
+- Current Implementation: `bin-atlas/SLT-IMPLEMENTATION-GUIDE.md`
+- Individual Dashboard: `bin-atlas/SLT-ONE-PAGER.md`
+- AWS S3 Docs: https://docs.aws.amazon.com/s3/
+- Chart.js: https://www.chartjs.org/
+
+---
+
+**Status:** ğŸ“‹ Planned
+**Next Step:** Get approval from platform team
+**Created:** 2026-01-21
+**Owner:** Sourav Singh (CSIT)
diff --git a/SLT-IMPLEMENTATION-GUIDE.md b/SLT-IMPLEMENTATION-GUIDE.md
new file mode 100644
index 00000000..dfd9557c
--- /dev/null
+++ b/SLT-IMPLEMENTATION-GUIDE.md
@@ -0,0 +1,1958 @@
+# Service Level Tests (SLT) - Complete Implementation Guide
+
+**Comprehensive guide for implementing SLT in any Java service (Spring Boot / Dropwizard)**
+
+---
+
+## Table of Contents
+
+1. [Overview](#overview)
+2. [High-Level Architecture](#high-level-architecture)
+3. [Prerequisites](#prerequisites)
+4. [Quick Start (30 Minutes)](#quick-start-30-minutes)
+5. [SLT Implementer Agent (Automated Setup)](#slt-implementer-agent-automated-setup)
+6. [Framework-Specific Setup](#framework-specific-setup)
+7. [Infrastructure Components](#infrastructure-components)
+8. [Code Templates](#code-templates)
+9. [CI/CD Integration](#cicd-integration)
+10. [Visual Dashboard & Reporting](#visual-dashboard--reporting)
+11. [Running Tests](#running-tests)
+12. [Troubleshooting](#troubleshooting)
+13. [Best Practices](#best-practices)
+14. [Centralized Metrics & S3 Publishing](#centralized-metrics--s3-publishing)
+
+---
+
+## Overview
+
+### What are SLT Tests?
+
+**Service Level Tests (SLT)** are end-to-end integration tests that:
+- Start your **complete application** (Spring Boot / Dropwizard)
+- Use **real infrastructure** via **Testcontainers** (MySQL, Redis, SQS, DynamoDB, S3, etc.)
+- Test **actual API endpoints** with HTTP calls (RestAssured / OkHttp)
+- Run against **real databases and AWS services** (not mocks)
+- Contribute to **code coverage** metrics (JaCoCo / SonarQube)
+- Execute in **CI/CD pipelines** automatically
+
+### Why SLT?
+
+| Benefit | Description |
+|---------|-------------|
+| âœ… **Catch Integration Bugs** | Find database, cache, messaging issues before production |
+| âœ… **Realistic Testing** | Tests against actual MySQL, Redis, SQS, DynamoDB |
+| âœ… **Less Brittle** | More maintainable than heavy mocking |
+| âœ… **Coverage Metrics** | Counts towards SonarQube and JaCoCo |
+| âœ… **CI/CD Ready** | Auto-runs in Jenkins with visual dashboards |
+
+---
+
+## High-Level Architecture
+
+### System Overview
+
+```
+â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
+â”‚          Your Application (Test Profile)            â”‚
+â”‚    (Spring Boot / Dropwizard on Random Port)        â”‚
+â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+                 â”‚
+          â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
+          â”‚             â”‚
+          â–¼             â–¼
+    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
+    â”‚ HTTP     â”‚   â”‚ JUnit 5  â”‚
+    â”‚ Client   â”‚   â”‚ Tests    â”‚
+    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+          â”‚
+          â–¼
+â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
+â”‚            Testcontainers (Docker)                  â”‚
+â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
+â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
+â”‚  â”‚ MySQL    â”‚  â”‚ Redis  â”‚  â”‚  LocalStack      â”‚   â”‚
+â”‚  â”‚ 8.0.33   â”‚  â”‚ 7.0    â”‚  â”‚  4.0.3           â”‚   â”‚
+â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
+â”‚                                  â”‚                  â”‚
+â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
+â”‚                        â”‚ SQSâ”‚DynamoDBâ”‚S3â”‚SNSâ”‚     â”‚
+â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
+â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+```
+
+### Test Execution Flow
+
+1. **JUnit 5** starts test class with `@SpringBootTest` or Dropwizard test annotation
+2. **Testcontainers** starts Docker containers (MySQL, Redis, LocalStack, etc.)
+3. **Dynamic Properties** inject container URLs into application config
+4. **Application** starts with test profile on random port
+5. **HTTP Client** (RestAssured/OkHttp) makes API calls
+6. **Assertions** validate responses
+7. **Cleanup** resets database/cache for next test
+8. **JaCoCo** collects coverage metrics
+
+---
+
+## Prerequisites
+
+### Local Development
+
+| Requirement | Version | Purpose |
+|-------------|---------|---------|
+| **Docker** | Latest | Runs Testcontainers |
+| **Java** | 11+ (21 recommended) | Application runtime |
+| **Gradle/Maven** | 8.5+ / 3.9+ | Build tool |
+| **Git** | Any | Version control |
+
+### Docker Options
+
+Choose one:
+- **Docker Desktop** (macOS/Windows/Linux)
+- **Rancher Desktop** (macOS/Linux) - Kubernetes + Docker
+- **Colima** (macOS/Linux) - Lightweight Docker
+
+### System Requirements
+
+- **RAM:** 8GB minimum, 16GB recommended
+- **Docker Memory Allocation:** 4GB minimum, 8GB recommended
+- **Disk Space:** 10GB for Docker images
+- **Network:** Internet for first run (downloads images)
+
+---
+
+## Quick Start (30 Minutes)
+
+### Step 1: Add Dependencies (5 min)
+
+#### Gradle (build.gradle)
+
+```gradle
+dependencies {
+    // Testcontainers Core
+    testImplementation 'org.testcontainers:testcontainers:1.19.3'
+    testImplementation 'org.testcontainers:junit-jupiter:1.19.3'
+
+    // Infrastructure Containers
+    testImplementation 'org.testcontainers:mysql:1.19.3'          // MySQL
+    testImplementation 'org.testcontainers:postgresql:1.19.3'     // PostgreSQL (alternative)
+    testImplementation 'org.testcontainers:localstack:1.19.3'     // AWS services
+    testImplementation 'org.testcontainers:kafka:1.19.3'          // Kafka (if needed)
+    testImplementation 'org.testcontainers:mongodb:1.19.3'        // MongoDB (if needed)
+
+    // HTTP Testing
+    testImplementation 'io.rest-assured:rest-assured:5.3.2'       // RestAssured (recommended)
+    testImplementation 'com.squareup.okhttp3:okhttp:4.12.0'      // OkHttp (alternative)
+
+    // AWS SDK (for LocalStack)
+    testImplementation 'software.amazon.awssdk:sqs:2.20.0'       // SQS
+    testImplementation 'software.amazon.awssdk:dynamodb:2.20.0'  // DynamoDB
+    testImplementation 'software.amazon.awssdk:s3:2.20.0'        // S3
+    testImplementation 'software.amazon.awssdk:sns:2.20.0'       // SNS
+
+    // Spring Boot Test (if using Spring Boot)
+    testImplementation 'org.springframework.boot:spring-boot-starter-test'
+    testImplementation 'org.springframework.boot:spring-boot-testcontainers'
+}
+
+// JaCoCo for coverage
+plugins {
+    id 'jacoco'
+}
+
+jacoco {
+    toolVersion = "0.8.11"
+}
+
+test {
+    useJUnitPlatform()
+    finalizedBy jacocoTestReport
+}
+
+jacocoTestReport {
+    dependsOn test
+    reports {
+        xml.required = true
+        html.required = true
+        xml.outputLocation = file("${buildDir}/reports/jacoco/test/jacocoTestReport.xml")
+        html.outputLocation = file("${buildDir}/reports/jacoco/test/html")
+    }
+}
+```
+
+#### Maven (pom.xml)
+
+```xml
+<dependencies>
+    <!-- Testcontainers -->
+    <dependency>
+        <groupId>org.testcontainers</groupId>
+        <artifactId>testcontainers</artifactId>
+        <version>1.19.3</version>
+        <scope>test</scope>
+    </dependency>
+    <dependency>
+        <groupId>org.testcontainers</groupId>
+        <artifactId>junit-jupiter</artifactId>
+        <version>1.19.3</version>
+        <scope>test</scope>
+    </dependency>
+    <dependency>
+        <groupId>org.testcontainers</groupId>
+        <artifactId>mysql</artifactId>
+        <version>1.19.3</version>
+        <scope>test</scope>
+    </dependency>
+    <dependency>
+        <groupId>org.testcontainers</groupId>
+        <artifactId>localstack</artifactId>
+        <version>1.19.3</version>
+        <scope>test</scope>
+    </dependency>
+
+    <!-- HTTP Testing -->
+    <dependency>
+        <groupId>io.rest-assured</groupId>
+        <artifactId>rest-assured</artifactId>
+        <version>5.3.2</version>
+        <scope>test</scope>
+    </dependency>
+
+    <!-- AWS SDK -->
+    <dependency>
+        <groupId>software.amazon.awssdk</groupId>
+        <artifactId>sqs</artifactId>
+        <version>2.20.0</version>
+        <scope>test</scope>
+    </dependency>
+</dependencies>
+
+<build>
+    <plugins>
+        <plugin>
+            <groupId>org.jacoco</groupId>
+            <artifactId>jacoco-maven-plugin</artifactId>
+            <version>0.8.11</version>
+            <executions>
+                <execution>
+                    <goals>
+                        <goal>prepare-agent</goal>
+                    </goals>
+                </execution>
+                <execution>
+                    <id>report</id>
+                    <phase>test</phase>
+                    <goals>
+                        <goal>report</goal>
+                    </goals>
+                </execution>
+            </executions>
+        </plugin>
+    </plugins>
+</build>
+```
+
+### Step 2: Create Directory Structure (2 min)
+
+```bash
+mkdir -p src/test/java/your/package/slt
+mkdir -p src/test/java/your/package/slt/util
+mkdir -p src/test/java/your/package/slt/config
+mkdir -p src/test/resources
+mkdir -p scripts
+```
+
+### Step 3: Choose Your Framework (see next section)
+
+- [Spring Boot Setup](#spring-boot-setup)
+- [Dropwizard Setup](#dropwizard-setup)
+
+---
+
+## SLT Implementer Agent (Automated Setup)
+
+### Overview
+
+The **SLT Implementer Agent** is an AI-powered assistant that automates the entire SLT implementation process following bin-atlas patterns and best practices. It generates test cases in CSV format, gets your approval, then implements the tests automatically.
+
+**Key Features:**
+- ğŸ¤– **Automated Setup**: Bootstrap complete SLT infrastructure from scratch
+- ğŸ“‹ **CSV-Driven Development**: Generate test cases first, implement after approval
+- âœ… **Review Gate**: Mandatory approval before code implementation
+- ğŸ¯ **One Flow at a Time**: Focus on single API endpoint or business flow
+- ğŸ“Š **Metrics Publishing**: Optional S3 upload for centralized dashboard
+- ğŸ”§ **Framework Support**: Spring Boot and Dropwizard
+- ğŸŒ¿ **Git Integration**: Create PR or commit to current branch
+
+### Prerequisites
+
+- **Claude Code CLI** installed and configured
+- **Docker** running (for Testcontainers)
+- **Java 11+** and **Gradle/Maven**
+- **Repository access** with write permissions
+
+### Installation
+
+#### Step 1: Obtain the Agent File
+
+Contact your team lead or CSIT team to get the `slt-implementer.md` agent file.
+
+**Slack:** `#csit` or `#payments_slt_report_and_coverage`
+
+#### Step 2: Add to Your Repository
+
+Copy the agent file to your repository's `.claude/commands/` directory:
+
+```bash
+# Create directory if it doesn't exist
+mkdir -p .claude/commands
+
+# Copy the agent file (obtain from team lead)
+cp /path/to/slt-implementer.md .claude/commands/
+
+# Verify it's added
+ls -la .claude/commands/slt-implementer.md
+```
+
+#### Step 3: Verify Agent is Available
+
+Open Claude Code and check if the agent is available:
+
+```bash
+# List all available agents
+claude help
+
+# You should see:
+# /slt-implementer - SLT implementation agent for merchant payment services
+```
+
+### Usage
+
+The agent has **two modes**:
+
+#### Mode 1: Setup (First Time)
+
+Use this when your service **does not have SLT** infrastructure yet.
+
+```bash
+/slt-implementer setup
+```
+
+**What it does:**
+1. Detects your framework (Spring Boot or Dropwizard)
+2. Adds required dependencies (Testcontainers, RestAssured, JaCoCo)
+3. Creates `BaseIntegrationTest.java` with container setup
+4. Creates test utilities and helper classes
+5. Configures test profiles (application-test.properties or test-config.yml)
+6. Adds scripts (run_slt.sh, generate-metrics-json.py, upload-slt-metrics.sh)
+7. Creates directory structure for test cases
+
+**Example:**
+```bash
+$ /slt-implementer setup
+
+ğŸ“‹ SLT Setup Mode - Bootstrapping Infrastructure
+â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+
+ğŸ” Detected Framework: Spring Boot
+ğŸ“¦ Adding dependencies to build.gradle...
+âœ… Dependencies added
+
+ğŸ“ Creating directory structure...
+âœ… Created: src/test/java/com/yourservice/slt
+âœ… Created: src/test/java/com/yourservice/slt/util
+âœ… Created: src/test/resources/testcases
+
+ğŸ“ Creating BaseIntegrationTest.java...
+âœ… Created: src/test/java/com/yourservice/slt/BaseIntegrationTest.java
+
+ğŸ”§ Creating test configuration...
+âœ… Created: src/test/resources/application-test.properties
+
+ğŸ“œ Creating utility scripts...
+âœ… Created: run_slt.sh
+âœ… Created: scripts/generate-metrics-json.py
+âœ… Created: scripts/upload-slt-metrics.sh
+
+âœ… SLT Infrastructure Setup Complete!
+
+Next steps:
+  1. Run setup tests: ./run_slt.sh
+  2. Add your first flow: /slt-implementer <flow-name>
+```
+
+#### Mode 2: Implement (Add SLT for a Flow)
+
+Use this when adding SLT tests for a **specific API endpoint or business flow**.
+
+```bash
+/slt-implementer <flow-name>
+```
+
+**Example:**
+```bash
+$ /slt-implementer bin-lookup-api
+
+ğŸ“‹ SLT Implementation Mode - bin-lookup-api
+â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+
+ğŸ‘¤ Who is the author of these test cases?
+   (This will be used in CSV and code comments)
+
+> Sourav Singh
+
+âœ… Author: Sourav Singh
+
+ğŸ” Researching flow: bin-lookup-api
+   Analyzing: BinController.java
+   Analyzing: BinService.java
+   Analyzing: BinLookupResponse.java
+
+ğŸ“‹ Generating CSV Test Cases...
+   âœ… Generated 45 test cases
+
+   P0 (Sanity): 8 tests
+   P1 (Regression): 24 tests
+   P2 (Edge Cases): 13 tests
+
+â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+âš ï¸  REVIEW REQUIRED - WORKFLOW PAUSED
+â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+
+ğŸ“‹ ITEM FOR REVIEW: CSV Test Cases
+
+File: src/test/resources/testcases/bin_lookup_api.csv
+
+Preview (first 5 rows):
+â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
+â”‚ Title                                       â”‚ Priority      â”‚ Author   â”‚
+â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
+â”‚ BIN_LOOKUP_001 - Valid VISA BIN Returns    â”‚ P0            â”‚ Sourav   â”‚
+â”‚ BIN_LOOKUP_002 - Valid Mastercard BIN      â”‚ P0            â”‚ Sourav   â”‚
+â”‚ BIN_LOOKUP_003 - Valid RuPay BIN           â”‚ P0            â”‚ Sourav   â”‚
+â”‚ BIN_LOOKUP_004 - Valid BIN with READ       â”‚ P0            â”‚ Sourav   â”‚
+â”‚ BIN_LOOKUP_005 - Valid BIN with ADMIN      â”‚ P0            â”‚ Sourav   â”‚
+â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+
+ğŸ”´ NEXT STEPS:
+   - If approved: Type "approved" or "proceed"
+   - If changes needed: Provide your feedback
+   - If rejected: Type "stop" or "cancel"
+
+â›” I will NOT proceed to the next phase until you confirm.
+â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+
+> approved
+
+âœ… CSV Approved - Proceeding to Implementation
+
+ğŸ“ Creating Test Class: BinLookupApiSLT.java
+   âœ… Implementing P0 tests (8)
+   âœ… Implementing P1 tests (24)
+   âœ… Implementing P2 tests (13)
+
+âœ… Created: src/test/java/com/yourservice/slt/BinLookupApiSLT.java
+
+ğŸ§ª Running tests to verify...
+   ./gradlew test --tests "*BinLookupApiSLT"
+
+âœ… All 45 tests passed!
+
+ğŸ“Š Coverage: 78.5% instruction coverage
+
+ğŸŒ¿ Git Operations
+â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
+   Would you like to:
+   1. Create a new branch and commit
+   2. Commit to current branch
+   3. Skip git operations
+
+> 1
+
+Branch name? (default: feature/slt-bin-lookup-api)
+> feature/slt-bin-lookup-api
+
+âœ… Created branch: feature/slt-bin-lookup-api
+âœ… Committed: Add SLT tests for bin-lookup-api (45 tests)
+
+ğŸ‰ Implementation Complete!
+
+Summary:
+  âœ… CSV Test Cases: 45
+  âœ… Tests Implemented: 45
+  âœ… Tests Passing: 45
+  âœ… Coverage: 78.5%
+  âœ… Branch: feature/slt-bin-lookup-api
+
+Next steps:
+  â†’ Run tests locally: ./run_slt.sh
+  â†’ Push branch: git push -u origin feature/slt-bin-lookup-api
+  â†’ Create PR and add reviewers
+```
+
+### Workflow Example (Complete Flow)
+
+**Scenario:** Adding SLT for "merchant-onboarding" API flow
+
+```bash
+# 1. Start the agent
+$ /slt-implementer merchant-onboarding
+
+# Agent asks for author name
+> John Doe
+
+# 2. Agent researches the flow
+# - Reads MerchantController.java
+# - Reads MerchantService.java
+# - Reads related request/response models
+
+# 3. Agent generates CSV test cases
+# - Creates src/test/resources/testcases/merchant_onboarding.csv
+# - 35 test cases (P0: 6, P1: 18, P2: 11)
+
+# 4. Review Gate - You review the CSV
+# - Check test case titles
+# - Verify steps and expected results
+# - Ensure all scenarios covered
+
+> approved
+
+# 5. Agent implements tests
+# - Creates MerchantOnboardingSLT.java
+# - Implements all 35 test methods
+# - Follows bin-atlas patterns
+
+# 6. Agent runs tests to verify
+# - All 35 tests pass
+# - Coverage: 82.3%
+
+# 7. Git operations
+> 1 (Create new branch)
+> feature/slt-merchant-onboarding
+
+# 8. Done!
+# - Branch created
+# - Changes committed
+# - Ready to push and create PR
+```
+
+### Agent Capabilities
+
+#### Automatic Detection
+- **Framework**: Spring Boot or Dropwizard
+- **Build Tool**: Gradle or Maven
+- **Service Name**: From git remote or directory
+- **Existing Infrastructure**: Detects if SLT already exists
+
+#### Code Generation
+- **BaseIntegrationTest**: Testcontainers setup (MySQL, Redis, LocalStack)
+- **Test Classes**: RestAssured-based test methods
+- **Test Utilities**: Helper classes for common operations
+- **Scripts**: run_slt.sh, generate-metrics-json.py, upload-slt-metrics.sh
+
+#### CSV Test Cases
+- **Automatic Generation**: Based on code analysis
+- **Complete Fields**: Title, Steps, Expected Result, Priority, Author, References
+- **Code References**: Includes file paths and line numbers
+- **Priority Assignment**: P0 (critical), P1 (important), P2 (edge cases)
+
+#### Validation
+- **Pre-implementation**: Runs tests to verify they compile
+- **Post-implementation**: Runs tests to verify they pass
+- **Coverage Check**: Reports instruction coverage percentage
+
+### Configuration Options
+
+#### Environment Variables
+
+```bash
+# Override service name
+export SERVICE_NAME=my-service
+
+# Enable S3 upload by default
+export UPLOAD_TO_S3=true
+
+# Override S3 bucket
+export S3_BUCKET=my-bucket
+
+# Override author (if not prompted)
+export TEST_AUTHOR="Your Name"
+```
+
+#### Agent Behavior
+
+The agent will:
+- âœ… **Always ask for author name** before generating CSV
+- âœ… **Always pause for CSV review** before implementation
+- âœ… **Always run tests** to verify they work
+- âœ… **Always ask about git operations** before committing
+- âŒ **Never proceed without approval** at review gates
+- âŒ **Never skip test execution** verification
+
+### Best Practices
+
+#### 1. One Flow at a Time
+âœ… **DO:**
+```bash
+/slt-implementer user-authentication
+/slt-implementer payment-processing
+/slt-implementer order-management
+```
+
+âŒ **DON'T:**
+```bash
+/slt-implementer all-apis  # Too broad
+```
+
+#### 2. Review CSV Carefully
+Before approving CSV test cases, verify:
+- âœ… All critical scenarios covered (P0)
+- âœ… Error handling scenarios included (P1)
+- âœ… Edge cases and boundaries tested (P2)
+- âœ… Steps are clear and actionable
+- âœ… Expected results are specific
+- âœ… Code references are accurate
+
+#### 3. Run Tests After Implementation
+```bash
+# Run specific flow tests
+./run_slt.sh
+
+# View coverage report
+open build/reports/slt-dashboard/index.html
+```
+
+#### 4. Commit Gradually
+Add SLT tests **one flow at a time** and commit after each flow:
+- âœ… Easier code review
+- âœ… Better git history
+- âœ… Incremental progress tracking
+
+### Troubleshooting
+
+#### Agent Not Found
+
+**Issue:** `/slt-implementer` command not recognized
+
+**Solution:**
+```bash
+# Check if file exists
+ls -la .claude/commands/slt-implementer.md
+
+# If missing, copy from team lead
+cp /path/to/slt-implementer.md .claude/commands/
+
+# Restart Claude Code
+```
+
+#### CSV Review Stuck
+
+**Issue:** Agent waiting for CSV approval
+
+**Solution:**
+- Type `approved` to proceed
+- Type `rejected` to stop
+- Provide specific feedback for changes
+
+#### Tests Fail After Implementation
+
+**Issue:** Generated tests don't pass
+
+**Solution:**
+1. Check Docker is running: `docker ps`
+2. Check test dependencies: `./gradlew dependencies`
+3. Review test output for specific errors
+4. Ask agent to fix: Provide error message to agent
+
+#### Git Operations Fail
+
+**Issue:** Cannot create branch or commit
+
+**Solution:**
+```bash
+# Check git status
+git status
+
+# Ensure working directory is clean
+git stash
+
+# Try again
+```
+
+### S3 Metrics Publishing
+
+#### Automatic Upload (Jenkins)
+
+Metrics are automatically uploaded in Jenkins pipeline (no configuration needed).
+
+#### Manual Upload (Local)
+
+```bash
+# Run tests with S3 upload
+./run_slt.sh --upload-s3
+
+# Or run separately
+python3 scripts/generate-metrics-json.py
+./scripts/upload-slt-metrics.sh
+```
+
+#### Prerequisites for S3 Upload
+
+```bash
+# Install AWS CLI
+brew install awscli  # macOS
+# OR
+pip install awscli   # Python
+
+# Configure AWS credentials
+aws configure
+```
+
+### Support
+
+#### Getting Help
+
+- **Slack**: `#csit` or `#payments_slt_report_and_coverage`
+- **Documentation**: This guide + bin-atlas examples
+- **Team**: CSIT (Sourav Singh)
+
+#### Example Repositories
+
+Reference implementations:
+- **bin-atlas** - Complete SLT setup with 45 test cases
+- See: `/Desktop/bin-atlas/bin-server/src/test/java/in/dreamplug/bin/slt/`
+
+#### Common Questions
+
+**Q: Can I use this for non-merchant-payment services?**
+A: Yes, but it's optimized for merchant payment patterns. May need customization.
+
+**Q: Does it work with existing test infrastructure?**
+A: Yes, it detects existing SLT setup and adds new flows incrementally.
+
+**Q: Can I modify generated test cases?**
+A: Yes, generated code is standard Java/RestAssured. Modify as needed.
+
+**Q: How long does implementation take?**
+A: 10-20 minutes per flow (including CSV review and implementation).
+
+---
+
+## Framework-Specific Setup
+
+### Spring Boot Setup
+
+#### Test Configuration
+
+**File:** `src/test/resources/application-test.properties`
+
+```properties
+# Server
+server.port=0
+spring.main.banner-mode=off
+
+# Database (overridden by @DynamicPropertySource)
+spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
+spring.jpa.hibernate.ddl-auto=none
+spring.jpa.show-sql=false
+
+# Redis (overridden by @DynamicPropertySource)
+spring.redis.host=localhost
+spring.redis.port=6379
+
+# AWS (overridden by @DynamicPropertySource)
+aws.sqs.enabled=true
+aws.dynamodb.enabled=true
+aws.s3.enabled=true
+
+# Disable features not needed in tests
+scheduler.enabled=false
+management.metrics.export.cloudwatch.enabled=false
+logging.level.org.testcontainers=INFO
+```
+
+#### Base Integration Test
+
+**File:** `src/test/java/your/package/slt/BaseIntegrationTest.java`
+
+```java
+package your.package.slt;
+
+import org.junit.jupiter.api.AfterEach;
+import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Test;
+import org.springframework.boot.test.context.SpringBootTest;
+import org.springframework.boot.test.web.server.LocalServerPort;
+import org.springframework.test.context.ActiveProfiles;
+import org.springframework.test.context.DynamicPropertyRegistry;
+import org.springframework.test.context.DynamicPropertySource;
+import org.testcontainers.containers.GenericContainer;
+import org.testcontainers.containers.MySQLContainer;
+import org.testcontainers.containers.localstack.LocalStackContainer;
+import org.testcontainers.junit.jupiter.Container;
+import org.testcontainers.junit.jupiter.Testcontainers;
+import org.testcontainers.utility.DockerImageName;
+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;
+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;
+import software.amazon.awssdk.regions.Region;
+import software.amazon.awssdk.services.sqs.SqsClient;
+
+import static org.junit.jupiter.api.Assertions.assertTrue;
+import static org.testcontainers.containers.localstack.LocalStackContainer.Service.*;
+
+/**
+ * Base class for all SLT (Service Level Tests).
+ * Provides real infrastructure via Testcontainers.
+ */
+@SpringBootTest(
+    classes = YourApplication.class,
+    webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT
+)
+@ActiveProfiles("test")
+@Testcontainers
+public abstract class BaseIntegrationTest {
+
+    @LocalServerPort
+    protected int port;
+
+    protected String getBaseUrl() {
+        return "http://localhost:" + port + "/your-context-path";
+    }
+
+    // ==================== Containers ====================
+
+    @Container
+    private static final MySQLContainer<?> mySqlContainer = createMySqlContainer();
+
+    @Container
+    private static final GenericContainer<?> redisContainer = createRedisContainer();
+
+    @Container
+    static LocalStackContainer localstack = new LocalStackContainer(
+        DockerImageName.parse("localstack/localstack:4.0.3")
+    )
+    .withServices(SQS, DYNAMODB, S3, SNS);
+
+    protected static SqsClient sqsClient;
+    protected static String testQueueUrl;
+
+    // ==================== Container Creation ====================
+
+    private static MySQLContainer<?> createMySqlContainer() {
+        return new MySQLContainer<>("mysql:8.0.33")
+            .withDatabaseName("test_db")
+            .withUsername("test")
+            .withPassword("test")
+            .withExposedPorts(3306)
+            .withInitScript("init.sql")
+            .withReuse(false);  // Set to true for local dev (faster)
+    }
+
+    private static GenericContainer<?> createRedisContainer() {
+        return new GenericContainer<>("redis:7.0-alpine")
+            .withExposedPorts(6379)
+            .withReuse(false);
+    }
+
+    // ==================== Lifecycle ====================
+
+    @BeforeAll
+    static void beforeAll() throws Exception {
+        mySqlContainer.start();
+        redisContainer.start();
+        localstack.start();
+
+        // Initialize SQS Client
+        String sqsEndpoint = localstack.getEndpointOverride(SQS).toString();
+        sqsClient = SqsClient.builder()
+            .endpointOverride(java.net.URI.create(sqsEndpoint))
+            .region(Region.AP_SOUTH_1)
+            .credentialsProvider(
+                StaticCredentialsProvider.create(
+                    AwsBasicCredentials.create("test", "test")
+                )
+            )
+            .build();
+
+        // Create test SQS queue
+        localstack.execInContainer("awslocal", "sqs", "create-queue",
+            "--queue-name", "test-queue", "--region", "ap-south-1");
+        testQueueUrl = sqsEndpoint + "/000000000000/test-queue";
+    }
+
+    @AfterEach
+    public void cleanUp() {
+        cleanUpDatabase();
+        cleanUpRedis();
+    }
+
+    private void cleanUpDatabase() {
+        try {
+            mySqlContainer.execInContainer("mysql",
+                "-u" + mySqlContainer.getUsername(),
+                "-p" + mySqlContainer.getPassword(),
+                "-D" + mySqlContainer.getDatabaseName(),
+                "-e", "DELETE FROM your_table");
+        } catch (Exception e) {
+            // Ignore cleanup errors
+        }
+    }
+
+    private void cleanUpRedis() {
+        try {
+            redisContainer.execInContainer("redis-cli", "FLUSHALL");
+        } catch (Exception e) {
+            // Ignore cleanup errors
+        }
+    }
+
+    // ==================== Dynamic Properties ====================
+
+    @DynamicPropertySource
+    static void properties(DynamicPropertyRegistry registry) {
+        // MySQL
+        registry.add("spring.datasource.url", mySqlContainer::getJdbcUrl);
+        registry.add("spring.datasource.username", mySqlContainer::getUsername);
+        registry.add("spring.datasource.password", mySqlContainer::getPassword);
+
+        // Redis
+        registry.add("spring.redis.host", redisContainer::getHost);
+        registry.add("spring.redis.port", () -> redisContainer.getMappedPort(6379));
+
+        // AWS Services
+        String sqsEndpoint = localstack.getEndpointOverride(SQS).toString();
+        registry.add("aws.sqs.endpoint", () -> sqsEndpoint);
+        registry.add("aws.sqs.region", () -> "ap-south-1");
+
+        String dynamoDbEndpoint = localstack.getEndpointOverride(DYNAMODB).toString();
+        registry.add("aws.dynamodb.endpoint", () -> dynamoDbEndpoint);
+        registry.add("aws.dynamodb.region", () -> "ap-south-1");
+
+        String s3Endpoint = localstack.getEndpointOverride(S3).toString();
+        registry.add("aws.s3.endpoint", () -> s3Endpoint);
+        registry.add("aws.s3.region", () -> "ap-south-1");
+    }
+
+    @Test
+    void contextLoads() {
+        assertTrue(true, "Spring context should load successfully");
+    }
+}
+```
+
+### Dropwizard Setup
+
+#### Test Configuration
+
+**File:** `src/test/resources/test-config.yml`
+
+```yaml
+server:
+  applicationConnectors:
+    - type: http
+      port: 0  # Random port
+  adminConnectors:
+    - type: http
+      port: 0  # Random port
+
+database:
+  driverClass: com.mysql.cj.jdbc.Driver
+  url: ${DATABASE_URL}  # Set via environment variable
+  user: ${DATABASE_USER}
+  password: ${DATABASE_PASSWORD}
+
+redis:
+  host: ${REDIS_HOST}
+  port: ${REDIS_PORT}
+
+aws:
+  sqs:
+    endpoint: ${SQS_ENDPOINT}
+    region: ap-south-1
+  dynamodb:
+    endpoint: ${DYNAMODB_ENDPOINT}
+    region: ap-south-1
+```
+
+#### Base Integration Test
+
+**File:** `src/test/java/your/package/slt/BaseIntegrationTest.java`
+
+```java
+package your.package.slt;
+
+import io.dropwizard.testing.ResourceHelpers;
+import io.dropwizard.testing.junit5.DropwizardAppExtension;
+import io.dropwizard.testing.junit5.DropwizardExtensionsSupport;
+import org.junit.jupiter.api.AfterEach;
+import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Test;
+import org.junit.jupiter.api.extension.ExtendWith;
+import org.testcontainers.containers.GenericContainer;
+import org.testcontainers.containers.MySQLContainer;
+import org.testcontainers.containers.localstack.LocalStackContainer;
+import org.testcontainers.junit.jupiter.Container;
+import org.testcontainers.junit.jupiter.Testcontainers;
+import org.testcontainers.utility.DockerImageName;
+
+import static org.junit.jupiter.api.Assertions.assertTrue;
+import static org.testcontainers.containers.localstack.LocalStackContainer.Service.*;
+
+/**
+ * Base class for Dropwizard SLT tests.
+ */
+@ExtendWith(DropwizardExtensionsSupport.class)
+@Testcontainers
+public abstract class BaseIntegrationTest {
+
+    // ==================== Containers ====================
+
+    @Container
+    private static final MySQLContainer<?> mySqlContainer =
+        new MySQLContainer<>("mysql:8.0.33")
+            .withDatabaseName("test_db")
+            .withUsername("test")
+            .withPassword("test")
+            .withReuse(false);
+
+    @Container
+    private static final GenericContainer<?> redisContainer =
+        new GenericContainer<>("redis:7.0-alpine")
+            .withExposedPorts(6379)
+            .withReuse(false);
+
+    @Container
+    static LocalStackContainer localstack =
+        new LocalStackContainer(DockerImageName.parse("localstack/localstack:4.0.3"))
+            .withServices(SQS, DYNAMODB, S3);
+
+    // ==================== Dropwizard App ====================
+
+    public static final DropwizardAppExtension<YourConfiguration> APP =
+        new DropwizardAppExtension<>(
+            YourApplication.class,
+            ResourceHelpers.resourceFilePath("test-config.yml"),
+            config -> {
+                // Inject container URLs into config
+                config.getDatabaseConfiguration().setUrl(mySqlContainer.getJdbcUrl());
+                config.getDatabaseConfiguration().setUser(mySqlContainer.getUsername());
+                config.getDatabaseConfiguration().setPassword(mySqlContainer.getPassword());
+
+                config.getRedisConfiguration().setHost(redisContainer.getHost());
+                config.getRedisConfiguration().setPort(redisContainer.getMappedPort(6379));
+
+                config.getAwsConfiguration().getSqs().setEndpoint(
+                    localstack.getEndpointOverride(SQS).toString()
+                );
+            }
+        );
+
+    protected String getBaseUrl() {
+        return "http://localhost:" + APP.getLocalPort();
+    }
+
+    @BeforeAll
+    static void beforeAll() throws Exception {
+        mySqlContainer.start();
+        redisContainer.start();
+        localstack.start();
+    }
+
+    @AfterEach
+    public void cleanUp() {
+        // Similar cleanup as Spring Boot example
+    }
+
+    @Test
+    void contextLoads() {
+        assertTrue(true, "Dropwizard app should start successfully");
+    }
+}
+```
+
+---
+
+## Infrastructure Components
+
+### 1. MySQL (Database)
+
+```java
+@Container
+private static final MySQLContainer<?> mySqlContainer =
+    new MySQLContainer<>("mysql:8.0.33")
+        .withDatabaseName("test_db")
+        .withUsername("test")
+        .withPassword("test")
+        .withExposedPorts(3306)
+        .withInitScript("init.sql")  // SQL to create schema + seed data
+        .withReuse(false);            // Set to true for local dev (faster)
+```
+
+**Alternative: PostgreSQL**
+
+```java
+@Container
+private static final PostgreSQLContainer<?> postgresContainer =
+    new PostgreSQLContainer<>("postgres:15-alpine")
+        .withDatabaseName("test_db")
+        .withUsername("test")
+        .withPassword("test");
+```
+
+### 2. Redis (Cache)
+
+```java
+@Container
+private static final GenericContainer<?> redisContainer =
+    new GenericContainer<>("redis:7.0-alpine")
+        .withExposedPorts(6379)
+        .withReuse(false);
+```
+
+**Inject into config:**
+```java
+registry.add("spring.redis.host", redisContainer::getHost);
+registry.add("spring.redis.port", () -> redisContainer.getMappedPort(6379));
+```
+
+### 3. LocalStack (AWS Services)
+
+```java
+@Container
+static LocalStackContainer localstack =
+    new LocalStackContainer(DockerImageName.parse("localstack/localstack:4.0.3"))
+        .withServices(
+            LocalStackContainer.Service.SQS,       // Message queue
+            LocalStackContainer.Service.DYNAMODB,  // NoSQL database
+            LocalStackContainer.Service.S3,        // Object storage
+            LocalStackContainer.Service.SNS        // Pub/sub messaging
+        );
+```
+
+#### SQS Configuration
+
+```java
+String sqsEndpoint = localstack.getEndpointOverride(SQS).toString();
+SqsClient sqsClient = SqsClient.builder()
+    .endpointOverride(URI.create(sqsEndpoint))
+    .region(Region.AP_SOUTH_1)
+    .credentialsProvider(
+        StaticCredentialsProvider.create(
+            AwsBasicCredentials.create("test", "test")
+        )
+    )
+    .build();
+
+// Create queue
+localstack.execInContainer("awslocal", "sqs", "create-queue",
+    "--queue-name", "test-queue", "--region", "ap-south-1");
+```
+
+#### DynamoDB Configuration
+
+```java
+String dynamoEndpoint = localstack.getEndpointOverride(DYNAMODB).toString();
+DynamoDbClient dynamoClient = DynamoDbClient.builder()
+    .endpointOverride(URI.create(dynamoEndpoint))
+    .region(Region.AP_SOUTH_1)
+    .credentialsProvider(
+        StaticCredentialsProvider.create(
+            AwsBasicCredentials.create("test", "test")
+        )
+    )
+    .build();
+
+// Create table
+CreateTableRequest request = CreateTableRequest.builder()
+    .tableName("test-table")
+    .keySchema(KeySchemaElement.builder()
+        .attributeName("id")
+        .keyType(KeyType.HASH)
+        .build())
+    .attributeDefinitions(AttributeDefinition.builder()
+        .attributeName("id")
+        .attributeType(ScalarAttributeType.S)
+        .build())
+    .billingMode(BillingMode.PAY_PER_REQUEST)
+    .build();
+
+dynamoClient.createTable(request);
+```
+
+#### S3 Configuration
+
+```java
+String s3Endpoint = localstack.getEndpointOverride(S3).toString();
+S3Client s3Client = S3Client.builder()
+    .endpointOverride(URI.create(s3Endpoint))
+    .region(Region.AP_SOUTH_1)
+    .credentialsProvider(
+        StaticCredentialsProvider.create(
+            AwsBasicCredentials.create("test", "test")
+        )
+    )
+    .build();
+
+// Create bucket
+s3Client.createBucket(CreateBucketRequest.builder()
+    .bucket("test-bucket")
+    .build());
+```
+
+### 4. Kafka (Message Streaming)
+
+```java
+@Container
+static KafkaContainer kafkaContainer =
+    new KafkaContainer(DockerImageName.parse("confluentinc/cp-kafka:7.5.0"))
+        .withReuse(false);
+```
+
+**Inject into config:**
+```java
+registry.add("spring.kafka.bootstrap-servers", kafkaContainer::getBootstrapServers);
+```
+
+### 5. MongoDB (NoSQL Document DB)
+
+```java
+@Container
+private static final MongoDBContainer mongoDBContainer =
+    new MongoDBContainer(DockerImageName.parse("mongo:7.0"))
+        .withReuse(false);
+```
+
+**Inject into config:**
+```java
+registry.add("spring.data.mongodb.uri", mongoDBContainer::getReplicaSetUrl);
+```
+
+### 6. Elasticsearch (Search Engine)
+
+```java
+@Container
+private static final ElasticsearchContainer elasticsearchContainer =
+    new ElasticsearchContainer("docker.elastic.co/elasticsearch/elasticsearch:8.11.0")
+        .withEnv("discovery.type", "single-node")
+        .withEnv("xpack.security.enabled", "false")
+        .withReuse(false);
+```
+
+---
+
+## Code Templates
+
+### Sample SLT Test (RestAssured)
+
+**File:** `src/test/java/your/package/slt/YourApiSLT.java`
+
+```java
+package your.package.slt;
+
+import io.restassured.RestAssured;
+import io.restassured.http.ContentType;
+import org.junit.jupiter.api.BeforeEach;
+import org.junit.jupiter.api.Test;
+import org.springframework.http.HttpStatus;
+
+import static io.restassured.RestAssured.given;
+import static org.hamcrest.Matchers.*;
+
+/**
+ * SLT tests for Your API endpoint.
+ * Tests: GET /api/v1/your-endpoint/{id}
+ */
+public class YourApiSLT extends BaseIntegrationTest {
+
+    @BeforeEach
+    void setUp() {
+        RestAssured.baseURI = getBaseUrl();
+    }
+
+    // ==================== P0 - Happy Path ====================
+
+    @Test
+    void getEndpoint_withValidId_shouldReturn200() {
+        given()
+            .header("X-Client-Token", "test-token")
+            .contentType(ContentType.JSON)
+        .when()
+            .get("/api/v1/your-endpoint/1")
+        .then()
+            .statusCode(HttpStatus.OK.value())
+            .body("id", equalTo(1))
+            .body("name", notNullValue())
+            .body("status", equalTo("ACTIVE"));
+    }
+
+    // ==================== P1 - Error Handling ====================
+
+    @Test
+    void getEndpoint_withInvalidId_shouldReturn404() {
+        given()
+            .header("X-Client-Token", "test-token")
+            .contentType(ContentType.JSON)
+        .when()
+            .get("/api/v1/your-endpoint/999999")
+        .then()
+            .statusCode(HttpStatus.NOT_FOUND.value())
+            .body("error", equalTo("NOT_FOUND"))
+            .body("message", notNullValue());
+    }
+
+    // ==================== P1 - Authentication ====================
+
+    @Test
+    void getEndpoint_withoutAuthToken_shouldReturn403() {
+        given()
+            .contentType(ContentType.JSON)
+        .when()
+            .get("/api/v1/your-endpoint/1")
+        .then()
+            .statusCode(HttpStatus.FORBIDDEN.value());
+    }
+
+    @Test
+    void getEndpoint_withInvalidToken_shouldReturn403() {
+        given()
+            .header("X-Client-Token", "invalid-token")
+            .contentType(ContentType.JSON)
+        .when()
+            .get("/api/v1/your-endpoint/1")
+        .then()
+            .statusCode(HttpStatus.FORBIDDEN.value());
+    }
+
+    // ==================== P2 - Edge Cases ====================
+
+    @Test
+    void getEndpoint_withNonNumericId_shouldReturn400() {
+        given()
+            .header("X-Client-Token", "test-token")
+            .contentType(ContentType.JSON)
+        .when()
+            .get("/api/v1/your-endpoint/ABC")
+        .then()
+            .statusCode(HttpStatus.BAD_REQUEST.value());
+    }
+}
+```
+
+### Test Utilities
+
+**File:** `src/test/java/your/package/slt/util/TestDataUtil.java`
+
+```java
+package your.package.slt.util;
+
+/**
+ * Utility class for test data constants.
+ */
+public class TestDataUtil {
+
+    // Auth tokens
+    public static final String ADMIN_TOKEN = "admin-token-test";
+    public static final String READ_TOKEN = "read-token-test";
+
+    // Test IDs
+    public static final String TEST_ID_1 = "test-id-1";
+    public static final String TEST_ID_2 = "test-id-2";
+
+    // Test data
+    public static final String TEST_NAME = "Test Name";
+    public static final String TEST_EMAIL = "test@example.com";
+}
+```
+
+**File:** `src/test/java/your/package/slt/util/LocalStackUtil.java`
+
+```java
+package your.package.slt.util;
+
+import org.testcontainers.containers.localstack.LocalStackContainer;
+
+/**
+ * Utility for LocalStack operations.
+ */
+public class LocalStackUtil {
+
+    public static void createSqsQueue(LocalStackContainer localstack, String queueName)
+            throws Exception {
+        localstack.execInContainer("awslocal", "sqs", "create-queue",
+            "--queue-name", queueName, "--region", "ap-south-1");
+    }
+
+    public static void purgeSqsQueue(LocalStackContainer localstack, String queueUrl)
+            throws Exception {
+        localstack.execInContainer("awslocal", "sqs", "purge-queue",
+            "--queue-url", queueUrl, "--region", "ap-south-1");
+    }
+
+    public static void createDynamoDbTable(LocalStackContainer localstack, String tableName)
+            throws Exception {
+        String tableDefinition = String.format(
+            "{\"TableName\":\"%s\",\"KeySchema\":[{\"AttributeName\":\"id\",\"KeyType\":\"HASH\"}]," +
+            "\"AttributeDefinitions\":[{\"AttributeName\":\"id\",\"AttributeType\":\"S\"}]," +
+            "\"BillingMode\":\"PAY_PER_REQUEST\"}",
+            tableName
+        );
+
+        localstack.execInContainer("awslocal", "dynamodb", "create-table",
+            "--cli-input-json", tableDefinition, "--region", "ap-south-1");
+    }
+
+    public static void createS3Bucket(LocalStackContainer localstack, String bucketName)
+            throws Exception {
+        localstack.execInContainer("awslocal", "s3", "mb",
+            "s3://" + bucketName, "--region", "ap-south-1");
+    }
+}
+```
+
+---
+
+## CI/CD Integration
+
+### Option 1: GitHub Actions (Recommended) âœ…
+
+**Why GitHub Actions?**
+- âœ… Zero infrastructure setup
+- âœ… Native Docker support
+- âœ… Free for public repos / 2000 min/month for private
+- âœ… Modern YAML configuration
+- âœ… Automatic PR comments with test results
+- âœ… Built-in caching for Docker and Gradle
+
+**Complete workflow at:** `.github/workflows/slt.yml`
+
+**Triggers:**
+- âœ… Pull Requests (quality gate before merge)
+- âœ… Push to main/develop (validation + S3 upload)
+- âœ… Nightly scheduled (stability monitoring)
+- âœ… Manual trigger (debugging)
+
+**Path Filtering (Cost Optimization):**
+- Runs only when source code, build files, or test resources change
+- Skips on README/docs/markdown changes
+- Saves ~40% of workflow runs
+
+**See:** `.github/workflows/README.md` for complete setup guide
+
+### Option 2: Jenkins
+
+**Use Jenkins if:**
+- You already have Jenkins infrastructure
+- You need self-hosted control
+- You have specific Jenkins plugins required
+
+### Jenkinsfile
+
+```groovy
+pipeline {
+    agent none
+
+    environment {
+        SLACK_CHANNEL = '#your-slack-channel'
+    }
+
+    stages {
+        stage('Build') {
+            agent {
+                docker {
+                    image 'gradle:8.5-jdk21'
+                }
+            }
+            steps {
+                sh './gradlew clean build -x test'
+            }
+        }
+
+        stage('Service Level Tests') {
+            agent {
+                docker {
+                    image 'gradle:8.5-jdk21'
+                    args '-v /var/run/docker.sock:/var/run/docker.sock'
+                }
+            }
+            environment {
+                DOCKER_HOST = 'unix:///var/run/docker.sock'
+            }
+            steps {
+                sh './gradlew test --tests "*.slt.*" jacocoTestReport'
+
+                // Generate visual dashboard
+                sh 'chmod +x scripts/generate-coverage-dashboard.sh'
+                sh './scripts/generate-coverage-dashboard.sh || echo "Dashboard skipped"'
+
+                stash name: 'slt-reports', includes: '**/build/reports/**'
+            }
+        }
+
+        stage('Publish SLT Reports') {
+            agent any
+            steps {
+                unstash 'slt-reports'
+
+                publishHTML([
+                    allowMissing: false,
+                    alwaysLinkToLastBuild: true,
+                    keepAll: true,
+                    reportDir: 'build/reports/slt-dashboard',
+                    reportFiles: 'index.html',
+                    reportName: 'SLT Coverage Dashboard'
+                ])
+
+                publishHTML([
+                    allowMissing: false,
+                    alwaysLinkToLastBuild: true,
+                    keepAll: true,
+                    reportDir: 'build/reports/tests/test',
+                    reportFiles: 'index.html',
+                    reportName: 'SLT Test Report'
+                ])
+
+                publishHTML([
+                    allowMissing: false,
+                    alwaysLinkToLastBuild: true,
+                    keepAll: true,
+                    reportDir: 'build/reports/jacoco/test/html',
+                    reportFiles: 'index.html',
+                    reportName: 'SLT Coverage Report'
+                ])
+            }
+        }
+    }
+
+    post {
+        always {
+            script {
+                def buildStatus = currentBuild.result ?: 'SUCCESS'
+                notifySlack(buildStatus, env.SLACK_CHANNEL)
+            }
+        }
+    }
+}
+
+def notifySlack(String buildStatus, String channel) {
+    buildStatus = buildStatus ?: 'SUCCESS'
+
+    if (buildStatus == 'STARTED') {
+        def msg = "â–¶ï¸ *STARTED*: `${env.JOB_NAME}` #${env.BUILD_NUMBER}\n" +
+                  "ğŸŒ¿ Branch: `${env.GIT_BRANCH}`"
+        slackSend(channel: channel, color: '#D4DADF', message: msg)
+        return
+    }
+
+    try {
+        def slackPayload = sh(
+            script: """
+                export BUILD_STATUS="${buildStatus}"
+                export BUILD_NUMBER="${env.BUILD_NUMBER}"
+                export BUILD_URL="${env.BUILD_URL}"
+                export GIT_BRANCH="${env.GIT_BRANCH}"
+                chmod +x scripts/generate-slack-payload.sh
+                ./scripts/generate-slack-payload.sh "${buildStatus}"
+            """,
+            returnStdout: true
+        ).trim()
+
+        slackSend(channel: channel, attachments: slackPayload)
+    } catch (Exception e) {
+        echo "Failed to send rich Slack notification: ${e.message}"
+        def fallbackMsg = "${buildStatus}: ${env.JOB_NAME} #${env.BUILD_NUMBER}"
+        slackSend(channel: channel, message: fallbackMsg)
+    }
+}
+```
+
+---
+
+## Visual Dashboard & Reporting
+
+### Dashboard Features
+
+1. **Hero Metric:** Overall service coverage percentage
+2. **Coverage Cards:** Instruction, branch, line, method coverage
+3. **Interactive Charts:** Pie charts, bar charts (Chart.js)
+4. **Module Breakdown:** Top 5 packages by coverage
+5. **Test Summary:** Total tests, pass rate, duration
+6. **Color-Coded Badges:** ğŸŸ¢ Excellent (70%+), ğŸŸ¡ Good (50-70%), ğŸ”´ Needs Work (<50%)
+
+### Scripts to Create
+
+Copy from bin-atlas repository:
+
+1. **`run_slt.sh`** - Local test runner (Docker detection, report generation)
+2. **`scripts/generate-coverage-dashboard.sh`** - Dashboard generator (Python XML parser)
+3. **`scripts/generate-slack-payload.sh`** - Slack notification (Block Kit JSON)
+4. **`src/test/resources/coverage-dashboard-template.html`** - Dashboard HTML template
+
+---
+
+## Running Tests
+
+### Local Execution
+
+```bash
+# Run all SLT tests
+./run_slt.sh
+
+# View reports in browser
+./run_slt.sh show
+
+# Get help
+./run_slt.sh help
+```
+
+### Manual Gradle Commands
+
+```bash
+# For Rancher Desktop
+export DOCKER_HOST=unix://$HOME/.rd/docker.sock
+
+# Run SLT tests
+./gradlew test --tests "*.slt.*" jacocoTestReport
+
+# Generate dashboard
+./scripts/generate-coverage-dashboard.sh
+
+# View reports
+open build/reports/slt-dashboard/index.html
+```
+
+---
+
+## Troubleshooting
+
+### Docker Not Running
+
+**Error:** `Could not find a valid Docker environment`
+
+**Solution:**
+1. Start Docker Desktop / Rancher Desktop / Colima
+2. Verify: `docker ps`
+3. For Rancher: `export DOCKER_HOST=unix://$HOME/.rd/docker.sock`
+
+### Tests Timeout
+
+**Error:** `Wait strategy failed. Container did not become ready`
+
+**Solution:**
+1. Increase Docker memory: Settings â†’ Resources â†’ Memory â†’ 4GB+
+2. Pre-pull images: `docker pull mysql:8.0.33 redis:7.0-alpine localstack/localstack:4.0.3`
+
+### Permission Denied (Docker Socket)
+
+**Error:** `Permission denied while trying to connect to Docker daemon socket`
+
+**Solution:**
+```bash
+sudo usermod -aG docker $USER
+newgrp docker
+```
+
+### Container Startup is Slow
+
+**Issue:** First run takes 5-10 minutes
+
+**Solution:**
+- Normal (downloads images)
+- Pre-pull images: `docker pull mysql:8.0.33 redis:7.0-alpine localstack/localstack:4.0.3`
+- Enable container reuse for local dev: `.withReuse(true)`
+
+---
+
+## Best Practices
+
+### 1. Test Naming Convention
+
+âœ… **DO:**
+- Test classes MUST end with `SLT` (not `Test`)
+- Package MUST be `*.slt`
+- Example: `UserApiSLT`, `PaymentApiSLT`
+
+### 2. Test Priority
+
+- **P0 (Sanity):** Happy path, critical flows (8-10 tests)
+- **P1 (Regression):** Auth, validation, errors (10-15 tests)
+- **P2 (Regression):** Edge cases, boundaries (10-15 tests)
+
+### 3. Coverage Targets
+
+- **SLT Tests:** 60-80% instruction coverage
+- **Unit Tests:** 80-90% class coverage
+- **Combined:** 85%+ overall coverage
+
+### 4. Container Reuse
+
+- **Local Dev:** `.withReuse(true)` (faster)
+- **CI/CD:** `.withReuse(false)` (clean state)
+
+### 5. Database Cleanup
+
+âœ… **DO:** Use `@AfterEach` with `DELETE` statements
+âŒ **DON'T:** Drop/recreate tables (slow)
+
+---
+
+## Support & Resources
+
+### Documentation
+- **One-Pager:** `SLT-ONE-PAGER.md`
+- **Quick Reference:** `SLT-QUICK-REFERENCE.md`
+- [Testcontainers](https://www.testcontainers.org/)
+- [RestAssured](https://rest-assured.io/)
+- [JaCoCo](https://www.jacoco.org/jacoco/)
+
+### Example Services
+- **bin-atlas** (Spring Boot) - 32 tests, MySQL, Redis, LocalStack
+- **statement-service** (Spring Boot) - Testcontainers + LocalStack
+- **flight-discovery** (Dropwizard) - Testcontainers + WireMock
+
+### Contact
+- **Team:** CSIT
+- **Slack:** `#csit` or `#payments_slt_report_and_coverage`
+- **Author:** Sourav Singh
+
+---
+
+## Centralized Metrics & S3 Publishing
+
+### Overview
+
+SLT metrics and reports can be automatically published to S3 for centralized dashboard tracking. This enables visibility across all merchant payment services in a single dashboard.
+
+### S3 Structure
+
+**Bucket:** `s3://payments-slt-metrics-report/merchant-payments/`
+
+**Path Structure:**
+```
+s3://payments-slt-metrics-report/merchant-payments/
+  â””â”€â”€ <service-name>/
+      â””â”€â”€ <YYYY-MM-DD_HH-MM-SS>/
+          â”œâ”€â”€ metrics.json              # Dashboard consumes this
+          â”œâ”€â”€ metadata.json             # Git and environment metadata
+          â”œâ”€â”€ test-report.html          # JUnit HTML report
+          â”œâ”€â”€ coverage-report.html      # JaCoCo HTML report
+          â”œâ”€â”€ slt-dashboard.html        # Visual dashboard
+          â”œâ”€â”€ jacocoTestReport.xml      # JaCoCo XML (for parsing)
+          â”œâ”€â”€ jacocoTestReport.csv      # JaCoCo CSV (for parsing)
+          â””â”€â”€ test-cases/
+              â””â”€â”€ <flow-name>.csv       # Test case CSVs
+```
+
+**Datetime Format:** `YYYY-MM-DD_HH-MM-SS`
+**Example:** `s3://payments-slt-metrics-report/merchant-payments/bin-atlas/2026-01-22_14-30-45/`
+
+### Metrics JSON Format
+
+**File:** `metrics.json`
+
+```json
+{
+  "service_name": "bin-atlas",
+  "timestamp": "2026-01-22T14:30:45Z",
+  "commit_sha": "abc123def456",
+  "branch": "main",
+  "author": "Sourav Singh",
+  "tests": {
+    "total": 32,
+    "passed": 32,
+    "failed": 0,
+    "skipped": 0,
+    "success_rate": 100.0,
+    "duration_seconds": 145.2,
+    "by_priority": {
+      "P0": {"total": 8, "passed": 8, "failed": 0},
+      "P1": {"total": 11, "passed": 11, "failed": 0},
+      "P2": {"total": 13, "passed": 13, "failed": 0}
+    },
+    "by_flow": {
+      "bin_lookup_api": {"total": 32, "passed": 32, "failed": 0}
+    }
+  },
+  "coverage": {
+    "overall": {
+      "instruction": 76.5,
+      "branch": 68.2,
+      "line": 78.9,
+      "method": 82.1
+    },
+    "by_package": {
+      "in.dreamplug.bin.api": {"instruction": 85.0, "branch": 75.0},
+      "in.dreamplug.bin.service": {"instruction": 70.0, "branch": 65.0}
+    },
+    "by_flow": {
+      "bin_lookup_api": {"instruction": 80.0, "branch": 72.0}
+    }
+  },
+  "stability": "stable",
+  "stability_reason": "All P0 tests passed and overall success rate 100% >= 90%",
+  "reports": {
+    "test_html": "test-report.html",
+    "coverage_html": "coverage-report.html",
+    "dashboard_html": "slt-dashboard.html",
+    "jacoco_xml": "jacocoTestReport.xml",
+    "jacoco_csv": "jacocoTestReport.csv"
+  }
+}
+```
+
+### Stability Rules
+
+**Stable:** All P0 tests pass AND overall success rate >= 90%
+**Unstable:** P0 tests pass BUT overall success rate < 90%
+**Failing:** Any P0 test fails
+
+### Scripts
+
+#### 1. Generate Metrics JSON
+
+**Script:** `scripts/generate-metrics-json.py`
+
+Parses JaCoCo XML/CSV and JUnit reports to create `metrics.json`.
+
+**Usage:**
+```bash
+python3 scripts/generate-metrics-json.py
+```
+
+**Output:** `build/reports/slt-metrics/metrics.json`
+
+#### 2. Upload to S3
+
+**Script:** `scripts/upload-slt-metrics.sh`
+
+Uploads reports and metrics to S3.
+
+**Prerequisites:**
+- AWS CLI installed (`brew install awscli`)
+- AWS credentials configured (`aws configure`)
+- Access to `s3://payments-slt-metrics-report/`
+
+**Usage:**
+```bash
+# Upload metrics (auto-detects service name from git)
+./scripts/upload-slt-metrics.sh
+
+# Override service name
+SERVICE_NAME=my-service ./scripts/upload-slt-metrics.sh
+
+# Override S3 bucket
+S3_BUCKET=my-bucket ./scripts/upload-slt-metrics.sh
+```
+
+#### 3. Run SLT with S3 Upload
+
+**Enhanced `run_slt.sh` usage:**
+```bash
+# Run tests only (no S3 upload)
+./run_slt.sh
+
+# Run tests and upload to S3
+./run_slt.sh --upload-s3
+```
+
+### Jenkins Integration
+
+Add S3 upload to Jenkins pipeline:
+
+```groovy
+stage('Service Level Tests') {
+    agent {
+        docker {
+            image 'gradle:8.5-jdk21'
+            args '-v /var/run/docker.sock:/var/run/docker.sock'
+        }
+    }
+    environment {
+        DOCKER_HOST = 'unix:///var/run/docker.sock'
+        AWS_REGION = 'ap-south-1'
+    }
+    steps {
+        // Run SLT tests
+        sh './gradlew test --tests "*.slt.*" jacocoTestReport'
+
+        // Generate visual dashboard
+        sh './scripts/generate-coverage-dashboard.sh || echo "Dashboard skipped"'
+
+        // Generate metrics JSON
+        sh 'python3 scripts/generate-metrics-json.py'
+
+        // Upload to S3
+        sh './scripts/upload-slt-metrics.sh'
+
+        stash name: 'slt-reports', includes: '**/build/reports/**'
+    }
+}
+```
+
+### CSV Test Case Template
+
+**Location:** `src/test/resources/testcases/<flow-name>.csv`
+
+**Template:**
+```csv
+Title,Steps,Automatable/Manual,Expected Result,Preconditions,Priority,Author,Section,Type,References
+```
+
+**Example:**
+```csv
+BIN_LOOKUP_001 - Valid VISA BIN Returns Correct Details,"1. Set headers: X-client-name=admin-service, X-client-token=admin-token-dev; 2. Send GET request to /api/v1/bin/lookup/512345; 3. Verify response status code is 200; 4. Verify network=VISA",Automatable,"200 OK with network=VISA, type=CREDIT, issuer=HDFC Bank","Valid admin-service credentials configured, Test BIN 512345 exists in database",P0,Sourav Singh,BIN Lookup API,Sanity,"BinController.java:29, BinService.java:31-52"
+```
+
+**Fields:**
+- **Title:** Unique test case ID and description
+- **Steps:** Numbered steps to execute the test
+- **Automatable/Manual:** "Automatable" or "Manual"
+- **Expected Result:** What should happen (status code, response fields)
+- **Preconditions:** Setup requirements
+- **Priority:** P0 (Sanity), P1 (Regression), P2 (Edge Cases)
+- **Author:** Test case author name
+- **Section:** API endpoint or flow section
+- **Type:** Sanity, Regression, Edge Cases
+- **References:** Related code files and line numbers
+
+**Example CSV:** See `src/test/resources/testcases/bin_lookup_api.csv` for a complete 45-test case example.
+
+### Workflow
+
+**Complete SLT workflow with metrics:**
+
+```bash
+# 1. Run SLT tests locally
+./run_slt.sh
+
+# 2. Generate metrics JSON
+python3 scripts/generate-metrics-json.py
+
+# 3. Upload to S3 (optional)
+./scripts/upload-slt-metrics.sh
+
+# 4. View reports
+./run_slt.sh show
+
+# Or: All-in-one with S3 upload
+./run_slt.sh --upload-s3
+```
+
+**In Jenkins:** Automatic on every build
+- Tests run â†’ Metrics generated â†’ Uploaded to S3 â†’ Dashboard updates
+
+### Centralized Dashboard
+
+**Access:** (Dashboard URL - to be configured)
+
+**Features:**
+- Service-level view: All merchant payment services
+- Metrics tracking: Test success rate, coverage %, stability status
+- Trends: Historical data and trends over time
+- Drill-down: Click service â†’ View detailed reports in S3
+
+**Data Source:** `s3://payments-slt-metrics-report/merchant-payments/*/latest/metrics.json`
+
+---
+
+**Version:** 2.1
+**Last Updated:** 2026-01-22
+**Status:** âœ… Production Ready with Centralized Metrics
diff --git a/SLT-ONE-PAGER.md b/SLT-ONE-PAGER.md
new file mode 100644
index 00000000..9161d295
--- /dev/null
+++ b/SLT-ONE-PAGER.md
@@ -0,0 +1,159 @@
+# Service Level Tests (SLT) - One Pager
+
+> **TL;DR:** End-to-end API testing with real infrastructure (MySQL, Redis, LocalStack). One command to run locally (`./run_slt.sh`), auto-integrated with Jenkins + Slack notifications.
+
+---
+
+## What Is This?
+
+**Service Level Tests (SLT)** validate the entire BIN Atlas service end-to-end with **real infrastructure**:
+
+- MySQL 8.0 database
+- Redis 7.0 cache
+- LocalStack for AWS services (SQS, DynamoDB, S3)
+- Complete Spring Boot application
+- RestAssured HTTP API tests
+
+### Current Coverage
+- **32 comprehensive tests** (8 P0, 11 P1, 13 P2)
+- **100% test success rate**
+- **~76% instruction coverage** on core services
+- **Real infrastructure** via Testcontainers
+
+---
+
+## Quick Start (2 Minutes)
+
+### Local Development
+
+```bash
+# Prerequisites: Docker running, Java 21, Gradle 8.5+
+
+# Run all SLT tests
+./run_slt.sh
+
+# View reports in browser
+./run_slt.sh show
+
+# Get help
+./run_slt.sh help
+```
+
+### CI/CD (Jenkins)
+
+Already integrated! Every build automatically:
+1. Runs all 32 SLT tests
+2. Generates test + coverage reports
+3. Publishes reports to Jenkins
+4. Sends Slack notification to `#payments_slt_report_and_coverage`
+
+---
+
+## What Gets Tested
+
+| Priority | Count | Focus |
+|----------|-------|-------|
+| **P0 (Sanity)** | 8 tests | Happy path scenarios (VISA, Mastercard, RuPay lookups) |
+| **P1 (Regression)** | 11 tests | Authentication, authorization, input validation |
+| **P2 (Regression)** | 13 tests | Edge cases, error handling, response structure |
+
+---
+
+## Reports & Metrics
+
+### Slack Notifications
+
+Channel: `#payments_slt_report_and_coverage`
+
+Every build sends a rich notification with:
+- Build status (âœ… SUCCESS / âš ï¸ UNSTABLE / âŒ FAILURE)
+- Coverage metrics (instruction, branch, line)
+- Test results (32 tests, 100% pass rate)
+- **Clickable links** to all reports
+
+### Available Reports
+
+1. **Visual Dashboard** - Beautiful charts showing service coverage
+2. **Test Report** - Detailed test results with logs
+3. **Coverage Report** - Line-by-line code coverage
+
+**Access via:**
+- Slack notification links
+- Jenkins build sidebar
+- Local files after running `./run_slt.sh`
+
+---
+
+## Why This Matters
+
+### Before SLT
+- âŒ Unit tests with heavy mocking (brittle)
+- âŒ Manual API testing (slow, error-prone)
+- âŒ Integration issues caught in QA/production
+- âŒ No visibility into service-level coverage
+
+### After SLT
+- âœ… Tests run against real database and AWS services
+- âœ… Catches integration issues before deployment
+- âœ… Automatic execution in Jenkins
+- âœ… Clear metrics and reports
+- âœ… Slack notifications for at-a-glance status
+
+---
+
+## Adopting SLT in Your Service
+
+Want SLT for your service? See **`SLT-IMPLEMENTATION-GUIDE.md`** for:
+- 30-minute setup guide
+- Required dependencies (Testcontainers, Spring Boot Test)
+- Code templates and examples
+- Jenkins pipeline configuration
+- Troubleshooting guide
+- High-level architecture and workflow
+
+---
+
+## Key Metrics (BIN Atlas)
+
+- **Service Coverage:** 76% instruction coverage
+- **Total Tests:** 32 (100% passing)
+- **Infrastructure:** MySQL 8.0, Redis 7.0, LocalStack 4.0
+- **Execution Time:** ~2-3 minutes locally, 3-5 minutes in Jenkins
+- **Docker Detection:** Auto-detects Docker Desktop, Rancher Desktop, Colima
+
+---
+
+## Quick Reference
+
+### Commands
+```bash
+./run_slt.sh          # Run tests
+./run_slt.sh show     # View reports
+./run_slt.sh help     # Get help
+```
+
+### Report Locations
+
+**Local:**
+- Dashboard: `bin-server/build/reports/slt-dashboard/index.html`
+- Tests: `bin-server/build/reports/tests/test/index.html`
+- Coverage: `bin-server/build/reports/jacoco/test/html/index.html`
+
+**Jenkins:**
+- Click links in Slack notification
+- Or navigate to: Build â†’ Sidebar â†’ "SLT Coverage Dashboard"
+
+---
+
+## Support
+
+- **Team:** CSIT
+- **Slack:** `#csit`
+- **Documentation:** `SLT-IMPLEMENTATION-GUIDE.md`
+- **Contact:** Sourav Singh
+
+---
+
+**Status:** âœ… Production Ready
+**Last Updated:** 2026-01-21
+**Version:** 2.0
diff --git a/SLT-QUICK-REFERENCE.md b/SLT-QUICK-REFERENCE.md
new file mode 100644
index 00000000..75ebb542
--- /dev/null
+++ b/SLT-QUICK-REFERENCE.md
@@ -0,0 +1,224 @@
+# Service Level Tests (SLT) - Quick Reference
+
+**Cheat sheet for daily SLT usage**
+
+---
+
+## Commands
+
+```bash
+# Run all SLT tests
+./run_slt.sh
+
+# View reports in browser
+./run_slt.sh show
+
+# Get help
+./run_slt.sh help
+
+# Manual Gradle command
+./gradlew test --tests "*.slt.*" jacocoTestReport
+```
+
+---
+
+## What Gets Tested
+
+- âœ… **32 comprehensive test scenarios**
+- âœ… **P0 + P1 + P2 coverage** (sanity, regression, edge cases)
+- âœ… **Real infrastructure** (MySQL, Redis, LocalStack)
+- âœ… **76% service coverage** (instruction coverage)
+
+---
+
+## Reports & Dashboards
+
+### Local
+
+- **Dashboard:** `build/reports/slt-dashboard/index.html` â­ Start here!
+- **Tests:** `build/reports/tests/test/index.html`
+- **Coverage:** `build/reports/jacoco/test/html/index.html`
+
+### Jenkins
+
+1. Go to build (e.g., `your-service-stage-ci #42`)
+2. Click sidebar: **SLT Coverage Dashboard** â­ Start here!
+3. Or check Slack `#payments_slt_report_and_coverage` for links
+
+---
+
+## Common Issues
+
+| Issue | Solution |
+|-------|----------|
+| **Docker not running** | Start Docker Desktop/Rancher/Colima |
+| **Tests timeout** | Increase Docker memory to 4GB+ |
+| **Port in use** | Tests use random ports (auto-handled) |
+| **Permission denied** | `sudo usermod -aG docker $USER` |
+| **Images download slowly** | First run only (3-5 min). Pre-pull: `docker pull mysql:8.0.33 redis:7.0-alpine localstack/localstack:4.0.3` |
+
+---
+
+## Test Priority Guide
+
+| Priority | Count | Focus | Examples |
+|----------|-------|-------|----------|
+| **P0** | 8-10 | Happy path, critical journeys | Valid BIN lookup, successful payment |
+| **P1** | 10-15 | Auth, validation, errors | Invalid token, missing fields, 404 errors |
+| **P2** | 10-15 | Edge cases, boundaries | Min/max length, special chars, whitespace |
+
+---
+
+## Coverage Targets
+
+- **Service Level (SLT):** 60-80% instruction coverage âœ…
+- **Unit Tests:** 80-90% class coverage
+- **Combined:** 85%+ overall coverage
+
+---
+
+## Infrastructure Components
+
+### Available Testcontainers
+
+```java
+// Database
+MySQLContainer          // mysql:8.0.33
+PostgreSQLContainer     // postgres:15-alpine
+
+// Cache
+GenericContainer        // redis:7.0-alpine
+
+// AWS Services
+LocalStackContainer     // localstack:4.0.3
+  - SQS                 // Message queue
+  - DynamoDB            // NoSQL database
+  - S3                  // Object storage
+  - SNS                 // Pub/sub messaging
+
+// Message Streaming
+KafkaContainer          // confluentinc/cp-kafka:7.5.0
+
+// NoSQL
+MongoDBContainer        // mongo:7.0
+
+// Search
+ElasticsearchContainer  // elasticsearch:8.11.0
+```
+
+---
+
+## Framework Support
+
+### Spring Boot
+
+```java
+@SpringBootTest(webEnvironment = RANDOM_PORT)
+@ActiveProfiles("test")
+@Testcontainers
+public abstract class BaseIntegrationTest {
+    @LocalServerPort protected int port;
+    @Container static MySQLContainer<?> mysql = ...;
+    @DynamicPropertySource
+    static void properties(DynamicPropertyRegistry registry) { ... }
+}
+```
+
+### Dropwizard
+
+```java
+@ExtendWith(DropwizardExtensionsSupport.class)
+@Testcontainers
+public abstract class BaseIntegrationTest {
+    @Container static MySQLContainer<?> mysql = ...;
+    static DropwizardAppExtension<Config> APP = ...;
+}
+```
+
+---
+
+## Quick Test Template
+
+```java
+public class YourApiSLT extends BaseIntegrationTest {
+
+    @BeforeEach
+    void setUp() {
+        RestAssured.baseURI = getBaseUrl();
+    }
+
+    @Test
+    void getEndpoint_withValidId_shouldReturn200() {
+        given()
+            .header("X-Client-Token", "test-token")
+            .contentType(ContentType.JSON)
+        .when()
+            .get("/api/v1/endpoint/1")
+        .then()
+            .statusCode(HttpStatus.OK.value())
+            .body("id", equalTo(1))
+            .body("status", equalTo("ACTIVE"));
+    }
+}
+```
+
+---
+
+## Best Practices
+
+### âœ… DO
+
+- Name test classes with `SLT` suffix (`YourApiSLT`)
+- Use `*.slt` package for easy identification
+- Test both success and error scenarios
+- Use `@AfterEach` cleanup with `DELETE` statements
+- Set `.withReuse(false)` in CI/CD
+- Aim for 60-80% instruction coverage
+
+### âŒ DON'T
+
+- Name test classes with `Test` suffix (confusing with unit tests)
+- Recreate containers per test (slow)
+- Use `@DirtiesContext` (very slow)
+- Drop/recreate tables in cleanup (slow)
+- Write 100+ SLT tests (use unit tests for edge cases)
+
+---
+
+## Jenkins Integration
+
+**Required Jenkinsfile additions:**
+
+```groovy
+stage('Service Level Tests') {
+    agent {
+        docker {
+            image 'gradle:8.5-jdk21'
+            args '-v /var/run/docker.sock:/var/run/docker.sock'
+        }
+    }
+    steps {
+        sh './gradlew test --tests "*.slt.*" jacocoTestReport'
+        sh './scripts/generate-coverage-dashboard.sh'
+    }
+}
+```
+
+---
+
+## Full Documentation
+
+- **One-Pager:** `SLT-ONE-PAGER.md` - Executive summary
+- **Implementation Guide:** `SLT-IMPLEMENTATION-GUIDE.md` - Complete setup guide
+
+---
+
+## Support
+
+- **Team:** CSIT
+- **Slack:** `#csit` or `#payments_slt_report_and_coverage`
+- **Example Service:** `bin-atlas` repository
+
+---
+
+**Version:** 2.0 | **Last Updated:** 2026-01-21
diff --git a/bin-server/build.gradle b/bin-server/build.gradle
index 95ef55e5..f6d6f5a5 100644
--- a/bin-server/build.gradle
+++ b/bin-server/build.gradle
@@ -40,12 +40,90 @@ dependencies {
     implementation project(":bin-server:egress")
     implementation project(":bin-server:ingress")
     implementation project(":bin-server:manager")
+
+    // SLT Test Dependencies - Testcontainers Core
+    testImplementation "org.testcontainers:testcontainers:1.19.3"
+    testImplementation "org.testcontainers:junit-jupiter:1.19.3"
+
+    // SLT Test Dependencies - Specific Containers
+    testImplementation "org.testcontainers:mysql:1.19.3"
+    testImplementation "org.testcontainers:localstack:1.19.3"
+
+    // SLT Test Dependencies - WireMock for External API Mocking
+    testImplementation "org.wiremock:wiremock-standalone:3.9.1"
+
+    // SLT Test Dependencies - Spring Boot Test
+    testImplementation "org.springframework.boot:spring-boot-starter-test"
+    testImplementation "org.springframework.boot:spring-boot-testcontainers"
+
+    // SLT Test Dependencies - AWS SDK BOM for version management
+    testImplementation platform("software.amazon.awssdk:bom:2.20.100")
+
+    // SLT Test Dependencies - AWS SDK for LocalStack and S3
+    testImplementation "software.amazon.awssdk:sqs"
+    testImplementation "software.amazon.awssdk:dynamodb"
+    testImplementation "software.amazon.awssdk:s3"
+
+    // SLT Test Dependencies - REST Assured for API Testing
+    testImplementation "io.rest-assured:rest-assured:5.3.2"
+
+    // Standard Test Dependencies (inherited from subprojects pattern)
+    testImplementation "org.springframework.boot:spring-boot-starter-web"  // For HttpStatus and web testing
+    testImplementation('org.springframework.boot:spring-boot-starter-test') {
+        exclude group: "junit"
+        exclude group: "org.junit.vintage", module: 'junit-vintage-engine'
+    }
+    testImplementation("org.mockito:mockito-core")
+    testImplementation("org.junit.jupiter:junit-jupiter-api")
+    testImplementation("org.junit.jupiter:junit-jupiter-engine")
+    testImplementation("org.junit.jupiter:junit-jupiter-params")
+    testImplementation("org.junit.platform:junit-platform-launcher")
+    testImplementation("org.junit.platform:junit-platform-runner")
 }
 
 springBoot {
     buildInfo()
 }
 
+// Jacoco test coverage report configuration for aggregating coverage from submodules
+test {
+    useJUnitPlatform()
+    finalizedBy jacocoTestReport
+}
+
+jacocoTestReport {
+    dependsOn test
+
+    // Aggregate execution data from the parent module test run
+    executionData fileTree(project.buildDir).include("jacoco/*.exec")
+
+    // Collect source and class directories from all submodules
+    def subprojectSourceDirs = subprojects.collect { it.sourceSets.main.allSource.srcDirs }.flatten()
+    def subprojectClassDirs = subprojects.collect { it.sourceSets.main.output }.flatten()
+
+    sourceDirectories.setFrom(files(subprojectSourceDirs))
+    classDirectories.setFrom(files(subprojectClassDirs).collect {
+        fileTree(dir: it, exclude: [
+            '**/config/**',
+            '**/dto/**',
+            '**/entity/**',
+            '**/exception/**',
+            '**/datatype/**',
+            '**/*Application.class',
+            '**/*Configuration.class',
+            '**/*Config.class'
+        ])
+    })
+
+    reports {
+        xml.required = true
+        html.required = true
+        csv.required = false
+
+        xml.outputLocation = file("${buildDir}/reports/jacoco/test/jacocoTestReport.xml")
+        html.outputLocation = file("${buildDir}/reports/jacoco/test/html")
+    }
+}
 
 allprojects {
     version = "0.0.1"
diff --git a/bin-server/core/build.gradle b/bin-server/core/build.gradle
index 46a218d5..a14ce672 100644
--- a/bin-server/core/build.gradle
+++ b/bin-server/core/build.gradle
@@ -25,6 +25,34 @@ dependencies {
     // database
     implementation 'com.mysql:mysql-connector-j'
 
+    // SLT Test Dependencies - Module Dependencies for Integration Tests
+    testImplementation project(":bin-server:ingress")
+    testImplementation project(":bin-server:manager")
+    testImplementation project(":bin-server:egress")
+
+    // SLT Test Dependencies - Testcontainers Core
     testImplementation "org.testcontainers:testcontainers:1.19.3"
+    testImplementation "org.testcontainers:junit-jupiter:1.19.3"
+
+    // SLT Test Dependencies - Specific Containers
     testImplementation "org.testcontainers:mysql:1.19.3"
+    testImplementation "org.testcontainers:localstack:1.19.3"
+
+    // SLT Test Dependencies - WireMock for External API Mocking
+    testImplementation "org.wiremock:wiremock-standalone:3.9.1"
+
+    // SLT Test Dependencies - Spring Boot Test
+    testImplementation "org.springframework.boot:spring-boot-starter-test"
+    testImplementation "org.springframework.boot:spring-boot-testcontainers"
+
+    // SLT Test Dependencies - AWS SDK for LocalStack
+    testImplementation "software.amazon.awssdk:sqs:2.20.0"
+    testImplementation "software.amazon.awssdk:dynamodb:2.20.0"
+    testImplementation "software.amazon.awssdk:aws-core:2.20.0"
+    testImplementation "software.amazon.awssdk:apache-client:2.20.0"
+    testImplementation "software.amazon.awssdk:protocol-core:2.20.0"
+    testImplementation "software.amazon.awssdk:aws-query-protocol:2.20.0"
+
+    // SLT Test Dependencies - REST Assured for API Testing
+    testImplementation "io.rest-assured:rest-assured:5.3.2"
 }
diff --git a/bin-server/core/src/test/resources/application-test.properties b/bin-server/core/src/test/resources/application-test.properties
new file mode 100644
index 00000000..d53eee5d
--- /dev/null
+++ b/bin-server/core/src/test/resources/application-test.properties
@@ -0,0 +1,16 @@
+# Server
+server.port=0
+spring.main.banner-mode=off
+
+# Database - will be overridden by @DynamicPropertySource
+spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
+spring.jpa.hibernate.ddl-auto=none
+spring.jpa.show-sql=false
+
+# AWS - will be overridden by @DynamicPropertySource
+aws.sqs.enabled=true
+
+# Disable unnecessary features in tests
+scheduler.bin-deactivation.enabled=false
+statsd.configuration.enabled=false
+management.metrics.export.cloudwatch.enabled=false
diff --git a/bin-server/core/src/test/resources/init.sql b/bin-server/core/src/test/resources/init.sql
new file mode 100644
index 00000000..ce7e34b1
--- /dev/null
+++ b/bin-server/core/src/test/resources/init.sql
@@ -0,0 +1,62 @@
+-- Create bins table
+CREATE TABLE IF NOT EXISTS `bins` (
+    `id` BIGINT NOT NULL AUTO_INCREMENT,
+    `external_id` VARCHAR(50) NOT NULL,
+    `bin_number` BIGINT NOT NULL,
+    `bin_range_low` DECIMAL(30,0) NOT NULL,
+    `bin_range_high` DECIMAL(30,0) NOT NULL,
+    `bin_range_low_padded` DECIMAL(30,0) NOT NULL,
+    `bin_range_high_padded` DECIMAL(30,0) NOT NULL,
+    `network` VARCHAR(20) NOT NULL,
+    `bin_length` BIGINT NOT NULL,
+    `pan_length` BIGINT NOT NULL,
+    `country` VARCHAR(50) NOT NULL,
+    `issuer` VARCHAR(200) NOT NULL,
+    `ingestion_id` BIGINT NOT NULL,
+    `ingestion_batch_id` BIGINT NOT NULL,
+    `type` VARCHAR(20) NOT NULL,
+    `funding_source` VARCHAR(50) NOT NULL,
+    `network_card_product` VARCHAR(50),
+    `is_domestic` BOOLEAN NOT NULL,
+    `billing_currency` VARCHAR(50) NOT NULL,
+    `status` VARCHAR(50) NOT NULL,
+    `consumer_type` VARCHAR(50),
+    `created_at` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
+    `updated_at` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
+    PRIMARY KEY (`id`),
+    INDEX `idx_bin_number` (`bin_number`),
+    INDEX `idx_status` (`status`)
+) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
+
+-- Insert test data for BIN lookup tests
+INSERT INTO `bins` (
+    external_id, bin_number, bin_range_low, bin_range_high,
+    bin_range_low_padded, bin_range_high_padded, network,
+    bin_length, pan_length, country, issuer, ingestion_id,
+    ingestion_batch_id, type, funding_source, network_card_product,
+    is_domestic, billing_currency, status, consumer_type
+) VALUES
+    -- VISA Credit Card - HDFC Bank
+    (
+        'test-bin-512345', 512345, 51234500000000, 51234599999999,
+        51234500000000000000, 51234599999999999999, 'VISA',
+        6, 16, 'India', 'HDFC Bank', 1,
+        1, 'CREDIT', 'CREDIT', 'VISA_SIGNATURE',
+        true, 'INR', 'ACTIVE', 'PERSONAL'
+    ),
+    -- MASTERCARD Debit Card - ICICI Bank
+    (
+        'test-bin-487654', 487654, 48765400000000, 48765499999999,
+        48765400000000000000, 48765499999999999999, 'MASTERCARD',
+        6, 16, 'India', 'ICICI Bank', 1,
+        1, 'DEBIT', 'DEBIT', 'MASTERCARD_WORLD',
+        true, 'INR', 'ACTIVE', 'PERSONAL'
+    ),
+    -- RUPAY Credit Card - SBI
+    (
+        'test-bin-654321', 654321, 65432100000000, 65432199999999,
+        65432100000000000000, 65432199999999999999, 'RUPAY',
+        6, 16, 'India', 'SBI', 1,
+        1, 'CREDIT', 'CREDIT', 'RUPAY_PLATINUM',
+        true, 'INR', 'ACTIVE', 'PERSONAL'
+    );
diff --git a/bin-server/core/src/test/resources/testcontainers.properties b/bin-server/core/src/test/resources/testcontainers.properties
new file mode 100644
index 00000000..54d83f08
--- /dev/null
+++ b/bin-server/core/src/test/resources/testcontainers.properties
@@ -0,0 +1,5 @@
+# Disable Ryuk (resource cleanup container) for Rancher Desktop compatibility
+testcontainers.reuse.enable=true
+ryuk.container.image=testcontainers/ryuk:0.5.1
+ryuk.container.privileged=true
+docker.client.strategy=org.testcontainers.dockerclient.UnixSocketClientProviderStrategy
diff --git a/bin-server/src/test/java/in/dreamplug/bin/slt/BaseIntegrationTest.java b/bin-server/src/test/java/in/dreamplug/bin/slt/BaseIntegrationTest.java
new file mode 100644
index 00000000..beddf2e9
--- /dev/null
+++ b/bin-server/src/test/java/in/dreamplug/bin/slt/BaseIntegrationTest.java
@@ -0,0 +1,154 @@
+package in.dreamplug.bin.slt;
+
+import static org.junit.jupiter.api.Assertions.assertTrue;
+
+import in.dreamplug.bin.core.Application;
+import in.dreamplug.bin.slt.config.AwsTestConfiguration;
+import in.dreamplug.bin.slt.util.LocalStackUtil;
+import java.io.IOException;
+import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Test;
+import org.springframework.boot.test.context.SpringBootTest;
+import org.springframework.boot.test.web.server.LocalServerPort;
+import org.springframework.context.annotation.Import;
+import org.springframework.test.context.ActiveProfiles;
+import org.springframework.test.context.DynamicPropertyRegistry;
+import org.springframework.test.context.DynamicPropertySource;
+import org.testcontainers.containers.GenericContainer;
+import org.testcontainers.containers.MySQLContainer;
+import org.testcontainers.containers.localstack.LocalStackContainer;
+import org.testcontainers.junit.jupiter.Container;
+import org.testcontainers.junit.jupiter.Testcontainers;
+import org.testcontainers.utility.DockerImageName;
+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;
+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;
+import software.amazon.awssdk.regions.Region;
+import software.amazon.awssdk.services.sqs.SqsClient;
+
+/**
+ * Base class for all SLT (Service Level Tests) integration tests.
+ *
+ * <p>This class provides:
+ *
+ * <ul>
+ *   <li>MySQL database container with test schema
+ *   <li>Redis container for caching
+ *   <li>LocalStack container for SQS and DynamoDB
+ *   <li>Automatic database cleanup after each test
+ *   <li>Spring Boot application with random port
+ * </ul>
+ *
+ * <p><b>Usage:</b>
+ *
+ * <pre>
+ * public class BinLookupApiSLT extends BaseIntegrationTest {
+ *     // Your test methods here
+ * }
+ * </pre>
+ *
+ * @author Sourav Singh
+ */
+@SpringBootTest(
+    classes = Application.class,
+    webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)
+@ActiveProfiles("test")
+@Import(AwsTestConfiguration.class)
+@Testcontainers
+public abstract class BaseIntegrationTest {
+
+  @LocalServerPort protected int port;
+
+  protected String getBaseUrl() {
+    return "http://localhost:" + port + "/bin-atlas";
+  }
+
+  @Container private static final MySQLContainer<?> mySqlContainer = createMySqlContainer();
+
+  @Container private static final GenericContainer<?> redisContainer = createRedisContainer();
+
+  static DockerImageName localstackImage = DockerImageName.parse("localstack/localstack:4.0.3");
+
+  @Container
+  public static LocalStackContainer localstack =
+      new LocalStackContainer(localstackImage)
+          .withServices(
+              LocalStackContainer.Service.SQS,
+              LocalStackContainer.Service.DYNAMODB,
+              LocalStackContainer.Service.S3);
+
+  protected static SqsClient sqsClient;
+  protected static String testQueueUrl;
+
+  private static MySQLContainer<?> createMySqlContainer() {
+    return new MySQLContainer<>("mysql:8.0.33")
+        .withDatabaseName("bin_atlas")
+        .withUsername("test")
+        .withPassword("test")
+        .withExposedPorts(3306)
+        .withInitScript("init.sql")
+        .withReuse(false);
+  }
+
+  private static GenericContainer<?> createRedisContainer() {
+    return new GenericContainer<>("redis:7.0-alpine").withExposedPorts(6379).withReuse(false);
+  }
+
+  @BeforeAll
+  static void beforeAll() throws IOException, InterruptedException {
+    mySqlContainer.start();
+    redisContainer.start();
+    localstack.start();
+
+    String sqsEndpoint = localstack.getEndpointOverride(LocalStackContainer.Service.SQS).toString();
+    sqsClient =
+        SqsClient.builder()
+            .endpointOverride(java.net.URI.create(sqsEndpoint))
+            .region(Region.AP_SOUTH_1)
+            .credentialsProvider(
+                StaticCredentialsProvider.create(AwsBasicCredentials.create("test", "test")))
+            .build();
+
+    String queueName = "bin-atlas-test-queue";
+    LocalStackUtil.createQueue(localstack, queueName);
+    testQueueUrl = sqsEndpoint + "/000000000000/" + queueName;
+  }
+
+  @DynamicPropertySource
+  static void properties(DynamicPropertyRegistry registry) {
+    registry.add("spring.datasource.url", mySqlContainer::getJdbcUrl);
+    registry.add("spring.datasource.username", mySqlContainer::getUsername);
+    registry.add("spring.datasource.password", mySqlContainer::getPassword);
+
+    registry.add("spring.redis.host", redisContainer::getHost);
+    registry.add("spring.redis.port", () -> redisContainer.getMappedPort(6379));
+
+    String sqsEndpoint = localstack.getEndpointOverride(LocalStackContainer.Service.SQS).toString();
+    registry.add("aws.sqs.endpoint", () -> sqsEndpoint);
+    registry.add("aws.sqs.region", () -> "ap-south-1");
+
+    String dynamoDbEndpoint =
+        localstack.getEndpointOverride(LocalStackContainer.Service.DYNAMODB).toString();
+    registry.add("aws.dynamodb.endpoint", () -> dynamoDbEndpoint);
+    registry.add("aws.dynamodb.region", () -> "ap-south-1");
+
+    String s3Endpoint = localstack.getEndpointOverride(LocalStackContainer.Service.S3).toString();
+    registry.add("aws.s3.endpoint", () -> s3Endpoint);
+    registry.add("aws.s3.region", () -> "ap-south-1");
+
+    registry.add("consumer.ingestion-batch-queue.name", () -> "bin-atlas-test-queue");
+
+    // Authentication configuration for tests
+    registry.add("auth.clients[0].name", () -> "admin-service");
+    registry.add("auth.clients[0].token", () -> "admin-token-dev");
+    registry.add("auth.clients[0].access-level", () -> "ADMIN");
+
+    registry.add("auth.clients[1].name", () -> "arsenal");
+    registry.add("auth.clients[1].token", () -> "read-token-dev");
+    registry.add("auth.clients[1].access-level", () -> "READ");
+  }
+
+  @Test
+  void contextLoads() {
+    assertTrue(true, "Spring context should load successfully");
+  }
+}
diff --git a/bin-server/src/test/java/in/dreamplug/bin/slt/BinLookupApiSLT.java b/bin-server/src/test/java/in/dreamplug/bin/slt/BinLookupApiSLT.java
new file mode 100644
index 00000000..cabd53d9
--- /dev/null
+++ b/bin-server/src/test/java/in/dreamplug/bin/slt/BinLookupApiSLT.java
@@ -0,0 +1,471 @@
+package in.dreamplug.bin.slt;
+
+import static io.restassured.RestAssured.given;
+import static org.hamcrest.Matchers.*;
+
+import in.dreamplug.bin.slt.util.BinTestDataUtil;
+import io.restassured.RestAssured;
+import io.restassured.http.ContentType;
+import org.junit.jupiter.api.BeforeEach;
+import org.junit.jupiter.api.Test;
+import org.springframework.http.HttpStatus;
+
+/**
+ * SLT tests for BIN Lookup API.
+ *
+ * <p>Tests the endpoint: GET /api/v1/bin/lookup/{input}
+ *
+ * <p>This test validates:
+ *
+ * <ul>
+ *   <li>Successful BIN lookup with valid data
+ *   <li>Authentication with valid token
+ *   <li>Database integration
+ *   <li>Response structure and content
+ * </ul>
+ *
+ * @author Sourav Singh
+ */
+public class BinLookupApiSLT extends BaseIntegrationTest {
+
+  @BeforeEach
+  void setUp() {
+    RestAssured.baseURI = getBaseUrl();
+  }
+
+  @Test
+  void lookupBin_withValidVisaBin_shouldReturnBinDetails() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.OK.value())
+        .body("bin_number", equalTo(512345))
+        .body("network", equalTo("VISA"))
+        .body("type", equalTo("CREDIT"))
+        .body("issuer", equalTo("HDFC Bank"))
+        .body("country", equalTo("India"))
+        .body("funding_source", equalTo("CREDIT"))
+        .body("network_card_product", equalTo("VISA_SIGNATURE"))
+        .body("is_domestic", equalTo(true))
+        .body("billing_currency", equalTo("INR"))
+        .body("status", equalTo("ACTIVE"))
+        .body("consumer_type", equalTo("PERSONAL"));
+  }
+
+  @Test
+  void lookupBin_withValidMastercardBin_shouldReturnCorrectDetails() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_487654)
+        .then()
+        .statusCode(HttpStatus.OK.value())
+        .body("bin_number", equalTo(487654))
+        .body("network", equalTo("MASTERCARD"))
+        .body("type", equalTo("DEBIT"))
+        .body("issuer", equalTo("ICICI Bank"))
+        .body("country", equalTo("India"))
+        .body("funding_source", equalTo("DEBIT"))
+        .body("network_card_product", equalTo("MASTERCARD_WORLD"))
+        .body("is_domestic", equalTo(true));
+  }
+
+  @Test
+  void lookupBin_withValidRupayBin_shouldReturnCorrectDetails() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_654321)
+        .then()
+        .statusCode(HttpStatus.OK.value())
+        .body("bin_number", equalTo(654321))
+        .body("network", equalTo("RUPAY"))
+        .body("type", equalTo("CREDIT"))
+        .body("issuer", equalTo("SBI"))
+        .body("country", equalTo("India"))
+        .body("network_card_product", equalTo("RUPAY_PLATINUM"));
+  }
+
+  @Test
+  void lookupBin_withInvalidBinNumber_shouldReturn404() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/999999")
+        .then()
+        .statusCode(HttpStatus.NOT_FOUND.value());
+  }
+
+  @Test
+  void lookupBin_withoutAuthToken_shouldReturn403() {
+    given()
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.UNAUTHORIZED.value());
+  }
+
+  @Test
+  void lookupBin_withInvalidAuthToken_shouldReturn403() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", "invalid-token")
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.UNAUTHORIZED.value());
+  }
+
+  @Test
+  void lookupBin_withAdminToken_shouldAlsoWork() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.OK.value())
+        .body("bin_number", equalTo(512345))
+        .body("network", equalTo("VISA"));
+  }
+
+  // ========== P1 REGRESSION TESTS: Input Validation ==========
+
+  @Test
+  void lookupBin_withTooShortInput_shouldReturn400() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/12345") // 5 digits - too short
+        .then()
+        .statusCode(HttpStatus.BAD_REQUEST.value());
+  }
+
+  @Test
+  void lookupBin_withTooLongInput_shouldReturn400() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/1234567890") // 10 digits - too long
+        .then()
+        .statusCode(HttpStatus.BAD_REQUEST.value());
+  }
+
+  @Test
+  void lookupBin_withNonNumericInput_shouldReturn400() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/ABC123")
+        .then()
+        .statusCode(HttpStatus.BAD_REQUEST.value());
+  }
+
+  @Test
+  void lookupBin_withSpecialCharacters_shouldReturn400() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/123@45")
+        .then()
+        .statusCode(HttpStatus.BAD_REQUEST.value());
+  }
+
+  // ========== P1 REGRESSION TESTS: Authentication & Authorization ==========
+
+  @Test
+  void lookupBin_withMissingClientName_shouldReturn403() {
+    given()
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.UNAUTHORIZED.value());
+  }
+
+  @Test
+  void lookupBin_withMissingClientToken_shouldReturn403() {
+    given()
+        .header("X-client-name", "admin-service")
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.UNAUTHORIZED.value());
+  }
+
+  @Test
+  void lookupBin_withInvalidClientName_shouldReturn403() {
+    given()
+        .header("X-client-name", "invalid-client")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.UNAUTHORIZED.value());
+  }
+
+  @Test
+  void lookupBin_withEmptyClientName_shouldReturn403() {
+    given()
+        .header("X-client-name", "")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.UNAUTHORIZED.value());
+  }
+
+  @Test
+  void lookupBin_withEmptyToken_shouldReturn403() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", "")
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.UNAUTHORIZED.value());
+  }
+
+  @Test
+  void lookupBin_withReadAccessToken_shouldWork() {
+    given()
+        .header("X-client-name", "arsenal")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_READ)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.OK.value())
+        .body("bin_number", equalTo(512345));
+  }
+
+  // ========== P2 REGRESSION TESTS: Edge Cases ==========
+
+  @Test
+  void lookupBin_withMinimumValidLength_shouldWork() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/512345") // 6 digits - minimum
+        .then()
+        .statusCode(anyOf(equalTo(HttpStatus.OK.value()), equalTo(HttpStatus.NOT_FOUND.value())));
+  }
+
+  @Test
+  void lookupBin_withMaximumValidLength_shouldWork() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/123456789") // 9 digits - maximum
+        .then()
+        .statusCode(anyOf(equalTo(HttpStatus.OK.value()), equalTo(HttpStatus.NOT_FOUND.value())));
+  }
+
+  @Test
+  void lookupBin_withLeadingZeros_shouldHandleCorrectly() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/012345")
+        .then()
+        .statusCode(
+            anyOf(
+                equalTo(HttpStatus.OK.value()),
+                equalTo(HttpStatus.NOT_FOUND.value()),
+                equalTo(HttpStatus.BAD_REQUEST.value())));
+  }
+
+  @Test
+  void lookupBin_withAllZeros_shouldReturn400OrNotFound() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/000000")
+        .then()
+        .statusCode(
+            anyOf(equalTo(HttpStatus.BAD_REQUEST.value()), equalTo(HttpStatus.NOT_FOUND.value())));
+  }
+
+  @Test
+  void lookupBin_withWhitespace_shouldReturn400() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/123 456")
+        .then()
+        .statusCode(HttpStatus.BAD_REQUEST.value());
+  }
+
+  // ========== P2 REGRESSION TESTS: Response Validation ==========
+
+  @Test
+  void lookupBin_responseContainsAllMandatoryFields() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.OK.value())
+        .body("$", hasKey("bin_number"))
+        .body("$", hasKey("network"))
+        .body("$", hasKey("type"))
+        .body("$", hasKey("issuer"))
+        .body("$", hasKey("country"))
+        .body("$", hasKey("funding_source"))
+        .body("$", hasKey("status"));
+  }
+
+  @Test
+  void lookupBin_responseFieldsHaveCorrectTypes() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.OK.value())
+        .body("bin_number", isA(Integer.class))
+        .body("network", isA(String.class))
+        .body("type", isA(String.class))
+        .body("is_domestic", isA(Boolean.class));
+  }
+
+  @Test
+  void lookupBin_responseFieldsAreNonNull() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.OK.value())
+        .body("bin_number", notNullValue())
+        .body("network", notNullValue())
+        .body("type", notNullValue())
+        .body("issuer", notNullValue())
+        .body("country", notNullValue());
+  }
+
+  @Test
+  void lookupBin_responseUsesSnakeCase() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.OK.value())
+        .body("$", hasKey("bin_number"))
+        .body("$", hasKey("network_card_product"))
+        .body("$", hasKey("is_domestic"))
+        .body("$", hasKey("billing_currency"))
+        .body("$", hasKey("consumer_type"));
+  }
+
+  // ========== P2 REGRESSION TESTS: Different Card Networks ==========
+
+  @Test
+  void lookupBin_withAmexBin_shouldReturnCorrectly() {
+    // This tests AMEX BIN handling if exists in DB
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/370000") // AMEX starts with 34 or 37
+        .then()
+        .statusCode(anyOf(equalTo(HttpStatus.OK.value()), equalTo(HttpStatus.NOT_FOUND.value())));
+  }
+
+  @Test
+  void lookupBin_withDiscoverBin_shouldHandleCorrectly() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/601100") // Discover
+        .then()
+        .statusCode(anyOf(equalTo(HttpStatus.OK.value()), equalTo(HttpStatus.NOT_FOUND.value())));
+  }
+
+  // ========== P2 REGRESSION TESTS: Error Response Structure ==========
+
+  @Test
+  void lookupBin_notFound_shouldReturnProperErrorStructure() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/999999")
+        .then()
+        .statusCode(HttpStatus.NOT_FOUND.value())
+        .body("$", anyOf(hasKey("error"), hasKey("message"), hasKey("status")));
+  }
+
+  @Test
+  void lookupBin_badRequest_shouldReturnProperErrorStructure() {
+    given()
+        .header("X-client-name", "admin-service")
+        .header("X-client-token", BinTestDataUtil.TEST_AUTH_TOKEN_ADMIN)
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/ABC123")
+        .then()
+        .statusCode(HttpStatus.BAD_REQUEST.value())
+        .body("$", anyOf(hasKey("error"), hasKey("message"), hasKey("status")));
+  }
+
+  @Test
+  void lookupBin_unauthorized_shouldReturnProperErrorStructure() {
+    given()
+        .contentType(ContentType.JSON)
+        .when()
+        .get("/api/v1/bin/lookup/" + BinTestDataUtil.TEST_BIN_512345)
+        .then()
+        .statusCode(HttpStatus.UNAUTHORIZED.value())
+        .body("$", anyOf(hasKey("error"), hasKey("message"), hasKey("status")));
+  }
+}
diff --git a/bin-server/src/test/java/in/dreamplug/bin/slt/config/AwsTestConfiguration.java b/bin-server/src/test/java/in/dreamplug/bin/slt/config/AwsTestConfiguration.java
new file mode 100644
index 00000000..4fa599ae
--- /dev/null
+++ b/bin-server/src/test/java/in/dreamplug/bin/slt/config/AwsTestConfiguration.java
@@ -0,0 +1,26 @@
+package in.dreamplug.bin.slt.config;
+
+import in.dreamplug.bin.slt.BaseIntegrationTest;
+import org.springframework.boot.test.context.TestConfiguration;
+import org.springframework.context.annotation.Bean;
+import org.testcontainers.containers.localstack.LocalStackContainer;
+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;
+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;
+import software.amazon.awssdk.regions.Region;
+import software.amazon.awssdk.services.s3.S3Client;
+
+@TestConfiguration
+public class AwsTestConfiguration {
+
+  @Bean
+  public S3Client s3Client() {
+    LocalStackContainer localstack = BaseIntegrationTest.localstack;
+    return S3Client.builder()
+        .endpointOverride(localstack.getEndpointOverride(LocalStackContainer.Service.S3))
+        .credentialsProvider(
+            StaticCredentialsProvider.create(AwsBasicCredentials.create("test", "test")))
+        .region(Region.AP_SOUTH_1)
+        .forcePathStyle(true)
+        .build();
+  }
+}
diff --git a/bin-server/src/test/java/in/dreamplug/bin/slt/util/BinTestDataUtil.java b/bin-server/src/test/java/in/dreamplug/bin/slt/util/BinTestDataUtil.java
new file mode 100644
index 00000000..b1742b5d
--- /dev/null
+++ b/bin-server/src/test/java/in/dreamplug/bin/slt/util/BinTestDataUtil.java
@@ -0,0 +1,16 @@
+package in.dreamplug.bin.slt.util;
+
+/**
+ * Utility class for creating test data in SLT tests.
+ *
+ * @author Sourav Singh
+ */
+public class BinTestDataUtil {
+
+  public static final String TEST_BIN_512345 = "512345";
+  public static final String TEST_BIN_487654 = "487654";
+  public static final String TEST_BIN_654321 = "654321";
+
+  public static final String TEST_AUTH_TOKEN_ADMIN = "admin-token-dev";
+  public static final String TEST_AUTH_TOKEN_READ = "read-token-dev";
+}
diff --git a/bin-server/src/test/java/in/dreamplug/bin/slt/util/LocalStackUtil.java b/bin-server/src/test/java/in/dreamplug/bin/slt/util/LocalStackUtil.java
new file mode 100644
index 00000000..eaa67d92
--- /dev/null
+++ b/bin-server/src/test/java/in/dreamplug/bin/slt/util/LocalStackUtil.java
@@ -0,0 +1,44 @@
+package in.dreamplug.bin.slt.util;
+
+import java.io.IOException;
+import org.testcontainers.containers.localstack.LocalStackContainer;
+
+/**
+ * Utility class for LocalStack operations in SLT tests.
+ *
+ * @author Sourav Singh
+ */
+public class LocalStackUtil {
+
+  public static void createQueue(LocalStackContainer localstack, String queueName)
+      throws IOException, InterruptedException {
+    localstack.execInContainer(
+        "awslocal", "sqs", "create-queue", "--queue-name", queueName, "--region", "ap-south-1");
+  }
+
+  public static void purgeQueue(LocalStackContainer localstack, String queueName)
+      throws IOException, InterruptedException {
+    localstack.execInContainer(
+        "awslocal",
+        "sqs",
+        "purge-queue",
+        "--queue-url",
+        "http://localhost:4566/000000000000/" + queueName,
+        "--region",
+        "ap-south-1");
+  }
+
+  public static void sendMessage(LocalStackContainer localstack, String queueUrl, String message)
+      throws IOException, InterruptedException {
+    localstack.execInContainer(
+        "awslocal",
+        "sqs",
+        "send-message",
+        "--queue-url",
+        queueUrl,
+        "--message-body",
+        message,
+        "--region",
+        "ap-south-1");
+  }
+}
diff --git a/bin-server/src/test/resources/application-test.properties b/bin-server/src/test/resources/application-test.properties
new file mode 100644
index 00000000..223dcdcf
--- /dev/null
+++ b/bin-server/src/test/resources/application-test.properties
@@ -0,0 +1,25 @@
+# Server
+server.port=0
+spring.main.banner-mode=off
+
+# Database - will be overridden by @DynamicPropertySource
+spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
+spring.jpa.hibernate.ddl-auto=none
+spring.jpa.show-sql=false
+
+# AWS - will be overridden by @DynamicPropertySource
+aws.sqs.enabled=true
+
+# Authentication configuration for tests
+auth.clients[0].name=admin-service
+auth.clients[0].token=admin-token-dev
+auth.clients[0].access-level=ADMIN
+
+auth.clients[1].name=arsenal
+auth.clients[1].token=read-token-dev
+auth.clients[1].access-level=READ
+
+# Disable unnecessary features in tests
+scheduler.bin-deactivation.enabled=false
+statsd.configuration.enabled=false
+management.metrics.export.cloudwatch.enabled=false
diff --git a/bin-server/src/test/resources/coverage-dashboard-template.html b/bin-server/src/test/resources/coverage-dashboard-template.html
new file mode 100644
index 00000000..f5859365
--- /dev/null
+++ b/bin-server/src/test/resources/coverage-dashboard-template.html
@@ -0,0 +1,437 @@
+<!DOCTYPE html>
+<html lang="en">
+<head>
+    <meta charset="UTF-8">
+    <meta name="viewport" content="width=device-width, initial-scale=1.0">
+    <title>BIN Atlas - SLT Coverage Dashboard</title>
+    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
+    <link rel="stylesheet" href="dashboard.css">
+    <style>
+        * {
+            margin: 0;
+            padding: 0;
+            box-sizing: border-box;
+        }
+
+        body {
+            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
+            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
+            padding: 20px;
+            min-height: 100vh;
+        }
+
+        .container {
+            max-width: 1400px;
+            margin: 0 auto;
+        }
+
+        .header {
+            background: white;
+            border-radius: 12px;
+            padding: 30px;
+            margin-bottom: 20px;
+            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
+        }
+
+        .header h1 {
+            color: #2d3748;
+            font-size: 32px;
+            margin-bottom: 10px;
+        }
+
+        .header p {
+            color: #718096;
+            font-size: 16px;
+        }
+
+        /* Hero Metric - Service Level Coverage */
+        .hero-metric {
+            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
+            border-radius: 16px;
+            padding: 40px;
+            margin-bottom: 20px;
+            box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);
+            color: white;
+            text-align: center;
+        }
+
+        .hero-metric h2 {
+            font-size: 24px;
+            margin-bottom: 10px;
+            font-weight: 600;
+            opacity: 0.95;
+        }
+
+        .hero-metric .hero-value {
+            font-size: 72px;
+            font-weight: 700;
+            margin: 20px 0;
+            text-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
+        }
+
+        .hero-metric .hero-label {
+            font-size: 18px;
+            opacity: 0.9;
+            margin-bottom: 15px;
+        }
+
+        .hero-metric .hero-definition {
+            font-size: 16px;
+            opacity: 0.85;
+            max-width: 800px;
+            margin: 0 auto;
+            line-height: 1.6;
+            padding: 15px;
+            background: rgba(255, 255, 255, 0.1);
+            border-radius: 8px;
+        }
+
+        .metrics-grid {
+            display: grid;
+            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
+            gap: 20px;
+            margin-bottom: 20px;
+        }
+
+        .metric-card {
+            background: white;
+            border-radius: 12px;
+            padding: 25px;
+            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
+            transition: transform 0.2s;
+        }
+
+        .metric-card:hover {
+            transform: translateY(-5px);
+            box-shadow: 0 8px 12px rgba(0, 0, 0, 0.15);
+        }
+
+        .metric-card h3 {
+            color: #4a5568;
+            font-size: 14px;
+            font-weight: 600;
+            text-transform: uppercase;
+            letter-spacing: 0.5px;
+            margin-bottom: 15px;
+        }
+
+        .metric-value {
+            font-size: 48px;
+            font-weight: 700;
+            margin-bottom: 10px;
+        }
+
+        .metric-label {
+            color: #718096;
+            font-size: 14px;
+            margin-bottom: 12px;
+            font-weight: 500;
+        }
+
+        .metric-definition {
+            color: #4a5568;
+            font-size: 12px;
+            line-height: 1.5;
+            padding: 10px;
+            background: #f7fafc;
+            border-radius: 6px;
+            border-left: 3px solid #667eea;
+            margin-top: 10px;
+        }
+
+        .success { color: #48bb78; }
+        .warning { color: #ed8936; }
+        .info { color: #4299e1; }
+        .primary { color: #667eea; }
+
+        .charts-grid {
+            display: grid;
+            grid-template-columns: repeat(auto-fit, minmax(450px, 1fr));
+            gap: 20px;
+            margin-bottom: 20px;
+        }
+
+        .chart-card {
+            background: white;
+            border-radius: 12px;
+            padding: 25px;
+            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
+        }
+
+        .chart-card h2 {
+            color: #2d3748;
+            font-size: 18px;
+            margin-bottom: 10px;
+            text-align: center;
+        }
+
+        .chart-card .chart-description {
+            color: #718096;
+            font-size: 13px;
+            text-align: center;
+            margin-bottom: 20px;
+            font-style: italic;
+        }
+
+        .chart-container {
+            position: relative;
+            height: 300px;
+            margin-bottom: 20px;
+        }
+
+        .details-section {
+            background: white;
+            border-radius: 12px;
+            padding: 25px;
+            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
+            margin-bottom: 20px;
+        }
+
+        .details-section h2 {
+            color: #2d3748;
+            font-size: 20px;
+            margin-bottom: 10px;
+            border-bottom: 2px solid #e2e8f0;
+            padding-bottom: 10px;
+        }
+
+        .details-section .section-description {
+            color: #718096;
+            font-size: 14px;
+            margin-bottom: 20px;
+            font-style: italic;
+        }
+
+        .package-list {
+            display: grid;
+            gap: 15px;
+        }
+
+        .package-item {
+            background: #f7fafc;
+            border-radius: 8px;
+            padding: 15px;
+            border-left: 4px solid #667eea;
+        }
+
+        .package-header {
+            display: flex;
+            justify-content: space-between;
+            align-items: center;
+            margin-bottom: 10px;
+        }
+
+        .package-name {
+            font-weight: 600;
+            color: #2d3748;
+            font-size: 14px;
+        }
+
+        .package-coverage {
+            font-weight: 700;
+            font-size: 18px;
+        }
+
+        .progress-bar {
+            height: 8px;
+            background: #e2e8f0;
+            border-radius: 4px;
+            overflow: hidden;
+        }
+
+        .progress-fill {
+            height: 100%;
+            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
+            transition: width 0.3s ease;
+        }
+
+        .info-box {
+            background: #edf2f7;
+            border-left: 4px solid #4299e1;
+            padding: 15px;
+            border-radius: 8px;
+            margin-bottom: 20px;
+        }
+
+        .info-box h3 {
+            color: #2d3748;
+            font-size: 16px;
+            margin-bottom: 10px;
+        }
+
+        .info-box p {
+            color: #4a5568;
+            font-size: 14px;
+            line-height: 1.6;
+            margin-bottom: 8px;
+        }
+
+        .footer {
+            background: white;
+            border-radius: 12px;
+            padding: 20px;
+            margin-top: 20px;
+            text-align: center;
+            color: #718096;
+            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
+        }
+
+        .footer a {
+            color: #667eea;
+            text-decoration: none;
+            font-weight: 600;
+        }
+
+        .footer a:hover {
+            text-decoration: underline;
+        }
+
+        .badge {
+            display: inline-block;
+            padding: 4px 12px;
+            border-radius: 12px;
+            font-size: 12px;
+            font-weight: 600;
+            margin-left: 10px;
+        }
+
+        .badge-success {
+            background: #c6f6d5;
+            color: #22543d;
+        }
+
+        .badge-warning {
+            background: #feebc8;
+            color: #7c2d12;
+        }
+
+        .badge-danger {
+            background: #fed7d7;
+            color: #742a2a;
+        }
+    </style>
+</head>
+<body>
+    <div class="container">
+        <!-- Header -->
+        <div class="header">
+            <h1>ğŸ“Š BIN Atlas - Service Level Test Coverage Dashboard</h1>
+            <p>Build #<span id="buildNumber">{{BUILD_NUMBER}}</span> | Branch: <span id="branch">{{BRANCH}}</span> | Date: <span id="date">{{DATE}}</span></p>
+        </div>
+
+        <!-- Hero Metric: Service Level Coverage -->
+        <div class="hero-metric">
+            <h2>ğŸ¯ Service Level Test Coverage</h2>
+            <div class="hero-value" id="serviceLevelCoverage">{{INSTRUCTION_COVERAGE}}%</div>
+            <div class="hero-label">Overall service coverage across all modules</div>
+            <div class="hero-definition">
+                <strong>What this means:</strong> This is the percentage of your entire BIN Atlas service code (all modules combined) that gets executed when SLT tests run.
+                It shows how much of your service is actually tested end-to-end through real API calls. Higher is better - aim for 70%+.
+            </div>
+        </div>
+
+        <!-- Key Metrics -->
+        <div class="metrics-grid">
+            <div class="metric-card">
+                <h3>ğŸ“ Total Tests</h3>
+                <div class="metric-value primary" id="totalTests">{{TOTAL_TESTS}}</div>
+                <div class="metric-label">Test cases executed</div>
+                <div class="metric-definition">
+                    The total number of automated SLT test cases that ran during this build. Each test validates a specific API scenario (happy path, error case, edge case, etc.).
+                </div>
+            </div>
+            <div class="metric-card">
+                <h3>âœ… Test Success Rate</h3>
+                <div class="metric-value success" id="successRate">{{SUCCESS_RATE}}%</div>
+                <div class="metric-label">Passed tests</div>
+                <div class="metric-definition">
+                    Percentage of tests that passed without failures. 100% means all test scenarios are working correctly. Below 100% means some APIs are broken or returning unexpected results.
+                </div>
+            </div>
+            <div class="metric-card">
+                <h3>ğŸ“ˆ Instruction Coverage</h3>
+                <div class="metric-value info" id="instructionCoverage">{{INSTRUCTION_COVERAGE}}%</div>
+                <div class="metric-label">Code instructions tested</div>
+                <div class="metric-definition">
+                    Shows what % of compiled Java bytecode instructions were executed during tests. Most accurate coverage metric - it measures actual code execution at the lowest level.
+                </div>
+            </div>
+            <div class="metric-card">
+                <h3>ğŸŒ¿ Branch Coverage</h3>
+                <div class="metric-value warning" id="branchCoverage">{{BRANCH_COVERAGE}}%</div>
+                <div class="metric-label">Decision paths tested</div>
+                <div class="metric-definition">
+                    Measures how many if/else branches, switch cases, and try/catch blocks were tested. Example: if you have "if (x > 0)" - did tests check both true and false cases?
+                </div>
+            </div>
+        </div>
+
+        <!-- Info Box -->
+        <div class="info-box">
+            <h3>ğŸ’¡ Understanding Coverage Metrics</h3>
+            <p><strong>Why is overall coverage {{INSTRUCTION_COVERAGE}}%?</strong> This is expected! SLT tests focus on testing your <strong>service APIs end-to-end</strong>, not every single line of code.</p>
+            <p><strong>What's good coverage?</strong> For service-level tests: 60-80% is excellent. You're testing critical user journeys, not utility functions.</p>
+            <p><strong>Low coverage areas:</strong> Internal utilities, data mappers, and helper classes often have low coverage in SLT - that's fine! Add unit tests for those.</p>
+        </div>
+
+        <!-- Charts -->
+        <div class="charts-grid">
+            <!-- Overall Coverage Chart -->
+            <div class="chart-card">
+                <h2>ğŸ“Š Service Coverage Breakdown</h2>
+                <p class="chart-description">How much of the service is covered by SLT tests</p>
+                <div class="chart-container">
+                    <canvas id="overallCoverageChart"></canvas>
+                </div>
+            </div>
+
+            <!-- Test Distribution Chart -->
+            <div class="chart-card">
+                <h2>ğŸ§ª Test Priority Distribution</h2>
+                <p class="chart-description">Test cases grouped by priority (P0 = critical, P1 = important, P2 = nice-to-have)</p>
+                <div class="chart-container">
+                    <canvas id="testDistributionChart"></canvas>
+                </div>
+            </div>
+
+            <!-- Coverage by Type Chart -->
+            <div class="chart-card">
+                <h2>ğŸ“ˆ Coverage Metrics Comparison</h2>
+                <p class="chart-description">Different ways to measure test coverage (instruction is most accurate)</p>
+                <div class="chart-container">
+                    <canvas id="coverageMetricsChart"></canvas>
+                </div>
+            </div>
+
+            <!-- Top Packages Chart -->
+            <div class="chart-card">
+                <h2>ğŸ“¦ Top 5 Module Coverage</h2>
+                <p class="chart-description">Which modules/packages have the best test coverage</p>
+                <div class="chart-container">
+                    <canvas id="topPackagesChart"></canvas>
+                </div>
+            </div>
+        </div>
+
+        <!-- Package Details -->
+        <div class="details-section">
+            <h2>ğŸ“¦ Module-Level Coverage Details</h2>
+            <p class="section-description">Coverage breakdown by module/package - shows which parts of your service are well-tested</p>
+            <div class="package-list" id="packageList">
+                <!-- Dynamically populated -->
+            </div>
+        </div>
+
+        <!-- Footer -->
+        <div class="footer">
+            <p>Generated by BIN Atlas SLT Pipeline |
+               <a href="{{JACOCO_REPORT_URL}}" target="_blank">View Detailed JaCoCo Report</a> |
+               <a href="{{TEST_REPORT_URL}}" target="_blank">View Test Results</a>
+            </p>
+            <p style="margin-top: 10px; font-size: 12px;">Â© 2026 CSIT Team - BIN Atlas Service</p>
+        </div>
+    </div>
+
+    <script src="dashboard.js"></script>
+</body>
+</html>
diff --git a/bin-server/src/test/resources/dashboard.css b/bin-server/src/test/resources/dashboard.css
new file mode 100644
index 00000000..b0c0d5ae
--- /dev/null
+++ b/bin-server/src/test/resources/dashboard.css
@@ -0,0 +1,302 @@
+        * {
+            margin: 0;
+            padding: 0;
+            box-sizing: border-box;
+        }
+
+        body {
+            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
+            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
+            padding: 20px;
+            min-height: 100vh;
+        }
+
+        .container {
+            max-width: 1400px;
+            margin: 0 auto;
+        }
+
+        .header {
+            background: white;
+            border-radius: 12px;
+            padding: 30px;
+            margin-bottom: 20px;
+            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
+        }
+
+        .header h1 {
+            color: #2d3748;
+            font-size: 32px;
+            margin-bottom: 10px;
+        }
+
+        .header p {
+            color: #718096;
+            font-size: 16px;
+        }
+
+        /* Hero Metric - Service Level Coverage */
+        .hero-metric {
+            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
+            border-radius: 16px;
+            padding: 40px;
+            margin-bottom: 20px;
+            box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);
+            color: white;
+            text-align: center;
+        }
+
+        .hero-metric h2 {
+            font-size: 24px;
+            margin-bottom: 10px;
+            font-weight: 600;
+            opacity: 0.95;
+        }
+
+        .hero-metric .hero-value {
+            font-size: 72px;
+            font-weight: 700;
+            margin: 20px 0;
+            text-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
+        }
+
+        .hero-metric .hero-label {
+            font-size: 18px;
+            opacity: 0.9;
+            margin-bottom: 15px;
+        }
+
+        .hero-metric .hero-definition {
+            font-size: 16px;
+            opacity: 0.85;
+            max-width: 800px;
+            margin: 0 auto;
+            line-height: 1.6;
+            padding: 15px;
+            background: rgba(255, 255, 255, 0.1);
+            border-radius: 8px;
+        }
+
+        .metrics-grid {
+            display: grid;
+            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
+            gap: 20px;
+            margin-bottom: 20px;
+        }
+
+        .metric-card {
+            background: white;
+            border-radius: 12px;
+            padding: 25px;
+            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
+            transition: transform 0.2s;
+        }
+
+        .metric-card:hover {
+            transform: translateY(-5px);
+            box-shadow: 0 8px 12px rgba(0, 0, 0, 0.15);
+        }
+
+        .metric-card h3 {
+            color: #4a5568;
+            font-size: 14px;
+            font-weight: 600;
+            text-transform: uppercase;
+            letter-spacing: 0.5px;
+            margin-bottom: 15px;
+        }
+
+        .metric-value {
+            font-size: 48px;
+            font-weight: 700;
+            margin-bottom: 10px;
+        }
+
+        .metric-label {
+            color: #718096;
+            font-size: 14px;
+            margin-bottom: 12px;
+            font-weight: 500;
+        }
+
+        .metric-definition {
+            color: #4a5568;
+            font-size: 12px;
+            line-height: 1.5;
+            padding: 10px;
+            background: #f7fafc;
+            border-radius: 6px;
+            border-left: 3px solid #667eea;
+            margin-top: 10px;
+        }
+
+        .success { color: #48bb78; }
+        .warning { color: #ed8936; }
+        .info { color: #4299e1; }
+        .primary { color: #667eea; }
+
+        .charts-grid {
+            display: grid;
+            grid-template-columns: repeat(auto-fit, minmax(450px, 1fr));
+            gap: 20px;
+            margin-bottom: 20px;
+        }
+
+        .chart-card {
+            background: white;
+            border-radius: 12px;
+            padding: 25px;
+            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
+        }
+
+        .chart-card h2 {
+            color: #2d3748;
+            font-size: 18px;
+            margin-bottom: 10px;
+            text-align: center;
+        }
+
+        .chart-card .chart-description {
+            color: #718096;
+            font-size: 13px;
+            text-align: center;
+            margin-bottom: 20px;
+            font-style: italic;
+        }
+
+        .chart-container {
+            position: relative;
+            height: 300px;
+            margin-bottom: 20px;
+        }
+
+        .details-section {
+            background: white;
+            border-radius: 12px;
+            padding: 25px;
+            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
+            margin-bottom: 20px;
+        }
+
+        .details-section h2 {
+            color: #2d3748;
+            font-size: 20px;
+            margin-bottom: 10px;
+            border-bottom: 2px solid #e2e8f0;
+            padding-bottom: 10px;
+        }
+
+        .details-section .section-description {
+            color: #718096;
+            font-size: 14px;
+            margin-bottom: 20px;
+            font-style: italic;
+        }
+
+        .package-list {
+            display: grid;
+            gap: 15px;
+        }
+
+        .package-item {
+            background: #f7fafc;
+            border-radius: 8px;
+            padding: 15px;
+            border-left: 4px solid #667eea;
+        }
+
+        .package-header {
+            display: flex;
+            justify-content: space-between;
+            align-items: center;
+            margin-bottom: 10px;
+        }
+
+        .package-name {
+            font-weight: 600;
+            color: #2d3748;
+            font-size: 14px;
+        }
+
+        .package-coverage {
+            font-weight: 700;
+            font-size: 18px;
+        }
+
+        .progress-bar {
+            height: 8px;
+            background: #e2e8f0;
+            border-radius: 4px;
+            overflow: hidden;
+        }
+
+        .progress-fill {
+            height: 100%;
+            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
+            transition: width 0.3s ease;
+        }
+
+        .info-box {
+            background: #edf2f7;
+            border-left: 4px solid #4299e1;
+            padding: 15px;
+            border-radius: 8px;
+            margin-bottom: 20px;
+        }
+
+        .info-box h3 {
+            color: #2d3748;
+            font-size: 16px;
+            margin-bottom: 10px;
+        }
+
+        .info-box p {
+            color: #4a5568;
+            font-size: 14px;
+            line-height: 1.6;
+            margin-bottom: 8px;
+        }
+
+        .footer {
+            background: white;
+            border-radius: 12px;
+            padding: 20px;
+            margin-top: 20px;
+            text-align: center;
+            color: #718096;
+            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
+        }
+
+        .footer a {
+            color: #667eea;
+            text-decoration: none;
+            font-weight: 600;
+        }
+
+        .footer a:hover {
+            text-decoration: underline;
+        }
+
+        .badge {
+            display: inline-block;
+            padding: 4px 12px;
+            border-radius: 12px;
+            font-size: 12px;
+            font-weight: 600;
+            margin-left: 10px;
+        }
+
+        .badge-success {
+            background: #c6f6d5;
+            color: #22543d;
+        }
+
+        .badge-warning {
+            background: #feebc8;
+            color: #7c2d12;
+        }
+
+        .badge-danger {
+            background: #fed7d7;
+            color: #742a2a;
+        }
diff --git a/bin-server/src/test/resources/dashboard.js b/bin-server/src/test/resources/dashboard.js
new file mode 100644
index 00000000..c590a32f
--- /dev/null
+++ b/bin-server/src/test/resources/dashboard.js
@@ -0,0 +1,197 @@
+// Sample data - will be replaced with actual data from Jenkins
+const coverageData = {
+    buildNumber: '{{BUILD_NUMBER}}',
+    branch: '{{BRANCH}}',
+    date: '{{DATE}}',
+    totalTests: {{TOTAL_TESTS}},
+    successRate: {{SUCCESS_RATE}},
+    instructionCoverage: {{INSTRUCTION_COVERAGE}},
+    branchCoverage: {{BRANCH_COVERAGE}},
+    lineCoverage: {{LINE_COVERAGE}},
+    methodCoverage: {{METHOD_COVERAGE}},
+    classCoverage: {{CLASS_COVERAGE}},
+    testDistribution: {
+        p0: {{P0_TESTS}},
+        p1: {{P1_TESTS}},
+        p2: {{P2_TESTS}}
+    },
+    topPackages: [
+        { name: 'core.service', coverage: 76 },
+        { name: 'manager.service', coverage: 7 },
+        { name: 'egress.service', coverage: 12 },
+        { name: 'ingress.controller', coverage: 19 },
+        { name: 'core.parser', coverage: 38 }
+    ]
+};
+
+// Overall Coverage Pie Chart
+const overallCoverageCtx = document.getElementById('overallCoverageChart').getContext('2d');
+new Chart(overallCoverageCtx, {
+    type: 'doughnut',
+    data: {
+        labels: ['Tested by SLT', 'Not Yet Tested'],
+        datasets: [{
+            data: [coverageData.instructionCoverage, 100 - coverageData.instructionCoverage],
+            backgroundColor: ['#48bb78', '#e2e8f0'],
+            borderWidth: 0
+        }]
+    },
+    options: {
+        responsive: true,
+        maintainAspectRatio: false,
+        plugins: {
+            legend: {
+                position: 'bottom'
+            },
+            tooltip: {
+                callbacks: {
+                    label: function(context) {
+                        return context.label + ': ' + context.parsed + '%';
+                    }
+                }
+            }
+        }
+    }
+});
+
+// Test Distribution Pie Chart
+const testDistCtx = document.getElementById('testDistributionChart').getContext('2d');
+new Chart(testDistCtx, {
+    type: 'pie',
+    data: {
+        labels: ['P0 - Critical/Sanity', 'P1 - Important/Regression', 'P2 - Edge Cases'],
+        datasets: [{
+            data: [
+                coverageData.testDistribution.p0,
+                coverageData.testDistribution.p1,
+                coverageData.testDistribution.p2
+            ],
+            backgroundColor: ['#667eea', '#4299e1', '#ed8936'],
+            borderWidth: 0
+        }]
+    },
+    options: {
+        responsive: true,
+        maintainAspectRatio: false,
+        plugins: {
+            legend: {
+                position: 'bottom'
+            }
+        }
+    }
+});
+
+// Coverage Metrics Bar Chart
+const metricsCtx = document.getElementById('coverageMetricsChart').getContext('2d');
+new Chart(metricsCtx, {
+    type: 'bar',
+    data: {
+        labels: ['Instruction', 'Branch', 'Line', 'Method', 'Class'],
+        datasets: [{
+            label: 'Coverage %',
+            data: [
+                coverageData.instructionCoverage,
+                coverageData.branchCoverage,
+                coverageData.lineCoverage,
+                coverageData.methodCoverage,
+                coverageData.classCoverage
+            ],
+            backgroundColor: [
+                '#667eea',
+                '#ed8936',
+                '#4299e1',
+                '#48bb78',
+                '#9f7aea'
+            ],
+            borderRadius: 8
+        }]
+    },
+    options: {
+        responsive: true,
+        maintainAspectRatio: false,
+        scales: {
+            y: {
+                beginAtZero: true,
+                max: 100,
+                ticks: {
+                    callback: function(value) {
+                        return value + '%';
+                    }
+                }
+            }
+        },
+        plugins: {
+            legend: {
+                display: false
+            }
+        }
+    }
+});
+
+// Top Packages Horizontal Bar Chart
+const packagesCtx = document.getElementById('topPackagesChart').getContext('2d');
+new Chart(packagesCtx, {
+    type: 'bar',
+    data: {
+        labels: coverageData.topPackages.map(p => p.name),
+        datasets: [{
+            label: 'Coverage %',
+            data: coverageData.topPackages.map(p => p.coverage),
+            backgroundColor: '#764ba2',
+            borderRadius: 8
+        }]
+    },
+    options: {
+        indexAxis: 'y',
+        responsive: true,
+        maintainAspectRatio: false,
+        scales: {
+            x: {
+                beginAtZero: true,
+                max: 100,
+                ticks: {
+                    callback: function(value) {
+                        return value + '%';
+                    }
+                }
+            }
+        },
+        plugins: {
+            legend: {
+                display: false
+            }
+        }
+    }
+});
+
+// Populate package list
+function populatePackageList() {
+    const packageList = document.getElementById('packageList');
+    coverageData.topPackages.forEach(pkg => {
+        const item = document.createElement('div');
+        item.className = 'package-item';
+
+        let badge = '';
+        if (pkg.coverage >= 70) {
+            badge = '<span class="badge badge-success">Excellent</span>';
+        } else if (pkg.coverage >= 50) {
+            badge = '<span class="badge badge-warning">Good</span>';
+        } else {
+            badge = '<span class="badge badge-danger">Needs Work</span>';
+        }
+
+        item.innerHTML = `
+            <div class="package-header">
+                <span class="package-name">ğŸ“¦ ${pkg.name}</span>
+                <span class="package-coverage ${pkg.coverage >= 70 ? 'success' : pkg.coverage >= 50 ? 'warning' : 'warning'}">${pkg.coverage}%</span>
+            </div>
+            ${badge}
+            <div class="progress-bar" style="margin-top: 10px;">
+                <div class="progress-fill" style="width: ${pkg.coverage}%"></div>
+            </div>
+        `;
+        packageList.appendChild(item);
+    });
+}
+
+populatePackageList();
diff --git a/bin-server/src/test/resources/init.sql b/bin-server/src/test/resources/init.sql
new file mode 100644
index 00000000..ac59d619
--- /dev/null
+++ b/bin-server/src/test/resources/init.sql
@@ -0,0 +1,62 @@
+-- Create bins table
+CREATE TABLE IF NOT EXISTS `bins` (
+    `id` BIGINT NOT NULL AUTO_INCREMENT,
+    `external_id` VARCHAR(50) NOT NULL,
+    `bin_number` BIGINT NOT NULL,
+    `bin_range_low` DECIMAL(30,0) NOT NULL,
+    `bin_range_high` DECIMAL(30,0) NOT NULL,
+    `bin_range_low_padded` DECIMAL(30,0) NOT NULL,
+    `bin_range_high_padded` DECIMAL(30,0) NOT NULL,
+    `network` VARCHAR(20) NOT NULL,
+    `bin_length` BIGINT NOT NULL,
+    `pan_length` BIGINT NOT NULL,
+    `country` VARCHAR(50) NOT NULL,
+    `issuer` VARCHAR(200) NOT NULL,
+    `ingestion_id` BIGINT NOT NULL,
+    `ingestion_batch_id` BIGINT NOT NULL,
+    `type` VARCHAR(20) NOT NULL,
+    `funding_source` VARCHAR(50) NOT NULL,
+    `network_card_product` VARCHAR(50),
+    `is_domestic` BOOLEAN NOT NULL,
+    `billing_currency` VARCHAR(50) NOT NULL,
+    `status` VARCHAR(50) NOT NULL,
+    `consumer_type` VARCHAR(50),
+    `created_at` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
+    `updated_at` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
+    PRIMARY KEY (`id`),
+    INDEX `idx_bin_number` (`bin_number`),
+    INDEX `idx_status` (`status`)
+) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
+
+-- Insert test data for BIN lookup tests
+INSERT INTO `bins` (
+    external_id, bin_number, bin_range_low, bin_range_high,
+    bin_range_low_padded, bin_range_high_padded, network,
+    bin_length, pan_length, country, issuer, ingestion_id,
+    ingestion_batch_id, type, funding_source, network_card_product,
+    is_domestic, billing_currency, status, consumer_type
+) VALUES
+    -- VISA Credit Card - HDFC Bank
+    (
+        'test-bin-512345', 512345, 51234500000000, 51234599999999,
+        512345000000000000000, 512345999999999999999, 'VISA',
+        6, 16, 'India', 'HDFC Bank', 1,
+        1, 'CREDIT', 'CREDIT', 'VISA_SIGNATURE',
+        true, 'INR', 'ACTIVE', 'PERSONAL'
+    ),
+    -- MASTERCARD Debit Card - ICICI Bank
+    (
+        'test-bin-487654', 487654, 48765400000000, 48765499999999,
+        487654000000000000000, 487654999999999999999, 'MASTERCARD',
+        6, 16, 'India', 'ICICI Bank', 1,
+        1, 'DEBIT', 'DEBIT', 'MASTERCARD_WORLD',
+        true, 'INR', 'ACTIVE', 'PERSONAL'
+    ),
+    -- RUPAY Credit Card - SBI
+    (
+        'test-bin-654321', 654321, 65432100000000, 65432199999999,
+        654321000000000000000, 654321999999999999999, 'RUPAY',
+        6, 16, 'India', 'SBI', 1,
+        1, 'CREDIT', 'CREDIT', 'RUPAY_PLATINUM',
+        true, 'INR', 'ACTIVE', 'PERSONAL'
+    );
diff --git a/bin-server/src/test/resources/testcontainers.properties b/bin-server/src/test/resources/testcontainers.properties
new file mode 100644
index 00000000..54d83f08
--- /dev/null
+++ b/bin-server/src/test/resources/testcontainers.properties
@@ -0,0 +1,5 @@
+# Disable Ryuk (resource cleanup container) for Rancher Desktop compatibility
+testcontainers.reuse.enable=true
+ryuk.container.image=testcontainers/ryuk:0.5.1
+ryuk.container.privileged=true
+docker.client.strategy=org.testcontainers.dockerclient.UnixSocketClientProviderStrategy
diff --git a/codepipeline/Jenkinsfile.env-stage-ci-with-slt.groovy b/codepipeline/Jenkinsfile.env-stage-ci-with-slt.groovy
new file mode 100644
index 00000000..c8da18d7
--- /dev/null
+++ b/codepipeline/Jenkinsfile.env-stage-ci-with-slt.groovy
@@ -0,0 +1,328 @@
+#!groovy
+
+pipeline {
+    agent any
+    // !!! Please set these DP_* env variables carefully
+    // if a cfn stack is not defined in DP_ENV_SUFFIX_CFNS, then caterpillar will try to create a new cloudformation stack
+
+    environment {
+        JK_SEED_JSON = credentials('jkrunenv')
+        DP_RUN_ENVS = 'stage'
+        DP_ENV_SUFFIX_CFNS = 'stage::bin-atlas-cfn'
+        //sonar tags convention: pod, pod-sub-pod,env Note: underscore is not allowed
+        DP_SONAR_TAGS = "stage,csit"
+        // Slack channel for SLT notifications
+        SLACK_CHANNEL = '#payments_slt_report_and_coverage'
+    }
+    options {
+//        disableConcurrentBuilds()
+        preserveStashes(buildCount: 7)
+        buildDiscarder(logRotator(numToKeepStr: '50', artifactNumToKeepStr: '50'))
+    }
+//    triggers {
+//         monday to friday, between 10:30 IST 18:30 IST, every 30 minute
+//        cron('H/30 5-13 * * 1-5')
+//    }
+    stages {
+        stage('prepare') {
+            agent {
+                docker {
+                    image 'credsre/caterpillar:latest'
+                    registryCredentialsId 'credsre_docker'
+                    alwaysPull true
+                }
+            }
+            steps {
+                sh "/opt/caterpillar/bin/seed.sh"
+                sh '/opt/caterpillar/utils/env/entrypoint.sh'
+                stash name: 'caterpillar', includes: '**'
+            }
+        }
+
+        stage('security') {
+            agent {
+                docker {
+                    image 'credsre/codepipeline-security:cps'
+                    registryCredentialsId 'credsre_docker'
+                    alwaysPull true
+                }
+            }
+            steps {
+                unstash 'caterpillar'
+                sh "${env.WORKSPACE}/caterpillar/utils/env/entrypoint.sh"
+            }
+        }
+
+        stage('build') {
+            agent {
+                docker {
+                    image 'credsre/gradle-ssm:8.5-corettojdk-21'
+                    registryCredentialsId 'credsre_docker'
+                    args "-v $HOME/.m2:/root/.m2 -v $HOME/$JOB_NAME/$BUILD_NUMBER/.gradle:/root/.gradle"
+                }
+            }
+
+            environment {
+                DP_SSM_KEYS = '{"prefixed_keys":[{"prefix":"/conf/nexus/central/v1","region":"ap-south-1",' +
+                        '"keys":{"DP_NEXUS_URL":{},"DP_NEXUS_USER":{},"DP_NEXUS_PASS":{}}},' +
+                        '{"prefix":"/conf/github-release/central/v1","region":"ap-south-1",' +
+                        '"keys":{"DP_ID_RSA":{}}}]}'
+                some_key = 'some_val'
+            }
+            steps {
+                unstash 'caterpillar'
+                sh "${env.WORKSPACE}/caterpillar/bin/preclean.sh"
+                sh "${env.WORKSPACE}/caterpillar/utils/env/entrypoint.sh bash -xe " +
+                        "${env.WORKSPACE}/codepipeline-stage/buildspec.sh"
+                // Please change following line, according to your build system output
+                stash name: 'jar', includes: 'bin-server/build/libs/bin-server-0.0.1.jar'
+                stash name: 'build_step', includes: '**'
+            }
+        }
+
+        stage('service-level-tests') {
+            agent {
+                docker {
+                    image 'credsre/gradle-ssm:8.5-corettojdk-21'
+                    registryCredentialsId 'credsre_docker'
+                    args "-v $HOME/.m2:/root/.m2 -v $HOME/$JOB_NAME/$BUILD_NUMBER/.gradle:/root/.gradle -v /var/run/docker.sock:/var/run/docker.sock"
+                }
+            }
+            environment {
+                CI = 'true'
+                DOCKER_HOST = 'unix:///var/run/docker.sock'
+                TESTCONTAINERS_RYUK_DISABLED = 'false'
+                DP_SSM_KEYS = '{"prefixed_keys":[{"prefix":"/conf/nexus/central/v1","region":"ap-south-1",' +
+                        '"keys":{"DP_NEXUS_URL":{},"DP_NEXUS_USER":{},"DP_NEXUS_PASS":{}}}]}'
+            }
+            steps {
+                script {
+                    unstash 'caterpillar'
+                    unstash 'build_step'
+
+                    try {
+                        // Run SLT tests with Testcontainers
+                        sh '''
+                            echo "ğŸ§ª Starting Service Level Tests (SLT) with Testcontainers..."
+                            echo "============================================================"
+
+                            # Run SLT tests
+                            ./gradlew clean :bin-server:test --tests "in.dreamplug.bin.slt.*" jacocoTestReport --info
+
+                            # Extract test results
+                            TEST_REPORT="bin-server/build/reports/tests/test/index.html"
+                            if [ -f "$TEST_REPORT" ]; then
+                                TOTAL_TESTS=$(grep -o '<div class="counter">[0-9]*</div>' "$TEST_REPORT" | head -1 | grep -o '[0-9]*')
+                                FAILURES=$(grep -o '<div class="counter">[0-9]*</div>' "$TEST_REPORT" | sed -n '2p' | grep -o '[0-9]*')
+
+                                echo ""
+                                echo "âœ… SLT Test Results:"
+                                echo "   Total Tests: $TOTAL_TESTS"
+                                echo "   Failures: $FAILURES"
+                                echo "   Success Rate: $((100 - (FAILURES * 100 / TOTAL_TESTS)))%"
+                                echo ""
+                            fi
+                        '''
+
+                        // Generate visual coverage dashboard
+                        sh '''
+                            echo "ğŸ“Š Generating visual coverage dashboard..."
+                            chmod +x scripts/generate-coverage-dashboard.sh
+                            ./scripts/generate-coverage-dashboard.sh || echo "Dashboard generation skipped"
+                        '''
+
+                        // Stash reports for publishing
+                        stash name: 'slt-reports', includes: 'bin-server/build/reports/**,bin-server/build/test-results/**'
+
+                    } catch (Exception e) {
+                        currentBuild.result = 'UNSTABLE'
+                        error("SLT tests failed: ${e.message}")
+                    } finally {
+                        // Clean up Docker containers
+                        sh '''
+                            docker ps -aq --filter "label=org.testcontainers=true" | xargs -r docker rm -f || true
+                        '''
+                    }
+                }
+            }
+        }
+
+        stage('publish-slt-reports') {
+            agent any
+            steps {
+                script {
+                    unstash 'slt-reports'
+
+                    // Publish JUnit test results
+                    junit allowEmptyResults: true, testResults: 'bin-server/build/test-results/test/*.xml'
+
+                    // Publish HTML Test Report
+                    publishHTML([
+                        allowMissing: false,
+                        alwaysLinkToLastBuild: true,
+                        keepAll: true,
+                        reportDir: 'bin-server/build/reports/tests/test',
+                        reportFiles: 'index.html',
+                        reportName: 'ğŸ“Š SLT Test Report',
+                        reportTitles: 'Service Level Test Results'
+                    ])
+
+                    // Publish JaCoCo Coverage Report
+                    publishHTML([
+                        allowMissing: false,
+                        alwaysLinkToLastBuild: true,
+                        keepAll: true,
+                        reportDir: 'bin-server/build/reports/jacoco/test/html',
+                        reportFiles: 'index.html',
+                        reportName: 'ğŸ“ˆ SLT Coverage Report',
+                        reportTitles: 'Service Level Test Coverage'
+                    ])
+
+                    // Publish Visual Coverage Dashboard
+                    publishHTML([
+                        allowMissing: true,
+                        alwaysLinkToLastBuild: true,
+                        keepAll: true,
+                        reportDir: 'bin-server/build/reports/slt-dashboard',
+                        reportFiles: 'index.html',
+                        reportName: 'ğŸ¨ SLT Coverage Dashboard',
+                        reportTitles: 'Visual Coverage Dashboard'
+                    ])
+
+                    // Generate report summary for Slack
+                    def testReportUrl = "${env.BUILD_URL}SLT_20Test_20Report/"
+                    def coverageReportUrl = "${env.BUILD_URL}SLT_20Coverage_20Report/"
+                    def dashboardUrl = "${env.BUILD_URL}SLT_20Coverage_20Dashboard/"
+
+                    env.SLT_TEST_REPORT_URL = testReportUrl
+                    env.SLT_COVERAGE_REPORT_URL = coverageReportUrl
+                    env.SLT_DASHBOARD_URL = dashboardUrl
+
+                    echo "ğŸ“Š SLT Test Report: ${testReportUrl}"
+                    echo "ğŸ“ˆ SLT Coverage Report: ${coverageReportUrl}"
+                    echo "ğŸ¨ SLT Coverage Dashboard: ${dashboardUrl}"
+                }
+            }
+        }
+
+        stage('sonarqube-stage') {
+            agent {
+                docker {
+                    image 'credsre/gradle-ssm:8.5-corettojdk-21'
+                    registryCredentialsId 'credsre_docker'
+                    args "-v $HOME/.m2:/root/.m2 -v $HOME/$JOB_NAME/$BUILD_NUMBER/.gradle:/root/.gradle -v $HOME/.sonar:/root/.sonar"
+                }
+            }
+            options {
+                timeout(time: 1800, unit: "SECONDS")
+            }
+            environment {
+                DP_SSM_KEYS = '{"compact_keys":[{"key":"/conf/nexus/central/v1/NEXUS","region":"ap-south-1"}]}'
+                //DP_SONARQUBE_COMMAND = './gradlew sonarqube --info -x test -Dsonar.projectKey=\$DP_SONARQUBE_SERVICE_KEY -Dsonar.host.url=\$DP_SONARQUBE_URL -Dsonar.login=\$DP_SONARQUBE_LOGIN'
+                DP_SONARQUBE_COMMAND = './gradlew jacocoTestReport --info sonarqube -Dsonar.projectKey=\$DP_SONARQUBE_SERVICE_KEY -Dsonar.host.url=\$DP_SONARQUBE_URL -Dsonar.login=\$DP_SONARQUBE_LOGIN'
+            }
+            steps {
+                unstash 'caterpillar'
+                unstash 'build_step'
+                sh "${env.WORKSPACE}/caterpillar/bin/preclean.sh"
+                unstash 'jar'
+                sh "${env.WORKSPACE}/caterpillar/utils/env/entrypoint.sh"
+            }
+        }
+    }
+
+    post {
+        always {
+            script {
+                // Unstash SLT reports so Slack notification can read metrics
+                try {
+                    unstash 'slt-reports'
+                } catch (Exception e) {
+                    echo "âš ï¸ Could not unstash SLT reports: ${e.message}"
+                }
+            }
+            notifySlack(currentBuild.result, SLACK_CHANNEL)
+            notifyBitBucket(currentBuild.result)
+        }
+    }
+}
+
+def notifySlack(String buildStatus = 'STARTED', String channel = '#payments_slt_report_and_coverage') {
+    // Build status of null means success.
+    buildStatus = buildStatus ?: 'SUCCESS'
+
+    // For STARTED, use simple message (no metrics available yet)
+    if (buildStatus == 'STARTED') {
+        def msg = "â–¶ï¸ *STARTED*: `${env.JOB_NAME}` #${env.BUILD_NUMBER}\n" +
+                  "ğŸŒ¿ Branch: `${env.GIT_BRANCH}`\n" +
+                  "ğŸ”— <${env.BUILD_URL}|View Build>"
+        slackSend(channel: channel, color: '#D4DADF', message: msg)
+        return
+    }
+
+    // For completed builds, use simple notification with report links
+    def color
+    def emoji
+    if (buildStatus == 'SUCCESS') {
+        color = '#00FF00'
+        emoji = 'âœ…'
+    } else if (buildStatus == 'UNSTABLE') {
+        color = '#FFFE89'
+        emoji = 'âš ï¸'
+    } else if (buildStatus == 'FAILURE') {
+        color = '#FF0000'
+        emoji = 'âŒ'
+    } else if (buildStatus == 'ABORTED') {
+        color = '#FFAABB'
+        emoji = 'ğŸ›‘'
+    } else {
+        color = '#FF9FA1'
+        emoji = 'â“'
+    }
+
+    def commit_id = sh(script: "git rev-parse HEAD", returnStdout: true).trim()
+    commit_id = commit_id.substring(0, 10)
+    def time_taken = currentBuild.durationString.replace(' and counting', '')
+
+    def sltLinks = ""
+    if (env.SLT_DASHBOARD_URL && env.SLT_TEST_REPORT_URL && env.SLT_COVERAGE_REPORT_URL) {
+        sltLinks = "\n\nğŸ“Š *SLT Reports:*\n" +
+                   "â€¢ <${env.SLT_DASHBOARD_URL}|ğŸ¨ Visual Dashboard> (recommended)\n" +
+                   "â€¢ <${env.SLT_TEST_REPORT_URL}|ğŸ§ª Test Report>\n" +
+                   "â€¢ <${env.SLT_COVERAGE_REPORT_URL}|ğŸ“ˆ Coverage Details>"
+    }
+
+    def msg = "${emoji} *${buildStatus}*: `${env.JOB_NAME}` #${env.BUILD_NUMBER}\n" +
+              "ğŸŒ¿ Branch: `${env.GIT_BRANCH}`\n" +
+              "ğŸ“ Commit: <${env.BUILD_URL}|#${commit_id}>\n" +
+              "â±ï¸ Duration: ${time_taken}" +
+              sltLinks
+
+    slackSend(channel: channel, color: color, message: msg)
+}
+
+def notifyBitBucket(String buildStatus = 'STARTED') {
+    // Build status of null means success.
+    buildStatus = buildStatus ?: 'SUCCESS'
+
+    def bbStatus
+
+    if (buildStatus == 'SUCCESS') {
+        bbStatus = 'SUCCESSFUL'
+    } else if (buildStatus == 'FAILURE') {
+        bbStatus = 'FAILED'
+    } else {
+        bbStatus = 'INPROGRESS'
+    }
+    commit_id = sh(script: "git rev-parse HEAD", returnStdout: true)
+    commit_id = commit_id.substring(0, 10)
+    repoSlug = sh(script: "basename \$(cat .git/FETCH_HEAD | head -1 | awk '{print \$NF}')", returnStdout: true)
+    time_taken = currentBuild.durationString.replace(' and counting', '')
+    def msg = "${buildStatus}: ${env.JOB_NAME} #${env.BUILD_NUMBER} ${commit_id} Time = ${time_taken}"
+    bitbucketStatusNotify(
+            buildState: bbStatus,
+            repoSlug: repoSlug.trim(),
+            commitId: env.GIT_COMMIT,
+            buildDescription: msg
+    )
+}
diff --git a/run_slt.sh b/run_slt.sh
new file mode 100755
index 00000000..32ca39a3
--- /dev/null
+++ b/run_slt.sh
@@ -0,0 +1,290 @@
+#!/bin/bash
+set -e
+
+# Colors for output
+RED='\033[0;31m'
+GREEN='\033[0;32m'
+YELLOW='\033[1;33m'
+BLUE='\033[0;34m'
+NC='\033[0m' # No Color
+
+# Banner
+echo -e "${BLUE}"
+cat << "EOF"
+â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
+â•‘                                                           â•‘
+â•‘     BIN Atlas - Service Level Test (SLT) Runner         â•‘
+â•‘                                                           â•‘
+â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+EOF
+echo -e "${NC}"
+
+# Function to print colored messages
+print_info() {
+    echo -e "${BLUE}â„¹ï¸  $1${NC}"
+}
+
+print_success() {
+    echo -e "${GREEN}âœ… $1${NC}"
+}
+
+print_error() {
+    echo -e "${RED}âŒ $1${NC}"
+}
+
+print_warning() {
+    echo -e "${YELLOW}âš ï¸  $1${NC}"
+}
+
+# Function to detect Docker environment
+detect_docker() {
+    print_info "Detecting Docker environment..."
+
+    # First, try to detect which Docker implementation is installed
+    local docker_type="unknown"
+
+    # Check for Rancher Desktop
+    if [ -S "$HOME/.rd/docker.sock" ]; then
+        export DOCKER_HOST=unix://$HOME/.rd/docker.sock
+        docker_type="Rancher Desktop"
+    # Check for Colima
+    elif [ -S "$HOME/.colima/default/docker.sock" ]; then
+        export DOCKER_HOST=unix://$HOME/.colima/default/docker.sock
+        docker_type="Colima"
+    # Check for Docker Desktop (uses default socket)
+    elif [ -S "/var/run/docker.sock" ]; then
+        docker_type="Docker Desktop"
+    fi
+
+    # Now verify Docker daemon is ACTUALLY running (not just checking cached data)
+    if docker info > /dev/null 2>&1; then
+        print_success "Using $docker_type"
+        if [ "$DOCKER_HOST" ]; then
+            print_success "DOCKER_HOST set to: $DOCKER_HOST"
+        fi
+        return 0
+    else
+        print_error "Docker daemon is not running!"
+        echo ""
+        print_info "Detected $docker_type but the daemon is not responding."
+        echo ""
+        print_info "To start:"
+        echo "  - Docker Desktop: Open Docker Desktop app and wait for it to fully start"
+        echo "  - Rancher Desktop: Open Rancher Desktop app and wait for it to fully start"
+        echo "  - Colima: Run 'colima start'"
+        echo ""
+        print_info "Then verify Docker is running:"
+        echo "  docker ps"
+        exit 1
+    fi
+}
+
+# Function to check Docker images
+check_docker_images() {
+    print_info "Checking required Docker images..."
+
+    local images=("mysql:8.0.33" "redis:7.0-alpine" "localstack/localstack:4.0.3" "testcontainers/ryuk:0.5.1")
+    local missing_images=()
+
+    for image in "${images[@]}"; do
+        if docker image inspect "$image" > /dev/null 2>&1; then
+            print_success "Image available: $image"
+        else
+            missing_images+=("$image")
+            print_warning "Image not found: $image (will be pulled automatically)"
+        fi
+    done
+
+    if [ ${#missing_images[@]} -gt 0 ]; then
+        print_warning "${#missing_images[@]} image(s) will be downloaded during test execution"
+        echo ""
+    fi
+}
+
+# Function to run SLT tests
+run_slt_tests() {
+    print_info "Running SLT tests with Testcontainers..."
+    echo ""
+
+    # Clean previous reports
+    rm -rf bin-server/build/reports/tests/test
+    rm -rf bin-server/build/reports/jacoco/test
+
+    # Run tests
+    ./gradlew clean :bin-server:test --tests "in.dreamplug.bin.slt.*" jacocoTestReport \
+        --console=plain \
+        --no-daemon
+
+    local exit_code=$?
+
+    echo ""
+    if [ $exit_code -eq 0 ]; then
+        print_success "SLT tests completed successfully!"
+    else
+        print_error "SLT tests failed with exit code $exit_code"
+        exit $exit_code
+    fi
+}
+
+# Function to display test results summary
+show_test_summary() {
+    local test_report="bin-server/build/reports/tests/test/index.html"
+
+    if [ -f "$test_report" ]; then
+        print_info "Extracting test results..."
+
+        # Extract test counts from HTML report
+        local total_tests=$(grep -o '<div class="counter">[0-9]*</div>' "$test_report" | head -1 | grep -o '[0-9]*')
+        local failures=$(grep -o '<div class="counter">[0-9]*</div>' "$test_report" | sed -n '2p' | grep -o '[0-9]*')
+        local duration=$(grep -o '<div class="counter">[^<]*</div>' "$test_report" | sed -n '4p' | sed 's/<[^>]*>//g')
+
+        echo ""
+        echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
+        echo -e "${GREEN}                    Test Results Summary                    ${NC}"
+        echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
+        echo ""
+        echo -e "  Total Tests:     ${GREEN}${total_tests}${NC}"
+        echo -e "  Failures:        ${RED}${failures}${NC}"
+        echo -e "  Success Rate:    ${GREEN}$(( 100 - (failures * 100 / total_tests) ))%${NC}"
+        echo -e "  Duration:        ${BLUE}${duration}${NC}"
+        echo ""
+        echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
+        echo ""
+    fi
+}
+
+# Function to display coverage summary
+show_coverage_summary() {
+    local coverage_report="bin-server/build/reports/jacoco/test/html/index.html"
+
+    if [ -f "$coverage_report" ]; then
+        print_info "Extracting coverage metrics..."
+
+        # Extract coverage from HTML report
+        local instruction_cov=$(grep -o 'Total.*ctr2.*>[0-9]*%' "$coverage_report" | head -1 | grep -o '[0-9]*%')
+        local branch_cov=$(grep -o 'Total.*ctr2.*>[0-9]*%' "$coverage_report" | sed -n '2p' | grep -o '[0-9]*%' || echo "N/A")
+
+        echo ""
+        echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
+        echo -e "${GREEN}                   Coverage Summary                         ${NC}"
+        echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
+        echo ""
+        echo -e "  Instruction Coverage:  ${GREEN}${instruction_cov:-N/A}${NC}"
+        echo -e "  Branch Coverage:       ${GREEN}${branch_cov:-N/A}${NC}"
+        echo ""
+        echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
+        echo ""
+    fi
+}
+
+# Function to show reports
+show_reports() {
+    local test_report="bin-server/build/reports/tests/test/index.html"
+    local coverage_report="bin-server/build/reports/jacoco/test/html/index.html"
+    local dashboard="bin-server/build/reports/slt-dashboard/index.html"
+
+    echo ""
+    print_info "Opening reports in browser..."
+    echo ""
+
+    if [ "$(uname)" == "Darwin" ]; then
+        # macOS
+        [ -f "$dashboard" ] && open "$dashboard" && print_success "Opened Coverage Dashboard" && sleep 1
+        [ -f "$test_report" ] && open "$test_report" && print_success "Opened Test Report" && sleep 1
+        [ -f "$coverage_report" ] && open "$coverage_report" && print_success "Opened Detailed Coverage Report"
+    elif [ "$(expr substr $(uname -s) 1 5)" == "Linux" ]; then
+        # Linux
+        [ -f "$dashboard" ] && xdg-open "$dashboard" && print_success "Opened Coverage Dashboard" && sleep 1
+        [ -f "$test_report" ] && xdg-open "$test_report" && print_success "Opened Test Report" && sleep 1
+        [ -f "$coverage_report" ] && xdg-open "$coverage_report" && print_success "Opened Detailed Coverage Report"
+    else
+        # Windows (Git Bash)
+        [ -f "$dashboard" ] && start "$dashboard" && print_success "Opened Coverage Dashboard" && sleep 1
+        [ -f "$test_report" ] && start "$test_report" && print_success "Opened Test Report" && sleep 1
+        [ -f "$coverage_report" ] && start "$coverage_report" && print_success "Opened Detailed Coverage Report"
+    fi
+
+    echo ""
+    print_info "Report locations:"
+    echo "  ğŸ“Š Dashboard:         file://$(pwd)/$dashboard"
+    echo "  ğŸ§ª Test Report:       file://$(pwd)/$test_report"
+    echo "  ğŸ“ˆ Coverage Details:  file://$(pwd)/$coverage_report"
+    echo ""
+}
+
+# Function to show help
+show_help() {
+    cat << EOF
+${BLUE}Usage:${NC} $0 [OPTION]
+
+${GREEN}Options:${NC}
+  run              Run SLT tests (default if no option provided)
+  show, report     Open test and coverage reports in browser
+  help, -h, --help Show this help message
+
+${GREEN}Examples:${NC}
+  $0              # Run SLT tests
+  $0 run          # Run SLT tests
+  $0 show         # Open reports in browser
+  $0 report       # Open reports in browser
+
+${GREEN}What are SLT tests?${NC}
+  Service Level Tests validate end-to-end API functionality with real
+  infrastructure (MySQL, Redis, LocalStack) using Testcontainers.
+
+${GREEN}Current SLT Coverage:${NC}
+  â€¢ 32 comprehensive test scenarios
+  â€¢ P0 (Sanity): 8 tests - Happy path scenarios
+  â€¢ P1 (Regression): 11 tests - Authentication, validation
+  â€¢ P2 (Regression): 12 tests - Edge cases, error handling
+
+${GREEN}Requirements:${NC}
+  â€¢ Docker Desktop, Rancher Desktop, or Colima running
+  â€¢ Java 21
+  â€¢ Gradle 8.5+
+
+EOF
+}
+
+# Main script logic
+main() {
+    local command="${1:-run}"
+
+    case "$command" in
+        run)
+            detect_docker
+            check_docker_images
+            echo ""
+            run_slt_tests
+            show_test_summary
+            show_coverage_summary
+
+            # Generate coverage dashboard
+            print_info "Generating visual coverage dashboard..."
+            ./scripts/generate-coverage-dashboard.sh > /dev/null 2>&1 || print_warning "Dashboard generation skipped"
+
+            print_success "SLT tests completed successfully!"
+            echo ""
+            print_info "To view reports, run: ./run_slt.sh show"
+            echo ""
+            ;;
+
+        show|report)
+            show_reports
+            ;;
+
+        help|-h|--help)
+            show_help
+            ;;
+
+        *)
+            print_error "Unknown command: $command"
+            echo ""
+            show_help
+            exit 1
+            ;;
+    esac
+}
+
+# Run main function
+main "$@"
diff --git a/scripts/generate-coverage-dashboard.sh b/scripts/generate-coverage-dashboard.sh
new file mode 100755
index 00000000..ae4810c9
--- /dev/null
+++ b/scripts/generate-coverage-dashboard.sh
@@ -0,0 +1,276 @@
+#!/bin/bash
+set -e
+
+# Colors
+BLUE='\033[0;34m'
+GREEN='\033[0;32m'
+NC='\033[0m' # No Color
+
+echo -e "${BLUE}ğŸ“Š Generating SLT Coverage Dashboard...${NC}"
+
+# Paths
+JACOCO_XML="bin-server/build/reports/jacoco/test/jacocoTestReport.xml"
+JACOCO_HTML="bin-server/build/reports/jacoco/test/html/index.html"
+TEST_REPORT="bin-server/build/reports/tests/test/index.html"
+TEMPLATE="bin-server/src/test/resources/coverage-dashboard-template.html"
+OUTPUT_DIR="bin-server/build/reports/slt-dashboard"
+OUTPUT_FILE="$OUTPUT_DIR/index.html"
+
+# Create output directory
+mkdir -p "$OUTPUT_DIR"
+
+# Check if JaCoCo XML report exists
+if [ ! -f "$JACOCO_XML" ]; then
+    echo "âŒ JaCoCo XML report not found at: $JACOCO_XML"
+    echo "   Run: ./gradlew clean :bin-server:test --tests \"in.dreamplug.bin.slt.*\" jacocoTestReport"
+    exit 1
+fi
+
+# Extract coverage metrics from JaCoCo XML
+echo "ğŸ“ˆ Extracting coverage metrics from JaCoCo XML..."
+
+# Extract instruction coverage
+INSTRUCTION_COVERED=$(grep -A 1 '<counter type="INSTRUCTION"' "$JACOCO_XML" | head -1 | sed -n 's/.*covered="\([0-9]*\)".*/\1/p')
+INSTRUCTION_MISSED=$(grep -A 1 '<counter type="INSTRUCTION"' "$JACOCO_XML" | head -1 | sed -n 's/.*missed="\([0-9]*\)".*/\1/p')
+INSTRUCTION_TOTAL=$((INSTRUCTION_COVERED + INSTRUCTION_MISSED))
+INSTRUCTION_COVERAGE=$((INSTRUCTION_COVERED * 100 / INSTRUCTION_TOTAL))
+
+# Extract branch coverage
+BRANCH_COVERED=$(grep -A 1 '<counter type="BRANCH"' "$JACOCO_XML" | head -1 | sed -n 's/.*covered="\([0-9]*\)".*/\1/p')
+BRANCH_MISSED=$(grep -A 1 '<counter type="BRANCH"' "$JACOCO_XML" | head -1 | sed -n 's/.*missed="\([0-9]*\)".*/\1/p')
+BRANCH_TOTAL=$((BRANCH_COVERED + BRANCH_MISSED))
+BRANCH_COVERAGE=0
+if [ $BRANCH_TOTAL -gt 0 ]; then
+    BRANCH_COVERAGE=$((BRANCH_COVERED * 100 / BRANCH_TOTAL))
+fi
+
+# Extract line coverage
+LINE_COVERED=$(grep -A 1 '<counter type="LINE"' "$JACOCO_XML" | head -1 | sed -n 's/.*covered="\([0-9]*\)".*/\1/p')
+LINE_MISSED=$(grep -A 1 '<counter type="LINE"' "$JACOCO_XML" | head -1 | sed -n 's/.*missed="\([0-9]*\)".*/\1/p')
+LINE_TOTAL=$((LINE_COVERED + LINE_MISSED))
+LINE_COVERAGE=$((LINE_COVERED * 100 / LINE_TOTAL))
+
+# Extract method coverage
+METHOD_COVERED=$(grep -A 1 '<counter type="METHOD"' "$JACOCO_XML" | head -1 | sed -n 's/.*covered="\([0-9]*\)".*/\1/p')
+METHOD_MISSED=$(grep -A 1 '<counter type="METHOD"' "$JACOCO_XML" | head -1 | sed -n 's/.*missed="\([0-9]*\)".*/\1/p')
+METHOD_TOTAL=$((METHOD_COVERED + METHOD_MISSED))
+METHOD_COVERAGE=$((METHOD_COVERED * 100 / METHOD_TOTAL))
+
+# Extract class coverage
+CLASS_COVERED=$(grep -A 1 '<counter type="CLASS"' "$JACOCO_XML" | head -1 | sed -n 's/.*covered="\([0-9]*\)".*/\1/p')
+CLASS_MISSED=$(grep -A 1 '<counter type="CLASS"' "$JACOCO_XML" | head -1 | sed -n 's/.*missed="\([0-9]*\)".*/\1/p')
+CLASS_TOTAL=$((CLASS_COVERED + CLASS_MISSED))
+CLASS_COVERAGE=$((CLASS_COVERED * 100 / CLASS_TOTAL))
+
+# Extract test results
+TOTAL_TESTS=32
+SUCCESS_RATE=100
+if [ -f "$TEST_REPORT" ]; then
+    TOTAL_TESTS=$(grep -o '<div class="counter">[0-9]*</div>' "$TEST_REPORT" | head -1 | grep -o '[0-9]*' || echo "32")
+    FAILURES=$(grep -o '<div class="counter">[0-9]*</div>' "$TEST_REPORT" | sed -n '2p' | grep -o '[0-9]*' || echo "0")
+    SUCCESS_RATE=$((100 - (FAILURES * 100 / TOTAL_TESTS)))
+fi
+
+# Build metadata
+BUILD_NUMBER="${BUILD_NUMBER:-local}"
+# Strip origin/ prefix from branch name if present (Jenkins)
+BRANCH="${GIT_BRANCH:-develop}"
+BRANCH="${BRANCH#origin/}"
+DATE=$(date '+%Y-%m-%d %H:%M:%S')
+
+# Test distribution (hardcoded for now - can be extracted from test annotations)
+P0_TESTS=8
+P1_TESTS=11
+P2_TESTS=13
+
+# Extract per-package coverage from JaCoCo XML
+echo "ğŸ“¦ Extracting package-level coverage..."
+PACKAGE_DATA="[]"
+
+# Parse all packages from JaCoCo XML and extract top 5 by coverage
+if [ -f "$JACOCO_XML" ]; then
+    # Use Python to parse XML properly (more reliable than awk/sed)
+    PACKAGE_DATA=$(python3 <<'PYTHON_EOF'
+import xml.etree.ElementTree as ET
+import json
+import sys
+
+try:
+    tree = ET.parse('bin-server/build/reports/jacoco/test/jacocoTestReport.xml')
+    root = tree.getroot()
+
+    packages = []
+    for package in root.findall('.//package'):
+        pkg_name = package.get('name')
+
+        # Find INSTRUCTION counter for this package
+        for counter in package.findall("./counter[@type='INSTRUCTION']"):
+            covered = int(counter.get('covered', 0))
+            missed = int(counter.get('missed', 0))
+            total = covered + missed
+
+            if total > 0:
+                coverage_pct = int((covered * 100) / total)
+
+                # Filter out very low coverage packages
+                if coverage_pct >= 5:
+                    # Shorten package name
+                    display_name = pkg_name.replace('in/dreamplug/bin/', '').replace('/', '.')
+                    packages.append({
+                        'name': display_name,
+                        'coverage': coverage_pct
+                    })
+
+    # Sort by coverage descending and take top 5
+    packages_sorted = sorted(packages, key=lambda x: x['coverage'], reverse=True)[:5]
+
+    print(json.dumps(packages_sorted))
+except Exception as e:
+    print('[]', file=sys.stderr)
+    print(f'Error parsing JaCoCo XML: {e}', file=sys.stderr)
+PYTHON_EOF
+)
+
+    # Fallback to empty array if Python script failed
+    if [ -z "$PACKAGE_DATA" ] || [ "$PACKAGE_DATA" = "null" ]; then
+        PACKAGE_DATA="[]"
+    fi
+fi
+
+echo "ğŸ“Š Top packages with coverage: $PACKAGE_DATA"
+
+echo ""
+echo "ğŸ“Š Coverage Metrics:"
+echo "   Instruction: ${INSTRUCTION_COVERAGE}%"
+echo "   Branch:      ${BRANCH_COVERAGE}%"
+echo "   Line:        ${LINE_COVERAGE}%"
+echo "   Method:      ${METHOD_COVERAGE}%"
+echo "   Class:       ${CLASS_COVERAGE}%"
+echo ""
+echo "ğŸ§ª Test Results:"
+echo "   Total Tests:  $TOTAL_TESTS"
+echo "   Success Rate: ${SUCCESS_RATE}%"
+echo ""
+
+# Copy template and replace placeholders
+cp "$TEMPLATE" "$OUTPUT_FILE"
+
+# Copy CSS and JS files to output directory
+CSS_SOURCE="bin-server/src/test/resources/dashboard.css"
+JS_SOURCE="bin-server/src/test/resources/dashboard.js"
+CSS_OUTPUT="$OUTPUT_DIR/dashboard.css"
+JS_OUTPUT="$OUTPUT_DIR/dashboard.js"
+
+echo "ğŸ“¦ Copying external CSS and JS files..."
+cp "$CSS_SOURCE" "$CSS_OUTPUT"
+cp "$JS_SOURCE" "$JS_OUTPUT"
+
+# Detect OS for sed syntax (macOS vs Linux)
+SED_INPLACE="-i"
+if [[ "$OSTYPE" == "darwin"* ]]; then
+    SED_INPLACE="-i ''"
+fi
+
+# Replace placeholders in dashboard using a temp file (portable across macOS/Linux)
+# Use | as delimiter to avoid issues with / in branch names
+sed "s/{{BUILD_NUMBER}}/$BUILD_NUMBER/g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+sed "s|{{BRANCH}}|$BRANCH|g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+sed "s/{{DATE}}/$DATE/g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+sed "s/{{TOTAL_TESTS}}/$TOTAL_TESTS/g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+sed "s/{{SUCCESS_RATE}}/$SUCCESS_RATE/g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+sed "s/{{INSTRUCTION_COVERAGE}}/$INSTRUCTION_COVERAGE/g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+sed "s/{{BRANCH_COVERAGE}}/$BRANCH_COVERAGE/g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+sed "s/{{LINE_COVERAGE}}/$LINE_COVERAGE/g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+sed "s/{{METHOD_COVERAGE}}/$METHOD_COVERAGE/g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+sed "s/{{CLASS_COVERAGE}}/$CLASS_COVERAGE/g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+sed "s/{{P0_TESTS}}/$P0_TESTS/g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+sed "s/{{P1_TESTS}}/$P1_TESTS/g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+sed "s/{{P2_TESTS}}/$P2_TESTS/g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+
+# Replace package data using Python (more portable than perl)
+# Pass package data as environment variable to avoid quote escaping issues
+export PACKAGE_JSON="$PACKAGE_DATA"
+python3 <<'PYTHON_EOF'
+import re
+import sys
+import os
+
+try:
+    # Replace in HTML
+    with open('bin-server/build/reports/slt-dashboard/index.html', 'r') as f:
+        html_content = f.read()
+
+    # Get package data from environment variable
+    package_data = os.environ.get('PACKAGE_JSON', '[]')
+
+    # Replace the topPackages array in HTML - match the entire array structure
+    html_content = re.sub(
+        r'topPackages:\s*\[[\s\S]*?\](?=\s*};)',
+        f'topPackages: {package_data}',
+        html_content
+    )
+
+    with open('bin-server/build/reports/slt-dashboard/index.html', 'w') as f:
+        f.write(html_content)
+
+    # Replace in JS file as well
+    with open('bin-server/build/reports/slt-dashboard/dashboard.js', 'r') as f:
+        js_content = f.read()
+
+    # Replace the topPackages array in JS - match the entire array structure
+    js_content = re.sub(
+        r'topPackages:\s*\[[\s\S]*?\]',
+        f'topPackages: {package_data}',
+        js_content
+    )
+
+    with open('bin-server/build/reports/slt-dashboard/dashboard.js', 'w') as f:
+        f.write(js_content)
+
+    print(f"Package data replaced successfully in HTML and JS with: {package_data}", file=sys.stderr)
+except Exception as e:
+    print(f"Error replacing package data: {e}", file=sys.stderr)
+    sys.exit(0)  # Don't fail the script
+PYTHON_EOF
+
+# Replace report URLs
+JACOCO_REPORT_URL="../jacoco/test/html/index.html"
+TEST_REPORT_URL="../tests/test/index.html"
+sed "s|{{JACOCO_REPORT_URL}}|$JACOCO_REPORT_URL|g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+sed "s|{{TEST_REPORT_URL}}|$TEST_REPORT_URL|g" "$OUTPUT_FILE" > "$OUTPUT_FILE.tmp" && mv "$OUTPUT_FILE.tmp" "$OUTPUT_FILE"
+
+# Also replace placeholders in dashboard.js
+echo "ğŸ”„ Replacing placeholders in dashboard.js..."
+sed "s/{{BUILD_NUMBER}}/$BUILD_NUMBER/g" "$JS_OUTPUT" > "$JS_OUTPUT.tmp" && mv "$JS_OUTPUT.tmp" "$JS_OUTPUT"
+sed "s|{{BRANCH}}|$BRANCH|g" "$JS_OUTPUT" > "$JS_OUTPUT.tmp" && mv "$JS_OUTPUT.tmp" "$JS_OUTPUT"
+sed "s/{{DATE}}/$DATE/g" "$JS_OUTPUT" > "$JS_OUTPUT.tmp" && mv "$JS_OUTPUT.tmp" "$JS_OUTPUT"
+sed "s/{{TOTAL_TESTS}}/$TOTAL_TESTS/g" "$JS_OUTPUT" > "$JS_OUTPUT.tmp" && mv "$JS_OUTPUT.tmp" "$JS_OUTPUT"
+sed "s/{{SUCCESS_RATE}}/$SUCCESS_RATE/g" "$JS_OUTPUT" > "$JS_OUTPUT.tmp" && mv "$JS_OUTPUT.tmp" "$JS_OUTPUT"
+sed "s/{{INSTRUCTION_COVERAGE}}/$INSTRUCTION_COVERAGE/g" "$JS_OUTPUT" > "$JS_OUTPUT.tmp" && mv "$JS_OUTPUT.tmp" "$JS_OUTPUT"
+sed "s/{{BRANCH_COVERAGE}}/$BRANCH_COVERAGE/g" "$JS_OUTPUT" > "$JS_OUTPUT.tmp" && mv "$JS_OUTPUT.tmp" "$JS_OUTPUT"
+sed "s/{{LINE_COVERAGE}}/$LINE_COVERAGE/g" "$JS_OUTPUT" > "$JS_OUTPUT.tmp" && mv "$JS_OUTPUT.tmp" "$JS_OUTPUT"
+sed "s/{{METHOD_COVERAGE}}/$METHOD_COVERAGE/g" "$JS_OUTPUT" > "$JS_OUTPUT.tmp" && mv "$JS_OUTPUT.tmp" "$JS_OUTPUT"
+sed "s/{{CLASS_COVERAGE}}/$CLASS_COVERAGE/g" "$JS_OUTPUT" > "$JS_OUTPUT.tmp" && mv "$JS_OUTPUT.tmp" "$JS_OUTPUT"
+sed "s/{{P0_TESTS}}/$P0_TESTS/g" "$JS_OUTPUT" > "$JS_OUTPUT.tmp" && mv "$JS_OUTPUT.tmp" "$JS_OUTPUT"
+sed "s/{{P1_TESTS}}/$P1_TESTS/g" "$JS_OUTPUT" > "$JS_OUTPUT.tmp" && mv "$JS_OUTPUT.tmp" "$JS_OUTPUT"
+sed "s/{{P2_TESTS}}/$P2_TESTS/g" "$JS_OUTPUT" > "$JS_OUTPUT.tmp" && mv "$JS_OUTPUT.tmp" "$JS_OUTPUT"
+
+echo -e "${GREEN}âœ… Coverage dashboard generated successfully!${NC}"
+echo ""
+echo "ğŸ“Š Dashboard location:"
+echo "   file://$(pwd)/$OUTPUT_FILE"
+echo ""
+echo "ğŸ“ˆ Other reports:"
+echo "   JaCoCo:  file://$(pwd)/$JACOCO_HTML"
+echo "   Tests:   file://$(pwd)/$TEST_REPORT"
+echo ""
+
+# Open dashboard in browser if requested
+if [ "$1" == "show" ] || [ "$1" == "open" ]; then
+    echo "ğŸŒ Opening dashboard in browser..."
+    if [ "$(uname)" == "Darwin" ]; then
+        open "$OUTPUT_FILE"
+    elif [ "$(expr substr $(uname -s) 1 5)" == "Linux" ]; then
+        xdg-open "$OUTPUT_FILE"
+    fi
+fi
diff --git a/scripts/generate-slack-payload.sh b/scripts/generate-slack-payload.sh
new file mode 100755
index 00000000..e7d57639
--- /dev/null
+++ b/scripts/generate-slack-payload.sh
@@ -0,0 +1,243 @@
+#!/bin/bash
+# Generate Slack notification payload with rich metrics
+# Author: Sourav Singh
+# Usage: ./generate-slack-payload.sh <build_status>
+
+set -e
+
+BUILD_STATUS="${1:-SUCCESS}"
+JACOCO_XML="bin-server/build/reports/jacoco/test/jacocoTestReport.xml"
+TEST_REPORT="bin-server/build/reports/tests/test/index.html"
+
+# Extract coverage metrics from JaCoCo XML
+extract_coverage() {
+    if [ ! -f "$JACOCO_XML" ]; then
+        echo "0"
+        return
+    fi
+
+    local counter_type=$1
+    local covered=$(grep "<counter type=\"$counter_type\"" "$JACOCO_XML" | head -1 | sed -n 's/.*covered="\([0-9]*\)".*/\1/p')
+    local missed=$(grep "<counter type=\"$counter_type\"" "$JACOCO_XML" | head -1 | sed -n 's/.*missed="\([0-9]*\)".*/\1/p')
+
+    if [ -z "$covered" ] || [ -z "$missed" ]; then
+        echo "0"
+        return
+    fi
+
+    local total=$((covered + missed))
+    if [ $total -eq 0 ]; then
+        echo "0"
+    else
+        echo $((covered * 100 / total))
+    fi
+}
+
+# Extract test results
+extract_test_results() {
+    if [ ! -f "$TEST_REPORT" ]; then
+        echo "0:0:0"
+        return
+    fi
+
+    local total=$(grep -o '<div class="counter">[0-9]*</div>' "$TEST_REPORT" | head -1 | grep -o '[0-9]*' || echo "0")
+    local failures=$(grep -o '<div class="counter">[0-9]*</div>' "$TEST_REPORT" | sed -n '2p' | grep -o '[0-9]*' || echo "0")
+    local success_rate=100
+
+    if [ $total -gt 0 ] && [ $total -ne 0 ]; then
+        success_rate=$((100 - (failures * 100 / total)))
+    fi
+
+    echo "$total:$failures:$success_rate"
+}
+
+# Get metrics
+INSTRUCTION_COVERAGE=$(extract_coverage "INSTRUCTION")
+BRANCH_COVERAGE=$(extract_coverage "BRANCH")
+LINE_COVERAGE=$(extract_coverage "LINE")
+
+TEST_DATA=$(extract_test_results)
+TOTAL_TESTS=$(echo $TEST_DATA | cut -d: -f1)
+FAILURES=$(echo $TEST_DATA | cut -d: -f2)
+SUCCESS_RATE=$(echo $TEST_DATA | cut -d: -f3)
+
+# Determine color and emoji based on build status
+case $BUILD_STATUS in
+    SUCCESS)
+        COLOR="good"
+        EMOJI="âœ…"
+        ;;
+    UNSTABLE)
+        COLOR="warning"
+        EMOJI="âš ï¸"
+        ;;
+    FAILURE)
+        COLOR="#FF0000"
+        EMOJI="âŒ"
+        ;;
+    ABORTED)
+        COLOR="#FFAABB"
+        EMOJI="ğŸ›‘"
+        ;;
+    *)
+        COLOR="#D4DADF"
+        EMOJI="â–¶ï¸"
+        ;;
+esac
+
+# Get commit info
+COMMIT_ID=$(git rev-parse HEAD 2>/dev/null | cut -c1-10 || echo "unknown")
+TIME_TAKEN="${BUILD_DURATION:-unknown}"
+
+# Coverage status emoji
+coverage_emoji() {
+    local cov=$1
+    if [ $cov -ge 70 ]; then
+        echo "ğŸŸ¢"
+    elif [ $cov -ge 50 ]; then
+        echo "ğŸŸ¡"
+    else
+        echo "ğŸ”´"
+    fi
+}
+
+INST_EMOJI=$(coverage_emoji $INSTRUCTION_COVERAGE)
+BRANCH_EMOJI=$(coverage_emoji $BRANCH_COVERAGE)
+LINE_EMOJI=$(coverage_emoji $LINE_COVERAGE)
+
+# Test status emoji
+if [ $SUCCESS_RATE -eq 100 ]; then
+    TEST_EMOJI="âœ…"
+elif [ $SUCCESS_RATE -ge 80 ]; then
+    TEST_EMOJI="âš ï¸"
+else
+    TEST_EMOJI="âŒ"
+fi
+
+# Escape JSON strings properly
+escape_json() {
+    echo "$1" | sed 's/\\/\\\\/g' | sed 's/"/\\"/g' | sed "s/'/\\'/g"
+}
+
+JOB_NAME=$(escape_json "${JOB_NAME:-bin-atlas}")
+GIT_BRANCH_ESC=$(escape_json "${GIT_BRANCH:-unknown}")
+BUILD_URL_ESC=$(escape_json "${BUILD_URL:-#}")
+
+# Generate Slack payload using cat with proper JSON escaping
+cat <<EOF
+[
+  {
+    "color": "$COLOR",
+    "blocks": [
+      {
+        "type": "header",
+        "text": {
+          "type": "plain_text",
+          "text": "$EMOJI BIN Atlas SLT - $BUILD_STATUS"
+        }
+      },
+      {
+        "type": "section",
+        "fields": [
+          {
+            "type": "mrkdwn",
+            "text": "*Build:*\\n#${BUILD_NUMBER:-unknown}"
+          },
+          {
+            "type": "mrkdwn",
+            "text": "*Branch:*\\n\`$GIT_BRANCH_ESC\`"
+          },
+          {
+            "type": "mrkdwn",
+            "text": "*Commit:*\\n<$BUILD_URL_ESC|#$COMMIT_ID>"
+          },
+          {
+            "type": "mrkdwn",
+            "text": "*Duration:*\\n$TIME_TAKEN"
+          }
+        ]
+      },
+      {
+        "type": "divider"
+      },
+      {
+        "type": "section",
+        "text": {
+          "type": "mrkdwn",
+          "text": "*ğŸ“Š Coverage Metrics at a Glance:*"
+        }
+      },
+      {
+        "type": "section",
+        "fields": [
+          {
+            "type": "mrkdwn",
+            "text": "$INST_EMOJI *Service Coverage:* ${INSTRUCTION_COVERAGE}%"
+          },
+          {
+            "type": "mrkdwn",
+            "text": "$BRANCH_EMOJI *Branch Coverage:* ${BRANCH_COVERAGE}%"
+          },
+          {
+            "type": "mrkdwn",
+            "text": "$LINE_EMOJI *Line Coverage:* ${LINE_COVERAGE}%"
+          },
+          {
+            "type": "mrkdwn",
+            "text": "$TEST_EMOJI *Tests:* $TOTAL_TESTS ($SUCCESS_RATE% pass)"
+          }
+        ]
+      },
+      {
+        "type": "divider"
+      },
+      {
+        "type": "section",
+        "text": {
+          "type": "mrkdwn",
+          "text": "*ğŸ“ˆ View Detailed Reports:*"
+        }
+      },
+      {
+        "type": "actions",
+        "elements": [
+          {
+            "type": "button",
+            "text": {
+              "type": "plain_text",
+              "text": "ğŸ¨ Visual Dashboard"
+            },
+            "url": "${BUILD_URL}SLT_20Coverage_20Dashboard/",
+            "style": "primary"
+          },
+          {
+            "type": "button",
+            "text": {
+              "type": "plain_text",
+              "text": "ğŸ§ª Test Report"
+            },
+            "url": "${BUILD_URL}SLT_20Test_20Report/"
+          },
+          {
+            "type": "button",
+            "text": {
+              "type": "plain_text",
+              "text": "ğŸ“Š Coverage Details"
+            },
+            "url": "${BUILD_URL}SLT_20Coverage_20Report/"
+          }
+        ]
+      },
+      {
+        "type": "context",
+        "elements": [
+          {
+            "type": "mrkdwn",
+            "text": "ğŸ’¡ *Tip:* ğŸŸ¢ 70%+ = Excellent | ğŸŸ¡ 50-70% = Good | ğŸ”´ <50% = Needs Work"
+          }
+        ]
+      }
+    ]
+  }
+]
+EOF
diff --git a/scripts/upload-slt-metrics.sh b/scripts/upload-slt-metrics.sh
new file mode 100755
index 00000000..7053aa70
--- /dev/null
+++ b/scripts/upload-slt-metrics.sh
@@ -0,0 +1,281 @@
+#!/bin/bash
+set -e
+
+# =============================================================================
+# SLT Metrics S3 Upload Script
+# =============================================================================
+# Uploads SLT test reports and metrics to S3 for centralized dashboard
+#
+# Usage:
+#   ./scripts/upload-slt-metrics.sh [service-name]
+#
+# Environment Variables:
+#   SERVICE_NAME      - Override detected service name
+#   S3_BUCKET         - Override S3 bucket (default: payments-slt-metrics-report)
+#   S3_PREFIX         - Override S3 prefix (default: merchant-payments)
+#   AWS_REGION        - AWS region (default: ap-south-1)
+#
+# Prerequisites:
+#   - AWS CLI installed OR AWS SDK available
+#   - AWS credentials configured
+#   - SLT tests already run (reports exist in build/)
+#
+# Author: Sourav Singh
+# =============================================================================
+
+# Colors
+RED='\033[0;31m'
+GREEN='\033[0;32m'
+YELLOW='\033[1;33m'
+BLUE='\033[0;34m'
+NC='\033[0m'
+
+# Configuration
+S3_BUCKET="${S3_BUCKET:-payments-slt-metrics-report}"
+S3_PREFIX="${S3_PREFIX:-instrument-stack}"  # Default for bin-atlas
+AWS_REGION="${AWS_REGION:-ap-south-1}"
+TIMESTAMP=$(date -u +"%Y-%m-%d_%H-%M-%S")
+
+# Helper functions
+print_info() {
+    echo -e "${BLUE}â„¹ï¸  $1${NC}"
+}
+
+print_success() {
+    echo -e "${GREEN}âœ… $1${NC}"
+}
+
+print_error() {
+    echo -e "${RED}âŒ $1${NC}"
+}
+
+print_warning() {
+    echo -e "${YELLOW}âš ï¸  $1${NC}"
+}
+
+print_header() {
+    echo -e "${BLUE}"
+    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
+    echo "  SLT Metrics Upload to S3"
+    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
+    echo -e "${NC}"
+}
+
+# Detect service name
+detect_service_name() {
+    if [ -n "$SERVICE_NAME" ]; then
+        echo "$SERVICE_NAME"
+        return
+    fi
+
+    # Try to detect from git remote
+    if git remote -v &>/dev/null; then
+        local remote_url=$(git config --get remote.origin.url 2>/dev/null || echo "")
+        if [ -n "$remote_url" ]; then
+            # Extract repo name from URL
+            local repo_name=$(basename "$remote_url" .git)
+            echo "$repo_name"
+            return
+        fi
+    fi
+
+    # Fallback to directory name
+    basename "$(pwd)"
+}
+
+# Detect Git metadata
+get_git_metadata() {
+    local commit_sha=$(git rev-parse HEAD 2>/dev/null || echo "unknown")
+    local branch=$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo "unknown")
+    local author=$(git log -1 --pretty=format:'%an' 2>/dev/null || echo "unknown")
+    local author_email=$(git log -1 --pretty=format:'%ae' 2>/dev/null || echo "unknown")
+
+    echo "$commit_sha|$branch|$author|$author_email"
+}
+
+# Check prerequisites
+check_prerequisites() {
+    print_info "Checking prerequisites..."
+
+    # Check if AWS CLI is available
+    if command -v aws &> /dev/null; then
+        UPLOAD_METHOD="aws-cli"
+        print_success "AWS CLI detected"
+    else
+        print_error "AWS CLI not found. Please install AWS CLI:"
+        echo "  brew install awscli  # macOS"
+        echo "  pip install awscli   # Python"
+        exit 1
+    fi
+
+    # Check AWS credentials
+    if ! aws sts get-caller-identity --region "$AWS_REGION" &>/dev/null; then
+        print_error "AWS credentials not configured or invalid"
+        echo "  Run: aws configure"
+        exit 1
+    fi
+
+    print_success "AWS credentials validated"
+
+    # Check if metrics.json exists
+    if [ ! -f "build/reports/slt-metrics/metrics.json" ]; then
+        print_error "metrics.json not found. Run generate-metrics-json.sh first"
+        exit 1
+    fi
+
+    print_success "Prerequisites check passed"
+}
+
+# Upload files to S3
+upload_to_s3() {
+    local service_name=$1
+    local s3_path="s3://${S3_BUCKET}/${S3_PREFIX}/${service_name}/${TIMESTAMP}"
+
+    print_info "Uploading to: $s3_path"
+
+    # Create temporary staging directory
+    local staging_dir="build/reports/slt-s3-staging"
+    rm -rf "$staging_dir"
+    mkdir -p "$staging_dir/test-cases"
+
+    # Copy metrics.json
+    if [ -f "build/reports/slt-metrics/metrics.json" ]; then
+        cp "build/reports/slt-metrics/metrics.json" "$staging_dir/"
+        print_success "Staged: metrics.json"
+    fi
+
+    # Copy metadata.json
+    if [ -f "build/reports/slt-metrics/metadata.json" ]; then
+        cp "build/reports/slt-metrics/metadata.json" "$staging_dir/"
+        print_success "Staged: metadata.json"
+    fi
+
+    # Copy test report HTML
+    if [ -f "build/reports/tests/test/index.html" ]; then
+        cp "build/reports/tests/test/index.html" "$staging_dir/test-report.html"
+        print_success "Staged: test-report.html"
+    fi
+
+    # Copy coverage report HTML
+    if [ -f "build/reports/jacoco/test/html/index.html" ]; then
+        cp -r "build/reports/jacoco/test/html" "$staging_dir/coverage-report"
+        mv "$staging_dir/coverage-report/index.html" "$staging_dir/coverage-report.html"
+        print_success "Staged: coverage-report.html"
+    fi
+
+    # Copy SLT dashboard
+    if [ -f "build/reports/slt-dashboard/index.html" ]; then
+        cp "build/reports/slt-dashboard/index.html" "$staging_dir/slt-dashboard.html"
+        print_success "Staged: slt-dashboard.html"
+    fi
+
+    # Copy JaCoCo XML and CSV
+    if [ -f "build/reports/jacoco/test/jacocoTestReport.xml" ]; then
+        cp "build/reports/jacoco/test/jacocoTestReport.xml" "$staging_dir/"
+        print_success "Staged: jacocoTestReport.xml"
+    fi
+
+    if [ -f "build/reports/jacoco/test/jacocoTestReport.csv" ]; then
+        cp "build/reports/jacoco/test/jacocoTestReport.csv" "$staging_dir/"
+        print_success "Staged: jacocoTestReport.csv"
+    fi
+
+    # Copy test case CSVs
+    if [ -d "src/test/resources/testcases" ]; then
+        cp src/test/resources/testcases/*.csv "$staging_dir/test-cases/" 2>/dev/null || true
+        local csv_count=$(ls -1 "$staging_dir/test-cases"/*.csv 2>/dev/null | wc -l)
+        if [ "$csv_count" -gt 0 ]; then
+            print_success "Staged: $csv_count test case CSV(s)"
+        fi
+    fi
+
+    echo ""
+    print_info "Uploading to S3..."
+
+    # Upload using AWS CLI
+    if aws s3 sync "$staging_dir" "$s3_path" \
+        --region "$AWS_REGION" \
+        --quiet \
+        --acl private; then
+        print_success "Upload completed successfully"
+    else
+        print_error "Upload failed"
+        exit 1
+    fi
+
+    echo ""
+    print_success "S3 Path: $s3_path"
+    echo ""
+
+    # Generate S3 URLs
+    echo "ğŸ“Š Reports available at:"
+    echo "  Metrics JSON:     ${s3_path}/metrics.json"
+    echo "  Test Report:      ${s3_path}/test-report.html"
+    echo "  Coverage Report:  ${s3_path}/coverage-report.html"
+    echo "  SLT Dashboard:    ${s3_path}/slt-dashboard.html"
+
+    # Cleanup staging
+    rm -rf "$staging_dir"
+}
+
+# Create latest symlink (for easy access to most recent report)
+create_latest_link() {
+    local service_name=$1
+    local s3_path="s3://${S3_BUCKET}/${S3_PREFIX}/${service_name}/${TIMESTAMP}"
+    local latest_path="s3://${S3_BUCKET}/${S3_PREFIX}/${service_name}/latest"
+
+    print_info "Creating 'latest' reference..."
+
+    # Create a simple JSON file pointing to latest
+    local latest_json=$(cat <<EOF
+{
+  "latest_run": "${TIMESTAMP}",
+  "s3_path": "${s3_path}",
+  "updated_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
+}
+EOF
+)
+
+    echo "$latest_json" | aws s3 cp - "${latest_path}/latest.json" \
+        --region "$AWS_REGION" \
+        --quiet \
+        --content-type "application/json"
+
+    print_success "Latest reference updated"
+}
+
+# Main execution
+main() {
+    print_header
+
+    # Get service name
+    local service_name="${1:-$(detect_service_name)}"
+    print_info "Service: $service_name"
+    print_info "Timestamp: $TIMESTAMP"
+    echo ""
+
+    # Check prerequisites
+    check_prerequisites
+    echo ""
+
+    # Upload to S3
+    upload_to_s3 "$service_name"
+
+    # Create latest link
+    create_latest_link "$service_name"
+
+    echo ""
+    echo -e "${GREEN}"
+    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
+    echo "  âœ… Upload Complete"
+    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
+    echo -e "${NC}"
+    echo ""
+    echo "Next steps:"
+    echo "  â†’ Metrics will appear in centralized dashboard"
+    echo "  â†’ S3 bucket: s3://${S3_BUCKET}/${S3_PREFIX}/${service_name}/${TIMESTAMP}/"
+    echo ""
+}
+
+# Run main
+main "$@"
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   120    0   120    0     0    823      0 --:--:-- --:--:-- --:--:--   827